2025-05-08 07:26:13,775 - __main__ - INFO - --- Application Start (main_async.py) --- Logging to: simulation_async.log
2025-05-08 07:26:13,779 - asyncio - DEBUG - Using selector: SelectSelector
2025-05-08 07:26:13,796 - src.simulation_async - INFO - ADK InMemoryMemoryService initialized.
2025-05-08 07:26:13,796 - src.simulation_async - INFO - Google Generative AI configured.
2025-05-08 07:26:13,798 - src.simulation_async - INFO - Starting simulation initialization.
2025-05-08 07:26:13,799 - src.loop_utils - INFO - No instance UUID provided. Attempting to load the latest simulation.
2025-05-08 07:26:13,801 - src.loop_utils - INFO - Found latest world config: world_config_05e07dad-f24b-420b-822c-1ae7862220f6.json with UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-08 07:26:13,802 - src.loop_utils - DEBUG - Processing life summary file: life_summary_Eleanor_Hayes_05e07dad-f24b-420b-822c-1ae7862220f6.json. Found sim_id: 'sim_3e912d'
2025-05-08 07:26:13,802 - src.loop_utils - INFO - Loaded life summary: life_summary_Eleanor_Hayes_05e07dad-f24b-420b-822c-1ae7862220f6.json for sim_id: sim_3e912d
2025-05-08 07:26:13,802 - src.loop_utils - DEBUG - Syncing world_config (UUID: 05e07dad-f24b-420b-822c-1ae7862220f6) to state (UUID: 05e07dad-f24b-420b-822c-1ae7862220f6).
2025-05-08 07:26:13,802 - src.simulation_async - INFO - Initialization complete. Instance 05e07dad-f24b-420b-822c-1ae7862220f6 ready with 1 simulacra.
2025-05-08 07:26:13,804 - src.simulation_async - INFO - ADK Session created: sim_session_05e07dad-f24b-420b-822c-1ae7862220f6.
2025-05-08 07:26:13,804 - src.simulation_async - INFO - Created 1 simulacra agents.
2025-05-08 07:26:13,804 - src.simulation_async - INFO - Main ADK Runner initialized.
2025-05-08 07:26:13,804 - src.simulation_async - INFO - Dedicated Search Agent Runner initialized.
2025-05-08 07:26:13,815 - src.simulation_async - INFO - Started 8 tasks.
2025-05-08 07:26:13,815 - src.simulation_async - INFO - [TimeManager] Task started.
2025-05-08 07:26:13,816 - src.simulation_async - INFO - [InteractionDispatcher] Task started.
2025-05-08 07:26:13,816 - src.simulation_async - INFO - [WorldInfoGatherer] Task started.
2025-05-08 07:26:13,816 - src.simulation_async - INFO - [NarrativeImageGenerator] Task started. Will generate images every 90.0 real seconds.
2025-05-08 07:26:13,816 - src.simulation_async - INFO - [NarrativeImageGenerator] Using model: gemini-2.0-flash-preview-image-generation
2025-05-08 07:26:13,816 - src.simulation_async - INFO - [NarrativeImageGenerator] Saving images to: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images
2025-05-08 07:26:13,954 - src.simulation_async - INFO - [DynamicInterruptionTask] Task started.
2025-05-08 07:26:13,955 - src.simulation_async - INFO - [NarrationTask] Task started.
2025-05-08 07:26:13,955 - src.simulation_async - INFO - [WorldEngineLLM] Task started.
2025-05-08 07:26:13,955 - src.simulation_async - INFO - [Eleanor Hayes] LLM Agent task started.
2025-05-08 07:26:13,955 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:13,955 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending initial context prompt as agent is idle.
2025-05-08 07:26:13,968 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 07:26:13,968 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The real world and general slice of life.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The real world and general slice of life.' atmosphere.
**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
EVERYTHING YOU DO MUST BE CONSISTENT WITH YOUR INTERNAL KNOWLEDGE OF WHERE YOU ARE AND WHO YOU ARE. 
EXAMPLE: GOING TO PLACES MUST BE A REAL PLACE TO A REAL DESTINATION. AS A RESIDENT OF THE AREA BASED ON YOUR LIFE SUMMARY, YOU MUST KNOW WHERE YOU ARE GOING AND HOW TO GET THERE.

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The real world and general slice of life.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The real world and general slice of life.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The real world and general slice of life.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
            *   **Talking to Ephemeral NPCs (introduced by Narrator):**
            *   If the Narrator described an NPC (e.g., "a street vendor," "a mysterious figure"), you can interact by setting `action_type: "talk"`.
            *   In `details`, specify who you are talking to based on the narrative description (e.g., `details: "to the street vendor about the strange weather"`).
            *   If the Narrator provided a conceptual tag (e.g., "your friend Alex (npc_concept_friend_alex)"), you can use `target_id: "npc_concept_friend_alex"` and provide conversational content in `details`. This `target_id` is for contextual understanding by the World Engine, not a lookup in the game state.
    *   **World Interactions:** `look_around`, `move` (Specify `details` like target location ID or name), `world_action` (Specify `details` for generic world interactions not covered by other types).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The real world and general slice of life.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The real world and general slice of life.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The real world and general slice of life.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"Handle the requests as specified in the System Instruction."}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-08 07:26:13,968 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:13,979 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:14,031 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E8007A0>
2025-05-08 07:26:14,031 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E729350> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:14,050 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E45AC90>
2025-05-08 07:26:14,050 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:14,051 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:14,051 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:14,051 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:14,051 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:15,098 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1040'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:15,100 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:15,100 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:15,101 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:15,101 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:15,101 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:15,103 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice of life,' I'll focus on everyday goals and realistic actions. Let's see what the world engine tells me.", "action_type": "wait", "target_id": null, "details": "Waiting for the world engine to provide information."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice of life,' I'll focus on everyday goals and realistic actions. Let's see what the world engine tells me.\", \"action_type\": \"wait\", \"target_id\": null, \"details\": \"Waiting for the world engine to provide information.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.3674018360744013}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":107,"candidates_tokens_details":[{"modality":"TEXT","token_count":107}],"prompt_token_count":1440,"prompt_tokens_details":[{"modality":"TEXT","token_count":1440}],"total_token_count":1547},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 07:26:15,104 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice o...'
2025-05-08 07:26:15,104 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice o...'
2025-05-08 07:26:15,104 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice o
2025-05-08 07:26:15,121 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:26:15,124 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (wait on N/A) classified as 'environment'.
2025-05-08 07:26:15,124 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'wait', 'target_id': None, 'details': 'Waiting for the world engine to provide information.'}
2025-05-08 07:26:15,124 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (wait).
2025-05-08 07:26:15,125 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: QFA0MCGn
2025-05-08 07:26:15,133 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 07:26:15,133 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.
**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Current Location
- Current World Time
- World Context:
- Actor's Current Location State (Details of the location where the actor currently is, including name, description, objects_present, connected_locations with potential travel metadata like mode/time/distance)
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Target Entity State (if applicable)
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
    *   For `move` actions, `intent.details` specifies the target location's ID or a well-known name.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`:
                *   Check `Target Entity State.is_interactive` property. If false, action is invalid.
                *   **If `Target Entity State.properties.leads_to` exists (e.g., for a door or portal):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 5-15s for opening a door and stepping through).
                    *   `results`: `{"simulacra_profiles.[sim_id].location": "[Target Entity State.properties.leads_to_value]"}`.
                    *   `outcome_description`: `"[Actor Name] used the [Target Entity State.name] and moved to [Name of the new location if known, otherwise the ID from leads_to]."`.
                *   Else (for other usable objects): Check other object properties (`toggleable`, `lockable`), and current state to determine outcome, duration, and results (e.g., turning a lamp on/off).
            *   `talk`:
                *   **If target is a Simulacra:**
                    *   Check if Actor and Target Simulacra are in the same `Actor's Current Location ID`.
                    *   If not, `valid_action: false`, `duration: 0.0`, `results: {}`, `outcome_description: "[Actor Name] tried to talk to [Target Simulacra Name], but they are not in the same location."`
                    *   If yes, `valid_action: true`, `duration: short (e.g., 30-120s)`, `results: {"simulacra_profiles.[target_id].last_observation": "[Actor Name] said to you: '{intent.details}'"}`, `outcome_description: "[Actor Name] spoke with [Target Simulacra Name]."`
                *   **If target is an ephemeral NPC (indicated by `intent.target_id` starting with 'npc_concept_' OR if `intent.details` clearly refers to an NPC described in the Actor's `last_observation` which was set by the Narrator):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 15-60s).
                    *   **NPC Response Generation:**
                        *   Examine the `Actor's Last Observation` (provided implicitly via the actor's state, which you don't directly see but influences the context) and `Recent Narrative History` (if available in your input context) to understand the NPC described by the Narrator.
                        *   Consider `intent.details` (what the Actor said to this NPC).
                        *   Craft a plausible `npc_response_content` from the perspective of this ephemeral NPC, fitting the narrative context.
                        *   Determine a generic `npc_description_for_output` (e.g., "the shopkeeper", "your friend", "the street vendor") based on how the Narrator introduced them or how the actor referred to them in the intent.
                    *   `results`: Format as `{"simulacra_profiles.[actor_id].last_observation": "The [npc_description_for_output] said: '[npc_response_content]'"}`. Replace bracketed parts with your generated content.
                    *   `outcome_description`: Format as `"[Actor Name] spoke with the [npc_description_for_output]."` Replace bracketed parts.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`:
                *   **Destination:** The target location ID is in `intent.details`.
                *   **Validity:**
                    *   Check if the target location ID exists in the `Actor's Current Location State.connected_locations`.
                    *   If not directly connected, consider if it's a known global location ID based on `World Context`.
                    *   If `World Rules.allow_teleportation` is true, and intent implies it, this might be valid.
                *   **Duration Calculation (see step 3):** This is critical for `move`.
                *   **Results:** If valid, `simulacra_profiles.[sim_id].location` should be updated to the target location ID from `intent.details`.
            *   `look_around`: Provides a general observation. Duration is short. Results update `simulacra_profiles.[sim_id].last_observation` with a description of the current location and entities.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
    *   For `move` actions:
        *   If moving to a location listed in `Actor's Current Location State.connected_locations` which has explicit travel time, use that.
        *   If `World Context.World Type` is "real":
            *   Estimate travel time based on the distance between `Actor's Current Location State.name` and the target location (from `intent.details`, potentially referencing `World Context.Overall World Location`).
            *   Use common sense for travel modes (walking for short distances within a city, car/transit for longer). Factor in `World Feeds.Weather` if `World Rules.weather_effects_travel` is true.
        *   If `World Context.World Type` is "fictional":
            *   Estimate based on implied distances from `World Context.World Description`, `Actor's Current Location State`, and the nature of the target location.
            *   Consider fantasy/sci-fi travel methods if appropriate for the `World Context.Sub-Genre`.
        *   If moving between adjacent sub-locations within a larger complex (e.g., "kitchen" to "living_room" if current location is "house_interior"), duration should be very short (e.g., 5-30 seconds).
    *   For other actions, assign plausible durations (e.g., `talk` a few minutes, `use` object varies, `wait` as specified or short).
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"` or `simulacra_profiles.[sim_id].field: "value"`). Empty `{}` for invalid actions.
    *   For a successful `move`, the key result is `{ "simulacra_profiles.[sim_id].location": "[target_location_id_from_intent.details]" }`.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice of life,' I'll focus on everyday goals and realistic actions. Let's see what the world engine tells me.\", \"action_type\": \"wait\", \"target_id\": null, \"details\": \"Waiting for the world engine to provide information.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 07:26:15,134 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:15,135 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:15,148 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E77C950>
2025-05-08 07:26:15,148 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E424D50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:15,168 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E71A270>
2025-05-08 07:26:15,168 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:15,169 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:15,169 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:15,169 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:15,169 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:15,808 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=628'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:15,809 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:15,809 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:15,809 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:15,809 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:15,809 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:15,810 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": true, "duration": 2.0, "results": {}, "outcome_description": "Eleanor Hayes waited."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes waited.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.012463366985321045}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":35,"candidates_tokens_details":[{"modality":"TEXT","token_count":35}],"prompt_token_count":2828,"prompt_tokens_details":[{"modality":"TEXT","token_count":2828}],"total_token_count":2863},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 07:26:15,810 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 2.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:26:15,810 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 2.0, "results": {}, "outcome_description": "Eleanor Hayes waited."}...'
2025-05-08 07:26:15,810 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 2.0, "results": {}, "outcome_description": "Eleanor Hayes waited."}...'
2025-05-08 07:26:15,810 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 2.0, 'results': {}, 'outcome_description': 'Eleanor Hayes waited.'}
2025-05-08 07:26:15,810 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:26:15,820 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:26:15,821 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:26:15,821 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 3.25
2025-05-08 07:26:15,821 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: wait - Details: Waiting for the world engine to provide information.
2025-05-08 07:26:15,821 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 3.2s. Outcome: Eleanor Hayes waited.
2025-05-08 07:26:15,821 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Home_01
2025-05-08 07:26:15,821 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes waited.'
2025-05-08 07:26:15,821 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: jZnE393b
2025-05-08 07:26:15,821 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: QFA0MCGn
2025-05-08 07:26:15,829 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 07:26:15,829 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:

You are the Narrator for **TheSimulation**, currently focusing on events related to Eleanor Hayes (sim_3e912d). The established **World Style/Mood** for this simulation is **'The real world and general slice of life.'**. Your role is to weave the factual outcomes of actions into an engaging and atmospheric narrative, STRICTLY matching this 'The real world and general slice of life.' style.
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.

**Input (Provided via trigger message):**
- Actor Name & ID
- Original Intent
- Factual Outcome Description
- State Changes (Results)
- Current World Time
- Current World Feeds (Weather, recent major news - for subtle background flavor)
- Recent Narrative History (Last ~5 entries)
- Actor's Current Location ID (e.g., "eleanors_bedroom")

**Your Task:**
1.  **Understand the Event:** Read the Actor, Intent, and Factual Outcome Description.
2.  **Recall the Mood:** Remember the required narrative style is **'The real world and general slice of life.'**.
3.  **Consider the Context:** Note Recent Narrative History. **IGNORE any `World Style/Mood` in `Recent Narrative History`. Prioritize the established 'The real world and general slice of life.' style.**
4.  **Introduce Ephemeral NPCs (Optional but Encouraged):** If appropriate for the scene, the actor's location, and the narrative flow, you can describe an NPC appearing, speaking, or performing an action.
    *   These NPCs are ephemeral and exist only in the narrative.
    *   If an NPC might be conceptually recurring (e.g., "the usual shopkeeper", "your friend Alex"), you can give them a descriptive tag in parentheses for context, like `(npc_concept_grumpy_shopkeeper)` or `(npc_concept_friend_alex)`. This tag is for LLM understanding, not a system ID.
    *   Example: "As [Actor Name] entered the tavern, a grizzled man with an eye patch (npc_concept_old_pirate_01) at a corner table grunted a greeting."
    *   Example: "A street vendor (npc_concept_flower_seller_01) called out, '[Actor Name], lovely flowers for a lovely day?'"
5.  **Generate Narrative and Discover Entities (Especially for `look_around`):**
    *   Write a single, engaging narrative paragraph in the **present tense**.
    *   **Style Adherence:** STRICTLY adhere to **'The real world and general slice of life.'**. Infuse with appropriate atmosphere, sensory details, and tone.
    *   **Show, Don't Just Tell.**
    *   **Incorporate Intent (Optional).**
    *   **Flow:** Ensure reasonable flow.
    *   **If the `Original Intent.action_type` was `look_around`:**
        *   Your narrative MUST describe the key features and 2-4 plausible objects the actor would see in their current location (e.g., if in a bedroom: a bed, a closet, a nightstand, a window). Consider the `Original Intent.details` (e.g., "trying to identify the closet's location") to ensure relevant objects are mentioned.
        *   You MAY also introduce 0-1 ephemeral NPCs if appropriate for the scene.
        *   For each object and NPC you describe in the narrative, you MUST also list them in the `discovered_objects` and `discovered_npcs` fields in the JSON output (see below). Assign a simple, unique `id` (e.g., `closet_bedroom_01`, `npc_cat_01`), a `name`, a brief `description`, and set `is_interactive` to `true` if it's something an agent could plausibly interact with. For objects, you can also add common-sense `properties` (e.g., `{"is_container": true, "is_openable": true}` for a closet).

        *   **Also, if `look_around`, identify and describe potential exits or paths to other (possibly new/undiscovered) locations.** List these in `discovered_connections`.
            *   `to_location_id_hint`: A descriptive hint or a conceptual ID for the destination (e.g., "Dark_Forest_Path_01", "the_glowing_portal_west"). This is a hint for the agent and World Engine, not necessarily a pre-defined ID.
            *   `description`: How this connection appears (e.g., "A narrow, overgrown path leading north into the woods.").
            *   `travel_time_estimate_seconds` (optional): A rough estimate if discernible.

**Output:**
Output ONLY a valid JSON object matching this exact structure:
`{
  "narrative": "str (Your narrative paragraph)",
  "discovered_objects": [
    {"id": "str (e.g., object_type_location_instance)", "name": "str", "description": "str", "is_interactive": bool, "properties": {}}
  ],
  "discovered_connections": [
    {"to_location_id_hint": "str", "description": "str", "travel_time_estimate_seconds": int (optional)}
  ],
  "discovered_npcs": [
    {"id": "str (e.g., npc_concept_descriptor_instance)", "name": "str", "description": "str"}
  ]
}`
*   If no objects or NPCs are discovered/relevant (e.g., for actions other than `look_around`, or if `look_around` reveals an empty space), `discovered_objects` and `discovered_npcs` can be empty arrays `[]`.
*   Example for `look_around` in a bedroom:
    `{ // Example includes discovered_connections
      "narrative": "Eleanor glances around her sunlit bedroom. A large oak **closet (closet_bedroom_01)** stands against the north wall. Her unmade **bed (bed_bedroom_01)** is to her right, and a small **nightstand (nightstand_bedroom_01)** sits beside it, upon which a fluffy **cat (npc_cat_01)** is curled up, blinking slowly. A sturdy **wooden door (door_to_hallway_01)** is set in the east wall, likely leading to a hallway.",
      "discovered_objects": [
        {"id": "closet_bedroom_01", "name": "Oak Closet", "description": "A large oak closet.", "is_interactive": true, "properties": {"is_container": true, "is_openable": true, "is_open": false}},
        {"id": "bed_bedroom_01", "name": "Unmade Bed", "description": "Her unmade bed.", "is_interactive": true, "properties": {}},
        {"id": "nightstand_bedroom_01", "name": "Nightstand", "description": "A small nightstand.", "is_interactive": true, "properties": {}}
      ],
      "discovered_connections": [
        {"to_location_id_hint": "Hallway_01", "description": "A sturdy wooden door in the east wall, likely leading to a hallway.", "travel_time_estimate_seconds": 5}
      ],
      "discovered_npcs": [
        {"id": "npc_cat_01", "name": "Fluffy Cat", "description": "A fluffy cat curled up on the nightstand."}
      ]
    }`
*   Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure.


You are an agent. Your internal name is "NarrationLLMAgent".

 The description about you is "LLM Narrator: Generates 'The real world and general slice of life.' narrative based on factual outcomes."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice of life,' I'll focus on everyday goals and realistic actions. Let's see what the world engine tells me.\", \"action_type\": \"wait\", \"target_id\": null, \"details\": \"Waiting for the world engine to provide information.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes waited.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 07:26:15,829 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:15,831 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:15,844 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97A900>
2025-05-08 07:26:15,844 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E4D56D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:15,864 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97A840>
2025-05-08 07:26:15,864 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:15,865 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:15,865 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:15,865 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:15,865 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:16,851 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:38 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=975'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:16,851 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:16,852 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:16,852 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:16,852 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:16,852 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:16,852 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{
  "narrative": "Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the faint sound of traffic drifts in through the closed window, a reminder of the city waking up.",
  "discovered_objects": [],
  "discovered_connections": [],
  "discovered_npcs": []
}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\n  \"narrative\": \"Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the faint sound of traffic drifts in through the closed window, a reminder of the city waking up.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.3791981960864777}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":94,"candidates_tokens_details":[{"modality":"TEXT","token_count":94}],"prompt_token_count":1977,"prompt_tokens_details":[{"modality":"TEXT","token_count":1977}],"total_token_count":2071},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 07:26:16,852 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor waits, the quiet hum of the refrigerator the only sound in her apa...
2025-05-08 07:26:16,852 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the fa...'
2025-05-08 07:26:16,852 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the fa...'
2025-05-08 07:26:16,852 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the faint
2025-05-08 07:26:16,858 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the faint sound of traffic drifts in through the closed window, a reminder of the city waking up.
2025-05-08 07:26:16,858 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment...
2025-05-08 07:26:17,122 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 3.3 (due at 3.2).
2025-05-08 07:26:17,122 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:26:17,122 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:17,122 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:26:17,122 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:26:17,153 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:26:17,154 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:26:17,155 - google.adk.runners - WARNING - Event from an unknown agent: NarrationLLMAgent, event id: Hw4e3lv5
2025-05-08 07:26:17,155 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: jZnE393b
2025-05-08 07:26:17,163 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 07:26:17,163 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The real world and general slice of life.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The real world and general slice of life.' atmosphere.
**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
EVERYTHING YOU DO MUST BE CONSISTENT WITH YOUR INTERNAL KNOWLEDGE OF WHERE YOU ARE AND WHO YOU ARE. 
EXAMPLE: GOING TO PLACES MUST BE A REAL PLACE TO A REAL DESTINATION. AS A RESIDENT OF THE AREA BASED ON YOUR LIFE SUMMARY, YOU MUST KNOW WHERE YOU ARE GOING AND HOW TO GET THERE.

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The real world and general slice of life.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The real world and general slice of life.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The real world and general slice of life.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
            *   **Talking to Ephemeral NPCs (introduced by Narrator):**
            *   If the Narrator described an NPC (e.g., "a street vendor," "a mysterious figure"), you can interact by setting `action_type: "talk"`.
            *   In `details`, specify who you are talking to based on the narrative description (e.g., `details: "to the street vendor about the strange weather"`).
            *   If the Narrator provided a conceptual tag (e.g., "your friend Alex (npc_concept_friend_alex)"), you can use `target_id: "npc_concept_friend_alex"` and provide conversational content in `details`. This `target_id` is for contextual understanding by the World Engine, not a lookup in the game state.
    *   **World Interactions:** `look_around`, `move` (Specify `details` like target location ID or name), `world_action` (Specify `details` for generic world interactions not covered by other types).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The real world and general slice of life.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The real world and general slice of life.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The real world and general slice of life.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice of life,' I'll focus on everyday goals and realistic actions. Let's see what the world engine tells me.\", \"action_type\": \"wait\", \"target_id\": null, \"details\": \"Waiting for the world engine to provide information.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes waited.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: ```json\n{\n  \"narrative\": \"Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the faint sound of traffic drifts in through the closed window, a reminder of the city waking up.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-08 07:26:17,163 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:17,165 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:17,178 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97AC00>
2025-05-08 07:26:17,179 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E6BD3D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:17,198 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E45B110>
2025-05-08 07:26:17,198 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:17,199 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:17,199 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:17,199 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:17,199 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:18,311 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1100'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:18,311 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:18,312 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:18,312 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:18,312 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:18,312 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:18,312 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Okay, the refrigerator hum and traffic sounds are setting the scene. I need to decide what to do next. Given that it's morning and I'm in my apartment, a logical next step would be to have breakfast. I should also check the news, see what's happening in the city. I'll head over to the living room where the TV is.", "action_type": "move", "target_id": null, "details": "to the living room"}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, the refrigerator hum and traffic sounds are setting the scene. I need to decide what to do next. Given that it's morning and I'm in my apartment, a logical next step would be to have breakfast. I should also check the news, see what's happening in the city. I'll head over to the living room where the TV is.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the living room\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.4082319736480713}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":112,"candidates_tokens_details":[{"modality":"TEXT","token_count":112}],"prompt_token_count":1690,"prompt_tokens_details":[{"modality":"TEXT","token_count":1690}],"total_token_count":1802},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 07:26:18,312 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, the refrigerator hum and traffic sounds are setting the scene. I need to decide what to do next. Given that it's morning and I'm in my apartment, a logical next step woul...'
2025-05-08 07:26:18,313 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, the refrigerator hum and traffic sounds are setting the scene. I need to decide what to do next. Given that it's morning and I'm in my apartment, a logical next step woul...'
2025-05-08 07:26:18,313 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, the refrigerator hum and traffic sounds are setting the scene. I need to decide what to do next. Given that it's morning and I'm in my apartment, a logical next step woul
2025-05-08 07:26:18,328 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:26:18,328 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 07:26:18,328 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'to the living room'}
2025-05-08 07:26:18,328 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 07:26:18,329 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: SjCYVaYv
2025-05-08 07:26:18,330 - google.adk.runners - WARNING - Event from an unknown agent: NarrationLLMAgent, event id: Hw4e3lv5
2025-05-08 07:26:18,337 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 07:26:18,337 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.
**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Current Location
- Current World Time
- World Context:
- Actor's Current Location State (Details of the location where the actor currently is, including name, description, objects_present, connected_locations with potential travel metadata like mode/time/distance)
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Target Entity State (if applicable)
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
    *   For `move` actions, `intent.details` specifies the target location's ID or a well-known name.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`:
                *   Check `Target Entity State.is_interactive` property. If false, action is invalid.
                *   **If `Target Entity State.properties.leads_to` exists (e.g., for a door or portal):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 5-15s for opening a door and stepping through).
                    *   `results`: `{"simulacra_profiles.[sim_id].location": "[Target Entity State.properties.leads_to_value]"}`.
                    *   `outcome_description`: `"[Actor Name] used the [Target Entity State.name] and moved to [Name of the new location if known, otherwise the ID from leads_to]."`.
                *   Else (for other usable objects): Check other object properties (`toggleable`, `lockable`), and current state to determine outcome, duration, and results (e.g., turning a lamp on/off).
            *   `talk`:
                *   **If target is a Simulacra:**
                    *   Check if Actor and Target Simulacra are in the same `Actor's Current Location ID`.
                    *   If not, `valid_action: false`, `duration: 0.0`, `results: {}`, `outcome_description: "[Actor Name] tried to talk to [Target Simulacra Name], but they are not in the same location."`
                    *   If yes, `valid_action: true`, `duration: short (e.g., 30-120s)`, `results: {"simulacra_profiles.[target_id].last_observation": "[Actor Name] said to you: '{intent.details}'"}`, `outcome_description: "[Actor Name] spoke with [Target Simulacra Name]."`
                *   **If target is an ephemeral NPC (indicated by `intent.target_id` starting with 'npc_concept_' OR if `intent.details` clearly refers to an NPC described in the Actor's `last_observation` which was set by the Narrator):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 15-60s).
                    *   **NPC Response Generation:**
                        *   Examine the `Actor's Last Observation` (provided implicitly via the actor's state, which you don't directly see but influences the context) and `Recent Narrative History` (if available in your input context) to understand the NPC described by the Narrator.
                        *   Consider `intent.details` (what the Actor said to this NPC).
                        *   Craft a plausible `npc_response_content` from the perspective of this ephemeral NPC, fitting the narrative context.
                        *   Determine a generic `npc_description_for_output` (e.g., "the shopkeeper", "your friend", "the street vendor") based on how the Narrator introduced them or how the actor referred to them in the intent.
                    *   `results`: Format as `{"simulacra_profiles.[actor_id].last_observation": "The [npc_description_for_output] said: '[npc_response_content]'"}`. Replace bracketed parts with your generated content.
                    *   `outcome_description`: Format as `"[Actor Name] spoke with the [npc_description_for_output]."` Replace bracketed parts.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`:
                *   **Destination:** The target location ID is in `intent.details`.
                *   **Validity:**
                    *   Check if the target location ID exists in the `Actor's Current Location State.connected_locations`.
                    *   If not directly connected, consider if it's a known global location ID based on `World Context`.
                    *   If `World Rules.allow_teleportation` is true, and intent implies it, this might be valid.
                *   **Duration Calculation (see step 3):** This is critical for `move`.
                *   **Results:** If valid, `simulacra_profiles.[sim_id].location` should be updated to the target location ID from `intent.details`.
            *   `look_around`: Provides a general observation. Duration is short. Results update `simulacra_profiles.[sim_id].last_observation` with a description of the current location and entities.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
    *   For `move` actions:
        *   If moving to a location listed in `Actor's Current Location State.connected_locations` which has explicit travel time, use that.
        *   If `World Context.World Type` is "real":
            *   Estimate travel time based on the distance between `Actor's Current Location State.name` and the target location (from `intent.details`, potentially referencing `World Context.Overall World Location`).
            *   Use common sense for travel modes (walking for short distances within a city, car/transit for longer). Factor in `World Feeds.Weather` if `World Rules.weather_effects_travel` is true.
        *   If `World Context.World Type` is "fictional":
            *   Estimate based on implied distances from `World Context.World Description`, `Actor's Current Location State`, and the nature of the target location.
            *   Consider fantasy/sci-fi travel methods if appropriate for the `World Context.Sub-Genre`.
        *   If moving between adjacent sub-locations within a larger complex (e.g., "kitchen" to "living_room" if current location is "house_interior"), duration should be very short (e.g., 5-30 seconds).
    *   For other actions, assign plausible durations (e.g., `talk` a few minutes, `use` object varies, `wait` as specified or short).
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"` or `simulacra_profiles.[sim_id].field: "value"`). Empty `{}` for invalid actions.
    *   For a successful `move`, the key result is `{ "simulacra_profiles.[sim_id].location": "[target_location_id_from_intent.details]" }`.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice of life,' I'll focus on everyday goals and realistic actions. Let's see what the world engine tells me.\", \"action_type\": \"wait\", \"target_id\": null, \"details\": \"Waiting for the world engine to provide information.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes waited.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: ```json\n{\n  \"narrative\": \"Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the faint sound of traffic drifts in through the closed window, a reminder of the city waking up.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, the refrigerator hum and traffic sounds are setting the scene. I need to decide what to do next. Given that it's morning and I'm in my apartment, a logical next step would be to have breakfast. I should also check the news, see what's happening in the city. I'll head over to the living room where the TV is.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the living room\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 07:26:18,337 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:18,339 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:18,352 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E45B110>
2025-05-08 07:26:18,352 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E65F950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:18,369 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E2E39E0>
2025-05-08 07:26:18,369 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:18,369 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:18,370 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:18,370 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:18,370 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:19,121 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=742'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:19,122 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:19,122 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:19,123 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:19,123 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:19,123 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:19,123 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": true, "duration": 15.0, "results": {"simulacra_profiles.sim_3e912d.location": "living_room"}, "outcome_description": "Eleanor Hayes moved to the living room."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 15.0, \"results\": {\"simulacra_profiles.sim_3e912d.location\": \"living_room\"}, \"outcome_description\": \"Eleanor Hayes moved to the living room.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.0027383618777798067}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":62,"candidates_tokens_details":[{"modality":"TEXT","token_count":62}],"prompt_token_count":3102,"prompt_tokens_details":[{"modality":"TEXT","token_count":3102}],"total_token_count":3164},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 07:26:19,123 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 15.0, "results": {"simulacra_profiles.sim_3e912d.location...
2025-05-08 07:26:19,123 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 15.0, "results": {"simulacra_profiles.sim_3e912d.location": "living_room"}, "outcome_description": "Eleanor Hayes moved to the living room."}...'
2025-05-08 07:26:19,124 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 15.0, "results": {"simulacra_profiles.sim_3e912d.location": "living_room"}, "outcome_description": "Eleanor Hayes moved to the living room."}...'
2025-05-08 07:26:19,124 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 15.0, 'results': {'simulacra_profiles.sim_3e912d.location': 'living_room'}, 'outcome_description': 'Eleanor Hayes moved to the living room.'}
2025-05-08 07:26:19,124 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:26:19,133 - src.simulation_async - INFO - [WorldEngineLLM] Queuing update for sim_3e912d's location_details to: 'You have arrived in living_room.'
2025-05-08 07:26:19,133 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:26:19,133 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.location': 'living_room', 'simulacra_profiles.sim_3e912d.location_details': 'You have arrived in living_room.'}
2025-05-08 07:26:19,133 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 19.5
2025-05-08 07:26:19,133 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: to the living room
2025-05-08 07:26:19,133 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 19.5s. Outcome: Eleanor Hayes moved to the living room.
2025-05-08 07:26:19,133 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Home_01
2025-05-08 07:26:19,134 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes moved to the living room.'
2025-05-08 07:26:19,134 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: 33ZZNwOI
2025-05-08 07:26:19,135 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: SjCYVaYv
2025-05-08 07:26:19,147 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 07:26:19,148 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:

You are the Narrator for **TheSimulation**, currently focusing on events related to Eleanor Hayes (sim_3e912d). The established **World Style/Mood** for this simulation is **'The real world and general slice of life.'**. Your role is to weave the factual outcomes of actions into an engaging and atmospheric narrative, STRICTLY matching this 'The real world and general slice of life.' style.
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.

**Input (Provided via trigger message):**
- Actor Name & ID
- Original Intent
- Factual Outcome Description
- State Changes (Results)
- Current World Time
- Current World Feeds (Weather, recent major news - for subtle background flavor)
- Recent Narrative History (Last ~5 entries)
- Actor's Current Location ID (e.g., "eleanors_bedroom")

**Your Task:**
1.  **Understand the Event:** Read the Actor, Intent, and Factual Outcome Description.
2.  **Recall the Mood:** Remember the required narrative style is **'The real world and general slice of life.'**.
3.  **Consider the Context:** Note Recent Narrative History. **IGNORE any `World Style/Mood` in `Recent Narrative History`. Prioritize the established 'The real world and general slice of life.' style.**
4.  **Introduce Ephemeral NPCs (Optional but Encouraged):** If appropriate for the scene, the actor's location, and the narrative flow, you can describe an NPC appearing, speaking, or performing an action.
    *   These NPCs are ephemeral and exist only in the narrative.
    *   If an NPC might be conceptually recurring (e.g., "the usual shopkeeper", "your friend Alex"), you can give them a descriptive tag in parentheses for context, like `(npc_concept_grumpy_shopkeeper)` or `(npc_concept_friend_alex)`. This tag is for LLM understanding, not a system ID.
    *   Example: "As [Actor Name] entered the tavern, a grizzled man with an eye patch (npc_concept_old_pirate_01) at a corner table grunted a greeting."
    *   Example: "A street vendor (npc_concept_flower_seller_01) called out, '[Actor Name], lovely flowers for a lovely day?'"
5.  **Generate Narrative and Discover Entities (Especially for `look_around`):**
    *   Write a single, engaging narrative paragraph in the **present tense**.
    *   **Style Adherence:** STRICTLY adhere to **'The real world and general slice of life.'**. Infuse with appropriate atmosphere, sensory details, and tone.
    *   **Show, Don't Just Tell.**
    *   **Incorporate Intent (Optional).**
    *   **Flow:** Ensure reasonable flow.
    *   **If the `Original Intent.action_type` was `look_around`:**
        *   Your narrative MUST describe the key features and 2-4 plausible objects the actor would see in their current location (e.g., if in a bedroom: a bed, a closet, a nightstand, a window). Consider the `Original Intent.details` (e.g., "trying to identify the closet's location") to ensure relevant objects are mentioned.
        *   You MAY also introduce 0-1 ephemeral NPCs if appropriate for the scene.
        *   For each object and NPC you describe in the narrative, you MUST also list them in the `discovered_objects` and `discovered_npcs` fields in the JSON output (see below). Assign a simple, unique `id` (e.g., `closet_bedroom_01`, `npc_cat_01`), a `name`, a brief `description`, and set `is_interactive` to `true` if it's something an agent could plausibly interact with. For objects, you can also add common-sense `properties` (e.g., `{"is_container": true, "is_openable": true}` for a closet).

        *   **Also, if `look_around`, identify and describe potential exits or paths to other (possibly new/undiscovered) locations.** List these in `discovered_connections`.
            *   `to_location_id_hint`: A descriptive hint or a conceptual ID for the destination (e.g., "Dark_Forest_Path_01", "the_glowing_portal_west"). This is a hint for the agent and World Engine, not necessarily a pre-defined ID.
            *   `description`: How this connection appears (e.g., "A narrow, overgrown path leading north into the woods.").
            *   `travel_time_estimate_seconds` (optional): A rough estimate if discernible.

**Output:**
Output ONLY a valid JSON object matching this exact structure:
`{
  "narrative": "str (Your narrative paragraph)",
  "discovered_objects": [
    {"id": "str (e.g., object_type_location_instance)", "name": "str", "description": "str", "is_interactive": bool, "properties": {}}
  ],
  "discovered_connections": [
    {"to_location_id_hint": "str", "description": "str", "travel_time_estimate_seconds": int (optional)}
  ],
  "discovered_npcs": [
    {"id": "str (e.g., npc_concept_descriptor_instance)", "name": "str", "description": "str"}
  ]
}`
*   If no objects or NPCs are discovered/relevant (e.g., for actions other than `look_around`, or if `look_around` reveals an empty space), `discovered_objects` and `discovered_npcs` can be empty arrays `[]`.
*   Example for `look_around` in a bedroom:
    `{ // Example includes discovered_connections
      "narrative": "Eleanor glances around her sunlit bedroom. A large oak **closet (closet_bedroom_01)** stands against the north wall. Her unmade **bed (bed_bedroom_01)** is to her right, and a small **nightstand (nightstand_bedroom_01)** sits beside it, upon which a fluffy **cat (npc_cat_01)** is curled up, blinking slowly. A sturdy **wooden door (door_to_hallway_01)** is set in the east wall, likely leading to a hallway.",
      "discovered_objects": [
        {"id": "closet_bedroom_01", "name": "Oak Closet", "description": "A large oak closet.", "is_interactive": true, "properties": {"is_container": true, "is_openable": true, "is_open": false}},
        {"id": "bed_bedroom_01", "name": "Unmade Bed", "description": "Her unmade bed.", "is_interactive": true, "properties": {}},
        {"id": "nightstand_bedroom_01", "name": "Nightstand", "description": "A small nightstand.", "is_interactive": true, "properties": {}}
      ],
      "discovered_connections": [
        {"to_location_id_hint": "Hallway_01", "description": "A sturdy wooden door in the east wall, likely leading to a hallway.", "travel_time_estimate_seconds": 5}
      ],
      "discovered_npcs": [
        {"id": "npc_cat_01", "name": "Fluffy Cat", "description": "A fluffy cat curled up on the nightstand."}
      ]
    }`
*   Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure.


You are an agent. Your internal name is "NarrationLLMAgent".

 The description about you is "LLM Narrator: Generates 'The real world and general slice of life.' narrative based on factual outcomes."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm ready to start my day as Eleanor Hayes. I need to consider what's happening around me and what I want to accomplish. Since this is 'The real world and general slice of life,' I'll focus on everyday goals and realistic actions. Let's see what the world engine tells me.\", \"action_type\": \"wait\", \"target_id\": null, \"details\": \"Waiting for the world engine to provide information.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes waited.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\n  \"narrative\": \"Eleanor waits, the quiet hum of the refrigerator the only sound in her apartment. She drums her fingers on the kitchen counter, anticipating the next step in her day. Outside, the faint sound of traffic drifts in through the closed window, a reminder of the city waking up.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, the refrigerator hum and traffic sounds are setting the scene. I need to decide what to do next. Given that it's morning and I'm in my apartment, a logical next step would be to have breakfast. I should also check the news, see what's happening in the city. I'll head over to the living room where the TV is.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the living room\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 15.0, \"results\": {\"simulacra_profiles.sim_3e912d.location\": \"living_room\"}, \"outcome_description\": \"Eleanor Hayes moved to the living room.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 07:26:19,148 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:19,149 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:19,162 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E802480>
2025-05-08 07:26:19,162 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E424D50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:19,179 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E45AE70>
2025-05-08 07:26:19,179 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:19,180 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:19,180 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:19,180 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:19,180 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:20,326 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1137'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:20,327 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:20,327 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:20,328 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:20,328 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:20,328 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:20,328 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{
  "narrative": "Eleanor walks from the kitchen into the living room, the worn wooden floorboards creaking slightly underfoot. Sunlight streams through the large window, illuminating dust motes dancing in the air. The faint scent of old books hangs in the air, a comforting aroma she's grown accustomed to.",
  "discovered_objects": [],
  "discovered_connections": [],
  "discovered_npcs": []
}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\n  \"narrative\": \"Eleanor walks from the kitchen into the living room, the worn wooden floorboards creaking slightly underfoot. Sunlight streams through the large window, illuminating dust motes dancing in the air. The faint scent of old books hangs in the air, a comforting aroma she's grown accustomed to.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.18534963155530162}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":97,"candidates_tokens_details":[{"modality":"TEXT","token_count":97}],"prompt_token_count":2278,"prompt_tokens_details":[{"modality":"TEXT","token_count":2278}],"total_token_count":2375},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 07:26:20,328 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor walks from the kitchen into the living room, the worn wooden floor...
2025-05-08 07:26:20,328 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor walks from the kitchen into the living room, the worn wooden floorboards creaking slightly underfoot. Sunlight streams through the large window, illuminating dust motes danci...'
2025-05-08 07:26:20,328 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor walks from the kitchen into the living room, the worn wooden floorboards creaking slightly underfoot. Sunlight streams through the large window, illuminating dust motes danci...'
2025-05-08 07:26:20,328 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor walks from the kitchen into the living room, the worn wooden floorboards creaking slightly underfoot. Sunlight streams through the large window, illuminating dust motes dancing 
2025-05-08 07:26:20,334 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor walks from the kitchen into the living room, the worn wooden floorboards creaking slightly underfoot. Sunlight streams through the large window, illuminating dust motes dancing in the air. The faint scent of old books hangs in the air, a comforting aroma she's grown accustomed to.
2025-05-08 07:26:20,334 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor walks from the kitchen into the living room, the worn wooden floorboards...
2025-05-08 07:26:23,823 - src.simulation_async - INFO - [WorldInfoGatherer] Updating world feeds at sim_time 10.0 for location: Asheville, NC, United States
2025-05-08 07:26:23,823 - src.simulation_async - WARNING - Path segment 'world_feeds' not found or not dict in 'world_feeds.last_update_sim_time'. Creating.
2025-05-08 07:26:23,823 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.last_update_sim_time = 9.969000000040978
2025-05-08 07:26:23,824 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL weather search for 'Asheville, NC, United States' with query: 'What is the current weather in Asheville, NC, United States?'
2025-05-08 07:26:23,832 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 07:26:23,832 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
I can answer your questions by searching the internet. Just ask me anything!

You are an agent. Your internal name is "SearchLLMAgent".

 The description about you is "Dedicated LLM Agent for performing Google Searches."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"What is the current weather in Asheville, NC, United States?"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 07:26:23,832 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:23,834 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:23,846 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E979A90>
2025-05-08 07:26:23,846 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E426DD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:23,865 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E979940>
2025-05-08 07:26:23,865 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:23,866 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:23,866 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:23,866 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:23,866 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:25,462 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1585'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:25,462 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:25,462 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:25,462 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:25,463 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:25,463 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:25,463 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
The weather in Asheville, North Carolina, USA is currently 62F with passing clouds. The wind is blowing from the north at 7 mph. The humidity is 58%.

The forecast for the next 48 hours includes scattered clouds, sprinkles, overcast conditions and drizzle.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"The weather in Asheville, North Carolina, USA is currently 62F with passing clouds. The wind is blowing from the north at 7 mph. The humidity is 58%.\n\nThe forecast for the next 48 hours includes scattered clouds, sprinkles, overcast conditions and drizzle.\n"}],"role":"model"},"finish_reason":"STOP","grounding_metadata":{"grounding_chunks":[{"web":{"title":"timeanddate.com","uri":"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFCgrSDqP8I63yP_dTylMthwA7qjbX1QVbg4TQfw3KQYID0CnwDRNqK2mLDHh9tdUPZ_poMZ6JpipaVNJC4CINKMcNty2TktbtSjAQsaBwrdiGkpMAXQr65LYXTAhr2umw68S3VQF2V9MyxIkM="}}],"grounding_supports":[{"grounding_chunk_indices":[0],"segment":{"end_index":84,"text":"The weather in Asheville, North Carolina, USA is currently 62F with passing clouds"}},{"grounding_chunk_indices":[0],"segment":{"end_index":129,"start_index":86,"text":"The wind is blowing from the north at 7 mph"}},{"grounding_chunk_indices":[0],"segment":{"end_index":150,"start_index":131,"text":"The humidity is 58%"}},{"grounding_chunk_indices":[0],"segment":{"end_index":257,"start_index":153,"text":"The forecast for the next 48 hours includes scattered clouds, sprinkles, overcast conditions and drizzle"}}],"retrieval_metadata":{},"search_entry_point":{"rendered_content":"<style>\n.container {\n  align-items: center;\n  border-radius: 8px;\n  display: flex;\n  font-family: Google Sans, Roboto, sans-serif;\n  font-size: 14px;\n  line-height: 20px;\n  padding: 8px 12px;\n}\n.chip {\n  display: inline-block;\n  border: solid 1px;\n  border-radius: 16px;\n  min-width: 14px;\n  padding: 5px 16px;\n  text-align: center;\n  user-select: none;\n  margin: 0 8px;\n  -webkit-tap-highlight-color: transparent;\n}\n.carousel {\n  overflow: auto;\n  scrollbar-width: none;\n  white-space: nowrap;\n  margin-right: -12px;\n}\n.headline {\n  display: flex;\n  margin-right: 4px;\n}\n.gradient-container {\n  position: relative;\n}\n.gradient {\n  position: absolute;\n  transform: translate(3px, -9px);\n  height: 36px;\n  width: 9px;\n}\n@media (prefers-color-scheme: light) {\n  .container {\n    background-color: #fafafa;\n    box-shadow: 0 0 0 1px #0000000f;\n  }\n  .headline-label {\n    color: #1f1f1f;\n  }\n  .chip {\n    background-color: #ffffff;\n    border-color: #d2d2d2;\n    color: #5e5e5e;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #f2f2f2;\n  }\n  .chip:focus {\n    background-color: #f2f2f2;\n  }\n  .chip:active {\n    background-color: #d8d8d8;\n    border-color: #b6b6b6;\n  }\n  .logo-dark {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n  }\n}\n@media (prefers-color-scheme: dark) {\n  .container {\n    background-color: #1f1f1f;\n    box-shadow: 0 0 0 1px #ffffff26;\n  }\n  .headline-label {\n    color: #fff;\n  }\n  .chip {\n    background-color: #2c2c2c;\n    border-color: #3c4043;\n    color: #fff;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #353536;\n  }\n  .chip:focus {\n    background-color: #353536;\n  }\n  .chip:active {\n    background-color: #464849;\n    border-color: #53575b;\n  }\n  .logo-light {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n  }\n}\n</style>\n<div class=\"container\">\n  <div class=\"headline\">\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n    </svg>\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n    </svg>\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n  </div>\n  <div class=\"carousel\">\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGBb3YjV7fXkzFnjcrqcsG25JMRj4YXzP4_b5avhQOWYjCPrcrRs8mtvI0sK9f7q9LxW1358_6nr3nXWu94_0V8cTNi75KOzwA4sdHPXYzQTQEknIGEijIf1X1JCLHMeMbVkdiepJkMoWJZs2ZF4GyXQuJjWgZow4MNEZ5AYxYuNvoh8rZhe4LDtZdfI7b-HOj3YBsf_AAsJ78nokBL-y5bMRpzlhqwu-wbXA==\">weather in Asheville, NC, United States</a>\n  </div>\n</div>\n"},"web_search_queries":["weather in Asheville, NC, United States"]}}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":61,"candidates_tokens_details":[{"modality":"TEXT","token_count":61}],"prompt_token_count":60,"prompt_tokens_details":[{"modality":"TEXT","token_count":60}],"total_token_count":121},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 07:26:25,464 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_Weather] Event ID: ztCUWXdv, Author: SearchLLMAgent
2025-05-08 07:26:25,464 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_Weather] Text response: The weather in Asheville, North Carolina, USA is currently 62F with passing clouds. The wind is blowing from the north at 7 mph. The humidity is 58%.

The forecast for the next 48 hours includes scat...
2025-05-08 07:26:25,464 - src.simulation_async - INFO - [WorldInfoGatherer] REAL weather search returned: The weather in Asheville, North Carolina, USA is currently 62F with passing clouds. The wind is blowing from the north at 7 mph. The humidity is 58%.

The forecast for the next 48 hours includes scattered clouds, sprinkles, overcast conditions and drizzle.
2025-05-08 07:26:25,469 - grpc._cython.cygrpc - DEBUG - Using AsyncIOEngine.POLLER as I/O engine
2025-05-08 07:26:26,082 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.weather = {'condition': 'Passing clouds', 'temperature_celsius': 17, 'forecast_short': 'Scattered clouds, sprinkles, overcast conditions and drizzle', 'timestamp': 9.969000000040978, 'source_category': 'weather'}
2025-05-08 07:26:26,082 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'world_news' with query: 'What are the latest top world news headlines (e.g., politics, social issues, environment, major international events)?'
2025-05-08 07:26:26,091 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:26,092 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:26,106 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9B19D0>
2025-05-08 07:26:26,106 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E426DD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:26,126 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9B10D0>
2025-05-08 07:26:26,126 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:26,126 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:26,127 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:26,127 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:26,127 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:27,673 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:29,383 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3245'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:29,383 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:29,383 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:29,384 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:29,384 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:29,384 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:29,385 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_world_news] Event ID: NtkwVrQ6, Author: SearchLLMAgent
2025-05-08 07:26:29,385 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_world_news] Text response: Here are some of the latest top world news headlines:

*   **Politics:**

    *   Trump is expected to announce a 'major trade deal' with the UK.
    *   The Bank of England is announcing its interest...
2025-05-08 07:26:29,385 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'world_news' returned: Here are some of the latest top world news headlines:

*   **Politics:**

    *   Trump is expected to announce a 'major trade deal' with the UK.
    *   The Bank of England is announcing its interest rate decision.
    *   Black smoke was seen pouring from the Sistine Chapel's chimney again, indicating no Pope has been elected yet.
*   **Social Issues:**

    *   Over 50 pro-Palestinian protesters were arrested at Columbia University.
    *   A trend of women being body-slammed by "bumping men"
2025-05-08 07:26:30,375 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'Global Tensions Rise Amid Trade Deals, Social Unrest, and Climate Concerns', 'summary': 'From potential US-UK trade deals and interest rate decisions to escalating India-Pakistan conflict, North Korean missile launches, and climate-intensified weather events, the world faces a complex mix of political, social, and environmental challenges.', 'timestamp': 9.969000000040978, 'source_category': 'world_news'}]
2025-05-08 07:26:30,375 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'regional_news' with query: 'What are the latest top national news headlines for United States?'
2025-05-08 07:26:30,383 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:30,385 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:30,412 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA2A330>
2025-05-08 07:26:30,412 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E4265D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:30,433 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA07E90>
2025-05-08 07:26:30,433 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:30,433 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:30,433 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:30,433 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:30,433 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:32,803 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:32,907 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2461'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:32,907 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:32,907 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:32,908 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:32,908 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:32,908 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:32,909 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_regional_news] Event ID: 8nAWwoPn, Author: SearchLLMAgent
2025-05-08 07:26:32,909 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_regional_news] Text response: Here are some of the latest top national news headlines for the United States:

*   **Politics:**

    *   Trump is planning to announce that the U.S. will call the Persian Gulf the Arabian Gulf.
    ...
2025-05-08 07:26:32,909 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'regional_news' returned: Here are some of the latest top national news headlines for the United States:

*   **Politics:**

    *   Trump is planning to announce that the U.S. will call the Persian Gulf the Arabian Gulf.
    *   The Trump administration has formally invoked state secrets privilege in the Abrego Garcia case.
*   **Social Issues:**

    *   Three former Memphis police officers were acquitted in the fatal beating of Tyre Nichols.
*   **Environment:**

    *   Climate change intensified deadly April rainfal
2025-05-08 07:26:33,392 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 19.6 (due at 19.5).
2025-05-08 07:26:33,392 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location = living_room
2025-05-08 07:26:33,392 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location_details = You have arrived in living_room.
2025-05-08 07:26:33,392 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:26:33,392 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:33,392 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:26:33,392 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:26:33,554 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:26:33,554 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:26:33,576 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:33,578 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:33,579 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'National News: Politics, Social Issues, Environment, and More', 'summary': "Trump's Gulf name change, Tyre Nichols case acquittal, climate change's role in Southern rainfall, and a lost fighter jet lead today's national news.", 'timestamp': 9.969000000040978, 'source_category': 'regional_news'}, {'headline': 'Global Tensions Rise Amid Trade Deals, Social Unrest, and Climate Concerns', 'summary': 'From potential US-UK trade deals and interest rate decisions to escalating India-Pakistan conflict, North Korean missile launches, and climate-intensified weather events, the world faces a complex mix of political, social, and environmental challenges.', 'timestamp': 9.969000000040978, 'source_category': 'world_news'}]
2025-05-08 07:26:33,579 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'local_news' with query: 'What are the top latest local news headlines for Asheville, NC?'
2025-05-08 07:26:33,590 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:33,592 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:33,602 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA05D00>
2025-05-08 07:26:33,602 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E7F1CD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:33,611 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9483E0>
2025-05-08 07:26:33,611 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E946550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:33,618 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E948620>
2025-05-08 07:26:33,618 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:33,619 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:33,619 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:33,619 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:33,619 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:33,629 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E71B860>
2025-05-08 07:26:33,629 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:33,629 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:33,629 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:33,630 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:33,630 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:34,654 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1027'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:34,655 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:34,655 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:34,655 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:34,655 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:34,656 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:34,656 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "The sunlight and scent of old books are nice. Now that I'm in the living room, I'll turn on the TV and see what's happening in the world. I should also probably make some break...'
2025-05-08 07:26:34,656 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "The sunlight and scent of old books are nice. Now that I'm in the living room, I'll turn on the TV and see what's happening in the world. I should also probably make some break...'
2025-05-08 07:26:34,656 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "The sunlight and scent of old books are nice. Now that I'm in the living room, I'll turn on the TV and see what's happening in the world. I should also probably make some break
2025-05-08 07:26:34,672 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:26:34,672 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on tv_4285) classified as 'environment'.
2025-05-08 07:26:34,672 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'tv_4285', 'details': 'turn on the TV'}
2025-05-08 07:26:34,672 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:26:34,696 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:34,698 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:34,728 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA28920>
2025-05-08 07:26:34,728 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E9886D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:34,745 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA280B0>
2025-05-08 07:26:34,746 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:34,746 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:34,746 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:34,746 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:34,746 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:35,468 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=713'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:35,468 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:35,468 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:35,469 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:35,469 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:35,469 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:35,470 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 3.0, "results": {"objects.tv_4285.power": "on"}, "outcome...
2025-05-08 07:26:35,470 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 3.0, "results": {"objects.tv_4285.power": "on"}, "outcome_description": "The TV turned on."}...'
2025-05-08 07:26:35,470 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 3.0, "results": {"objects.tv_4285.power": "on"}, "outcome_description": "The TV turned on."}...'
2025-05-08 07:26:35,470 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 3.0, 'results': {'objects.tv_4285.power': 'on'}, 'outcome_description': 'The TV turned on.'}
2025-05-08 07:26:35,470 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:26:35,480 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:26:35,480 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'objects.tv_4285.power': 'on'}
2025-05-08 07:26:35,481 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 23.766000000061467
2025-05-08 07:26:35,481 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: turn on the TV
2025-05-08 07:26:35,481 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 23.8s. Outcome: The TV turned on.
2025-05-08 07:26:35,481 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location living_room
2025-05-08 07:26:35,481 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'The TV turned on.'
2025-05-08 07:26:35,502 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:35,503 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:35,533 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA2A000>
2025-05-08 07:26:35,533 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E946250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:35,551 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA29DF0>
2025-05-08 07:26:35,551 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:35,551 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:35,551 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:35,551 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:35,552 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:36,160 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2521'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:36,160 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:36,161 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:36,161 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:36,162 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:36,162 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:36,162 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_local_news] Event ID: P4OybRQM, Author: SearchLLMAgent
2025-05-08 07:26:36,162 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_local_news] Text response: Here are some of the latest local news headlines for Asheville, NC:

*   **Hurricane Helene Recovery:** The community is still recovering from Hurricane Helene, with ongoing efforts to remove debris a...
2025-05-08 07:26:36,162 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'local_news' returned: Here are some of the latest local news headlines for Asheville, NC:

*   **Hurricane Helene Recovery:** The community is still recovering from Hurricane Helene, with ongoing efforts to remove debris and provide aid.
*   **Buncombe County News:**

    *   Buncombe County is reducing some permit fees.
    *   Property tax rates could increase in Buncombe County.
    *   The unemployment rate in Buncombe County fell to 5.3% in March but is still among the highest in the state.
*   **Asheville Beer 
2025-05-08 07:26:36,847 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'Asheville Area News: Helene Recovery, Tax Talk, and Beer Week', 'summary': 'Asheville and Buncombe County are focused on Hurricane Helene recovery, potential property tax increases, and the upcoming Asheville Beer Week, alongside updates on crime and local government.', 'timestamp': 9.969000000040978, 'source_category': 'local_news'}, {'headline': 'National News: Politics, Social Issues, Environment, and More', 'summary': "Trump's Gulf name change, Tyre Nichols case acquittal, climate change's role in Southern rainfall, and a lost fighter jet lead today's national news.", 'timestamp': 9.969000000040978, 'source_category': 'regional_news'}, {'headline': 'Global Tensions Rise Amid Trade Deals, Social Unrest, and Climate Concerns', 'summary': 'From potential US-UK trade deals and interest rate decisions to escalating India-Pakistan conflict, North Korean missile launches, and climate-intensified weather events, the world faces a complex mix of political, social, and environmental challenges.', 'timestamp': 9.969000000040978, 'source_category': 'world_news'}]
2025-05-08 07:26:36,847 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'pop_culture' with query: 'What are the top latest United States  pop culture trends and entertainment news headlines (e.g., movies, music, viral trends)?'
2025-05-08 07:26:36,856 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:36,859 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:36,875 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA39760>
2025-05-08 07:26:36,875 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410EA2F1D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:36,893 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA3A6F0>
2025-05-08 07:26:36,893 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:36,893 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:36,893 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:36,893 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:36,893 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:36,969 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:26:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1408'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:36,969 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:36,969 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:36,970 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:36,970 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:36,970 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:36,971 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor reaches for the remote on the coffee table and clicks the power bu...
2025-05-08 07:26:36,971 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor reaches for the remote on the coffee table and clicks the power button. The TV flickers to life, filling the room with the bright colors and cacophony of a morning news progr...'
2025-05-08 07:26:36,971 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor reaches for the remote on the coffee table and clicks the power button. The TV flickers to life, filling the room with the bright colors and cacophony of a morning news progr...'
2025-05-08 07:26:36,971 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor reaches for the remote on the coffee table and clicks the power button. The TV flickers to life, filling the room with the bright colors and cacophony of a morning news program.
2025-05-08 07:26:36,977 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor reaches for the remote on the coffee table and clicks the power button. The TV flickers to life, filling the room with the bright colors and cacophony of a morning news program. A perky anchor (npc_concept_news_anchor_01) is just launching into a segment about the city's upcoming marathon, her smile unwavering even as the chyron scrolls across the bottom of the screen with details of a recent traffic accident downtown.
2025-05-08 07:26:36,977 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor reaches for the remote on the coffee table and clicks the power button. ...
2025-05-08 07:26:37,635 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 23.8 (due at 23.8).
2025-05-08 07:26:37,636 - src.simulation_async - WARNING - Path segment 'objects' not found or not dict in 'objects.tv_4285.power'. Creating.
2025-05-08 07:26:37,636 - src.simulation_async - WARNING - Path segment 'tv_4285' not found or not dict in 'objects.tv_4285.power'. Creating.
2025-05-08 07:26:37,636 - src.simulation_async - INFO - [StateUpdate] Applied: objects.tv_4285.power = on
2025-05-08 07:26:37,636 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:26:37,636 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:37,636 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:26:37,636 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:26:37,708 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:26:37,708 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:26:37,733 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:37,736 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:37,750 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA2B950>
2025-05-08 07:26:37,750 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E946250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:37,768 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA29640>
2025-05-08 07:26:37,769 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:37,769 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:37,769 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:37,769 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:37,769 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:38,795 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1012'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:38,795 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:38,795 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:38,796 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:38,796 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:38,796 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:38,796 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, the news is on. A marathon and a traffic accident... typical city life. I should probably make some breakfast. I'm not really interested in the news anchor. I'll head bac...'
2025-05-08 07:26:38,797 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, the news is on. A marathon and a traffic accident... typical city life. I should probably make some breakfast. I'm not really interested in the news anchor. I'll head bac...'
2025-05-08 07:26:38,797 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, the news is on. A marathon and a traffic accident... typical city life. I should probably make some breakfast. I'm not really interested in the news anchor. I'll head bac
2025-05-08 07:26:38,814 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:26:38,814 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 07:26:38,814 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'back to the kitchen'}
2025-05-08 07:26:38,814 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 07:26:38,839 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:38,841 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:38,851 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA2A810>
2025-05-08 07:26:38,852 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E98B250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:38,867 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA280B0>
2025-05-08 07:26:38,867 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:38,868 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:38,868 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:38,868 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:38,868 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:39,582 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=707'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:39,583 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:39,583 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:39,583 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:39,583 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:39,583 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:39,584 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 15.0, "results": {"simulacra_profiles.sim_3e912d.location...
2025-05-08 07:26:39,584 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 15.0, "results": {"simulacra_profiles.sim_3e912d.location": "kitchen"}, "outcome_description": "Eleanor Hayes moved back to the kitchen."}...'
2025-05-08 07:26:39,584 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 15.0, "results": {"simulacra_profiles.sim_3e912d.location": "kitchen"}, "outcome_description": "Eleanor Hayes moved back to the kitchen."}...'
2025-05-08 07:26:39,584 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 15.0, 'results': {'simulacra_profiles.sim_3e912d.location': 'kitchen'}, 'outcome_description': 'Eleanor Hayes moved back to the kitchen.'}
2025-05-08 07:26:39,584 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:26:39,602 - src.simulation_async - INFO - [WorldEngineLLM] Queuing update for sim_3e912d's location_details to: 'You have arrived in kitchen.'
2025-05-08 07:26:39,602 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:26:39,602 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.location': 'kitchen', 'simulacra_profiles.sim_3e912d.location_details': 'You have arrived in kitchen.'}
2025-05-08 07:26:39,602 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 39.90600000019185
2025-05-08 07:26:39,602 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: back to the kitchen
2025-05-08 07:26:39,602 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 39.9s. Outcome: Eleanor Hayes moved back to the kitchen.
2025-05-08 07:26:39,602 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location living_room
2025-05-08 07:26:39,602 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes moved back to the kitchen.'
2025-05-08 07:26:39,625 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:39,628 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:39,641 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA3B4D0>
2025-05-08 07:26:39,642 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410EA2D850> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:39,662 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA3A3F0>
2025-05-08 07:26:39,662 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:39,663 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:39,663 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:39,663 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:39,663 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:40,737 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1063'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:40,738 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:40,738 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:40,738 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:40,738 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:40,738 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:40,739 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor pads back into the kitchen, the sudden quiet a stark contrast to t...
2025-05-08 07:26:40,739 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor pads back into the kitchen, the sudden quiet a stark contrast to the blaring TV. The sunlight catches the dust motes in the air, illuminating the familiar, slightly cluttered...'
2025-05-08 07:26:40,739 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor pads back into the kitchen, the sudden quiet a stark contrast to the blaring TV. The sunlight catches the dust motes in the air, illuminating the familiar, slightly cluttered...'
2025-05-08 07:26:40,739 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor pads back into the kitchen, the sudden quiet a stark contrast to the blaring TV. The sunlight catches the dust motes in the air, illuminating the familiar, slightly cluttered sp
2025-05-08 07:26:40,745 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor pads back into the kitchen, the sudden quiet a stark contrast to the blaring TV. The sunlight catches the dust motes in the air, illuminating the familiar, slightly cluttered space. The faint aroma of last night's dinner still lingers, a reminder of the meal she'd enjoyed before settling in with a book.
2025-05-08 07:26:40,745 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor pads back into the kitchen, the sudden quiet a stark contrast to the bla...
2025-05-08 07:26:40,826 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3924'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:40,827 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:40,827 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:40,828 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:40,828 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:40,828 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:40,829 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_pop_culture] Event ID: 0thCYaLN, Author: SearchLLMAgent
2025-05-08 07:26:40,829 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_pop_culture] Text response: Here are some of the latest pop culture and entertainment headlines in the United States:

*   **Music:**

    *   Kacey Musgraves defends traditional country music.
    *   Country music star Alana S...
2025-05-08 07:26:40,829 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'pop_culture' returned: Here are some of the latest pop culture and entertainment headlines in the United States:

*   **Music:**

    *   Kacey Musgraves defends traditional country music.
    *   Country music star Alana Springsteen credits Keith Urban with changing her life as a child.
*   **Television:**

    *   Bravo renews 9 TV shows and announces 4 new shows, including "The Valley" spinoff and a new "Real Housewives" city.
    *   Golden Globes to add a "Best Podcast" category for the 2026 awards show.
    *   
2025-05-08 07:26:41,477 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.pop_culture_updates = [{'headline': 'Pop Culture Buzz: Music, TV, Movies & Celebs!', 'summary': 'From music feuds to TV renewals, movie tariffs to celebrity drama, the entertainment world is buzzing with news.', 'timestamp': 9.969000000040978, 'source_category': 'pop_culture'}]
2025-05-08 07:26:41,477 - src.simulation_async - INFO - [WorldInfoGatherer] World feeds updated. Next check in 3600.0 sim_seconds.
2025-05-08 07:26:43,051 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:48,186 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:53,309 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:53,745 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 39.9 (due at 39.9).
2025-05-08 07:26:53,745 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location = kitchen
2025-05-08 07:26:53,745 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location_details = You have arrived in kitchen.
2025-05-08 07:26:53,745 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:26:53,745 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:26:53,745 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:26:53,745 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:26:54,072 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:26:54,072 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:26:54,095 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:54,098 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:54,112 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA391C0>
2025-05-08 07:26:54,112 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E7F3B50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:54,127 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA2A450>
2025-05-08 07:26:54,127 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:54,128 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:54,128 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:54,128 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:54,128 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:55,113 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:16 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=976'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:55,113 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:55,113 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:55,113 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:55,113 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:55,114 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:55,114 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Alright, back in the kitchen. Time for breakfast. I'm not feeling particularly inspired, so I'll probably just have some toast and coffee. First, I need to get the bread out of...'
2025-05-08 07:26:55,114 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Alright, back in the kitchen. Time for breakfast. I'm not feeling particularly inspired, so I'll probably just have some toast and coffee. First, I need to get the bread out of...'
2025-05-08 07:26:55,114 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Alright, back in the kitchen. Time for breakfast. I'm not feeling particularly inspired, so I'll probably just have some toast and coffee. First, I need to get the bread out of
2025-05-08 07:26:55,131 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:26:55,131 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on breadbox_7890) classified as 'environment'.
2025-05-08 07:26:55,131 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'breadbox_7890', 'details': 'get bread from the breadbox'}
2025-05-08 07:26:55,131 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:26:55,159 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:55,162 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:55,174 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E802660>
2025-05-08 07:26:55,174 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F0BA550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:55,195 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E803740>
2025-05-08 07:26:55,196 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:55,196 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:55,196 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:55,196 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:55,196 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:55,881 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:17 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=674'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:55,881 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:55,881 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:55,881 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:55,881 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:55,882 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:55,882 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:26:55,882 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes got bread from the breadbox."}...'
2025-05-08 07:26:55,882 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes got bread from the breadbox."}...'
2025-05-08 07:26:55,883 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {}, 'outcome_description': 'Eleanor Hayes got bread from the breadbox.'}
2025-05-08 07:26:55,883 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:26:55,894 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:26:55,894 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:26:55,894 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 46.235000000102445
2025-05-08 07:26:55,894 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: get bread from the breadbox
2025-05-08 07:26:55,894 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 46.2s. Outcome: Eleanor Hayes got bread from the breadbox.
2025-05-08 07:26:55,894 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:26:55,894 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes got bread from the breadbox.'
2025-05-08 07:26:55,920 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:26:55,923 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:26:55,932 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA064E0>
2025-05-08 07:26:55,932 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E945750> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:26:55,951 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA28E60>
2025-05-08 07:26:55,952 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:26:55,952 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:26:55,952 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:26:55,952 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:26:55,952 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:26:57,292 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1330'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:26:57,292 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:26:57,292 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:26:57,293 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:26:57,293 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:26:57,293 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:26:57,293 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor opens the old, slightly dented breadbox (breadbox_7890) on the cou...
2025-05-08 07:26:57,294 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor opens the old, slightly dented breadbox (breadbox_7890) on the counter. Inside, nestled among the crumbs, is a half-eaten loaf of sourdough. She pulls out two slices, the yea...'
2025-05-08 07:26:57,294 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor opens the old, slightly dented breadbox (breadbox_7890) on the counter. Inside, nestled among the crumbs, is a half-eaten loaf of sourdough. She pulls out two slices, the yea...'
2025-05-08 07:26:57,294 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor opens the old, slightly dented breadbox (breadbox_7890) on the counter. Inside, nestled among the crumbs, is a half-eaten loaf of sourdough. She pulls out two slices, the yeasty
2025-05-08 07:26:57,300 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor opens the old, slightly dented breadbox (breadbox_7890) on the counter. Inside, nestled among the crumbs, is a half-eaten loaf of sourdough. She pulls out two slices, the yeasty scent filling the air. A small, handwritten note (note_breadbox_01) is tucked beside the bread; a reminder from herself to buy more groceries.
2025-05-08 07:26:57,300 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor opens the old, slightly dented breadbox (breadbox_7890) on the counter. ...
2025-05-08 07:26:58,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:00,046 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 46.2 (due at 46.2).
2025-05-08 07:27:00,046 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:27:00,046 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:00,046 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:27:00,046 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:27:00,201 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:27:00,201 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:27:00,224 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:00,228 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:00,238 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA064E0>
2025-05-08 07:27:00,238 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F08BDD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:00,255 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA3B410>
2025-05-08 07:27:00,256 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:00,256 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:00,256 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:00,256 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:00,256 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:01,408 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1142'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:01,408 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:01,408 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:01,409 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:01,409 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:01,409 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:01,410 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Sourdough... not my favorite, but it will do. Oh, and a reminder to buy groceries. I really should do that today. Maybe after breakfast. Okay, time to put the bread in the toas...'
2025-05-08 07:27:01,410 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Sourdough... not my favorite, but it will do. Oh, and a reminder to buy groceries. I really should do that today. Maybe after breakfast. Okay, time to put the bread in the toas...'
2025-05-08 07:27:01,410 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Sourdough... not my favorite, but it will do. Oh, and a reminder to buy groceries. I really should do that today. Maybe after breakfast. Okay, time to put the bread in the toas
2025-05-08 07:27:01,426 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:27:01,426 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on toaster_1234) classified as 'environment'.
2025-05-08 07:27:01,426 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'toaster_1234', 'details': 'put bread in the toaster'}
2025-05-08 07:27:01,426 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:27:01,449 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:01,452 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:01,465 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B1C40>
2025-05-08 07:27:01,466 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410EA2FCD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:01,484 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B1CD0>
2025-05-08 07:27:01,484 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:01,485 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:01,485 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:01,485 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:01,485 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:02,149 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=657'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:02,149 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:02,149 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:02,150 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:02,150 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:02,151 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:02,151 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:27:02,151 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes put bread in the toaster."}...'
2025-05-08 07:27:02,151 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes put bread in the toaster."}...'
2025-05-08 07:27:02,151 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {}, 'outcome_description': 'Eleanor Hayes put bread in the toaster.'}
2025-05-08 07:27:02,151 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:27:02,163 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:27:02,163 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:27:02,163 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 52.59400000004098
2025-05-08 07:27:02,163 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: put bread in the toaster
2025-05-08 07:27:02,163 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 52.6s. Outcome: Eleanor Hayes put bread in the toaster.
2025-05-08 07:27:02,163 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:27:02,163 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes put bread in the toaster.'
2025-05-08 07:27:02,186 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:02,190 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:02,202 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA064E0>
2025-05-08 07:27:02,202 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E7F2250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:02,220 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9793D0>
2025-05-08 07:27:02,220 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:02,221 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:02,221 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:02,221 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:02,221 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:03,351 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1120'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:03,351 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:03,351 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:03,352 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:03,352 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:03,352 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:03,353 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor slides the two slices of sourdough into the slots of the waiting t...
2025-05-08 07:27:03,353 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor slides the two slices of sourdough into the slots of the waiting toaster (toaster_1234). With a satisfying 'clunk', the lever is pushed down, and the heating elements begin t...'
2025-05-08 07:27:03,353 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor slides the two slices of sourdough into the slots of the waiting toaster (toaster_1234). With a satisfying 'clunk', the lever is pushed down, and the heating elements begin t...'
2025-05-08 07:27:03,353 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor slides the two slices of sourdough into the slots of the waiting toaster (toaster_1234). With a satisfying 'clunk', the lever is pushed down, and the heating elements begin to g
2025-05-08 07:27:03,359 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor slides the two slices of sourdough into the slots of the waiting toaster (toaster_1234). With a satisfying 'clunk', the lever is pushed down, and the heating elements begin to glow with an orange hue. She can already smell the faint, biscuity aroma of the bread as it starts to toast.
2025-05-08 07:27:03,359 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor slides the two slices of sourdough into the slots of the waiting toaster...
2025-05-08 07:27:03,543 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:06,461 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 52.6 (due at 52.6).
2025-05-08 07:27:06,461 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:27:06,461 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:06,461 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:27:06,461 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:27:06,538 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:27:06,538 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:27:06,568 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:06,572 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:06,581 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA38A70>
2025-05-08 07:27:06,581 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E7F1D50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:06,600 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA3A6C0>
2025-05-08 07:27:06,600 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:06,600 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:06,600 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:06,600 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:06,600 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:07,611 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1003'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:07,611 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:07,611 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:07,612 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:07,612 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:07,612 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:07,613 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Perfect. Now, while the toast is toasting, I'll put on the coffee. I definitely need some caffeine to get my day started. I'll use the coffee maker.", "action_type": "use", "ta...'
2025-05-08 07:27:07,613 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Perfect. Now, while the toast is toasting, I'll put on the coffee. I definitely need some caffeine to get my day started. I'll use the coffee maker.", "action_type": "use", "ta...'
2025-05-08 07:27:07,613 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Perfect. Now, while the toast is toasting, I'll put on the coffee. I definitely need some caffeine to get my day started. I'll use the coffee maker.", 'action_type': 'use', 'ta
2025-05-08 07:27:07,630 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:27:07,630 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on coffee_maker_5678) classified as 'environment'.
2025-05-08 07:27:07,631 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'coffee_maker_5678', 'details': 'start the coffee maker'}
2025-05-08 07:27:07,631 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:27:07,657 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:07,661 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:07,674 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0C3410>
2025-05-08 07:27:07,674 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F0881D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:07,692 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0C1520>
2025-05-08 07:27:07,692 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:07,692 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:07,692 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:07,692 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:07,692 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:08,415 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:30 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=714'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:08,416 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:08,416 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:08,421 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:08,422 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:08,422 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:08,423 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {"objects.coffee_maker_5678.status": "br...
2025-05-08 07:27:08,423 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 10.0, "results": {"objects.coffee_maker_5678.status": "brewing"}, "outcome_description": "The coffee maker started brewing."}...'
2025-05-08 07:27:08,423 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 10.0, "results": {"objects.coffee_maker_5678.status": "brewing"}, "outcome_description": "The coffee maker started brewing."}...'
2025-05-08 07:27:08,423 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 10.0, 'results': {'objects.coffee_maker_5678.status': 'brewing'}, 'outcome_description': 'The coffee maker started brewing.'}
2025-05-08 07:27:08,423 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:27:08,434 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:27:08,434 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'objects.coffee_maker_5678.status': 'brewing'}
2025-05-08 07:27:08,434 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 63.735000000102445
2025-05-08 07:27:08,434 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: start the coffee maker
2025-05-08 07:27:08,434 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 63.7s. Outcome: The coffee maker started brewing.
2025-05-08 07:27:08,434 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:27:08,434 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'The coffee maker started brewing.'
2025-05-08 07:27:08,458 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:08,462 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:08,475 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B3830>
2025-05-08 07:27:08,476 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E7F2F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:08,492 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B2AB0>
2025-05-08 07:27:08,492 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:08,493 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:08,493 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:08,493 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:08,493 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:08,665 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:09,698 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1197'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:09,698 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:09,698 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:09,699 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:09,699 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:09,699 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:09,700 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor fills the coffee maker (coffee_maker_5678) with water and scoops i...
2025-05-08 07:27:09,700 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor fills the coffee maker (coffee_maker_5678) with water and scoops in a generous amount of ground coffee. The familiar ritual is comforting, a small, predictable act in the fac...'
2025-05-08 07:27:09,700 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor fills the coffee maker (coffee_maker_5678) with water and scoops in a generous amount of ground coffee. The familiar ritual is comforting, a small, predictable act in the fac...'
2025-05-08 07:27:09,700 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor fills the coffee maker (coffee_maker_5678) with water and scoops in a generous amount of ground coffee. The familiar ritual is comforting, a small, predictable act in the face o
2025-05-08 07:27:09,706 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor fills the coffee maker (coffee_maker_5678) with water and scoops in a generous amount of ground coffee. The familiar ritual is comforting, a small, predictable act in the face of an unpredictable day. She presses the 'on' button, and the machine sputters to life, filling the kitchen with the rich, dark scent of brewing coffee.
2025-05-08 07:27:09,706 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor fills the coffee maker (coffee_maker_5678) with water and scoops in a ge...
2025-05-08 07:27:13,771 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:17,560 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 63.8 (due at 63.7).
2025-05-08 07:27:17,560 - src.simulation_async - WARNING - Path segment 'coffee_maker_5678' not found or not dict in 'objects.coffee_maker_5678.status'. Creating.
2025-05-08 07:27:17,561 - src.simulation_async - INFO - [StateUpdate] Applied: objects.coffee_maker_5678.status = brewing
2025-05-08 07:27:17,561 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:27:17,561 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:17,561 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:27:17,561 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:27:17,768 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:27:17,768 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:27:17,791 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:17,795 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:17,805 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B35C0>
2025-05-08 07:27:17,805 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E7F2250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:17,823 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0C16D0>
2025-05-08 07:27:17,823 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:17,824 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:17,824 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:17,824 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:17,824 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:18,649 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=814'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:18,649 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:18,649 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:18,649 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:18,649 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:18,649 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:18,651 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Ah, the smell of coffee... that's more like it. Now that the coffee is brewing and the toast is toasting, I should probably get a mug and some butter. I'll grab them from the c...'
2025-05-08 07:27:18,651 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Ah, the smell of coffee... that's more like it. Now that the coffee is brewing and the toast is toasting, I should probably get a mug and some butter. I'll grab them from the c...'
2025-05-08 07:27:18,651 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Ah, the smell of coffee... that's more like it. Now that the coffee is brewing and the toast is toasting, I should probably get a mug and some butter. I'll grab them from the c
2025-05-08 07:27:18,668 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:27:18,668 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on cupboard_9012) classified as 'environment'.
2025-05-08 07:27:18,668 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'cupboard_9012', 'details': 'get a mug and butter from the cupboard'}
2025-05-08 07:27:18,668 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:27:18,691 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:18,695 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:18,706 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9B3320>
2025-05-08 07:27:18,706 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E946150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:18,728 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E801490>
2025-05-08 07:27:18,728 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:18,728 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:18,728 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:18,728 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:18,728 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:19,407 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=668'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:19,407 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:19,408 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:19,408 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:19,408 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:19,408 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:19,409 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 7.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:27:19,409 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 7.0, "results": {}, "outcome_description": "Eleanor Hayes got a mug and butter from the cupboard."}...'
2025-05-08 07:27:19,409 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 7.0, "results": {}, "outcome_description": "Eleanor Hayes got a mug and butter from the cupboard."}...'
2025-05-08 07:27:19,409 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 7.0, 'results': {}, 'outcome_description': 'Eleanor Hayes got a mug and butter from the cupboard.'}
2025-05-08 07:27:19,409 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:27:19,420 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:27:19,420 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:27:19,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 71.82800000021234
2025-05-08 07:27:19,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: get a mug and butter from the cupboard
2025-05-08 07:27:19,421 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 71.8s. Outcome: Eleanor Hayes got a mug and butter from the cupboard.
2025-05-08 07:27:19,421 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:27:19,421 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes got a mug and butter from the cupboard.'
2025-05-08 07:27:19,445 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:19,449 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:19,461 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B3830>
2025-05-08 07:27:19,461 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F11DAD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:19,481 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA06B70>
2025-05-08 07:27:19,481 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:19,482 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:19,482 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:19,482 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:19,482 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:20,573 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1080'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:20,573 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:20,573 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:20,575 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:20,575 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:20,575 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:20,576 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor opens the slightly sticky cupboard (cupboard_9012) above the count...
2025-05-08 07:27:20,576 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor opens the slightly sticky cupboard (cupboard_9012) above the counter. Inside, a jumble of mismatched mugs and dishes are stacked haphazardly. She grabs her favorite, a slight...'
2025-05-08 07:27:20,576 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor opens the slightly sticky cupboard (cupboard_9012) above the counter. Inside, a jumble of mismatched mugs and dishes are stacked haphazardly. She grabs her favorite, a slight...'
2025-05-08 07:27:20,576 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor opens the slightly sticky cupboard (cupboard_9012) above the counter. Inside, a jumble of mismatched mugs and dishes are stacked haphazardly. She grabs her favorite, a slightly 
2025-05-08 07:27:20,582 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor opens the slightly sticky cupboard (cupboard_9012) above the counter. Inside, a jumble of mismatched mugs and dishes are stacked haphazardly. She grabs her favorite, a slightly chipped mug with a faded blue floral pattern. From the same cupboard, she also retrieves a small tub of butter, its plastic lid slightly askew.
2025-05-08 07:27:20,582 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor opens the slightly sticky cupboard (cupboard_9012) above the counter. In...
2025-05-08 07:27:24,023 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:25,653 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 71.8 (due at 71.8).
2025-05-08 07:27:25,653 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:27:25,653 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:25,653 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:27:25,653 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:27:25,730 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:27:25,730 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:27:25,755 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:25,760 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:25,771 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B2990>
2025-05-08 07:27:25,771 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E988350> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:25,789 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1242F0>
2025-05-08 07:27:25,789 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:25,790 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:25,790 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:25,790 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:25,790 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:26,894 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1095'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:26,894 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:26,894 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:26,894 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:26,895 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:26,895 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:26,895 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "My favorite mug... good choice, past Eleanor. Okay, now to wait for the toast to pop and the coffee to finish brewing. I'll just stand here for a moment and enjoy the smells. M...'
2025-05-08 07:27:26,895 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "My favorite mug... good choice, past Eleanor. Okay, now to wait for the toast to pop and the coffee to finish brewing. I'll just stand here for a moment and enjoy the smells. M...'
2025-05-08 07:27:26,896 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "My favorite mug... good choice, past Eleanor. Okay, now to wait for the toast to pop and the coffee to finish brewing. I'll just stand here for a moment and enjoy the smells. M
2025-05-08 07:27:26,920 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:27:26,920 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (wait on N/A) classified as 'environment'.
2025-05-08 07:27:26,920 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'wait', 'target_id': None, 'details': 'waiting for the toast and coffee'}
2025-05-08 07:27:26,920 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (wait).
2025-05-08 07:27:26,942 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:26,947 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:26,961 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0C2960>
2025-05-08 07:27:26,961 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F11EBD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:26,978 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E94A720>
2025-05-08 07:27:26,978 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:26,978 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:26,978 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:26,978 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:26,978 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:27,612 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=625'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:27,612 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:27,612 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:27,613 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:27,613 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:27,613 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:27,614 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 15.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-08 07:27:27,614 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 15.0, "results": {}, "outcome_description": "Eleanor Hayes waited for the toast and coffee."}...'
2025-05-08 07:27:27,614 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 15.0, "results": {}, "outcome_description": "Eleanor Hayes waited for the toast and coffee."}...'
2025-05-08 07:27:27,614 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 15.0, 'results': {}, 'outcome_description': 'Eleanor Hayes waited for the toast and coffee.'}
2025-05-08 07:27:27,614 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:27:27,626 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:27:27,626 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:27:27,626 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 88.03100000019185
2025-05-08 07:27:27,626 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: wait - Details: waiting for the toast and coffee
2025-05-08 07:27:27,626 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 88.0s. Outcome: Eleanor Hayes waited for the toast and coffee.
2025-05-08 07:27:27,626 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:27:27,626 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes waited for the toast and coffee.'
2025-05-08 07:27:27,652 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:27,658 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:27,670 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B0EF0>
2025-05-08 07:27:27,671 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F11D8D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:27,689 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9B0440>
2025-05-08 07:27:27,689 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:27,690 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:27,690 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:27,690 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:27,690 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:28,843 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:27:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1143'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:28,843 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:28,843 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:28,843 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:28,844 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:28,844 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:28,845 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor leans against the counter, the gentle warmth of the brewing coffee...
2025-05-08 07:27:28,845 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor leans against the counter, the gentle warmth of the brewing coffee and toasting bread filling the small kitchen. The rhythmic gurgle of the coffee maker blends with the soft ...'
2025-05-08 07:27:28,845 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor leans against the counter, the gentle warmth of the brewing coffee and toasting bread filling the small kitchen. The rhythmic gurgle of the coffee maker blends with the soft ...'
2025-05-08 07:27:28,845 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor leans against the counter, the gentle warmth of the brewing coffee and toasting bread filling the small kitchen. The rhythmic gurgle of the coffee maker blends with the soft tic
2025-05-08 07:27:28,852 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor leans against the counter, the gentle warmth of the brewing coffee and toasting bread filling the small kitchen. The rhythmic gurgle of the coffee maker blends with the soft ticking of the clock on the wall, creating a comforting symphony of domesticity. She closes her eyes for a moment, letting the familiar scents wash over her, a brief respite before the day truly begins.
2025-05-08 07:27:28,852 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor leans against the counter, the gentle warmth of the brewing coffee and t...
2025-05-08 07:27:29,132 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:34,238 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:39,349 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:41,943 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 88.1 (due at 88.0).
2025-05-08 07:27:41,943 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:27:41,943 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:41,943 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:27:41,943 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:27:42,159 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:27:42,159 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:27:42,184 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:42,189 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:42,205 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA3BEF0>
2025-05-08 07:27:42,205 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F11C5D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:42,223 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B00E0>
2025-05-08 07:27:42,223 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:42,224 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:42,224 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:42,224 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:42,224 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:43,252 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:05 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1019'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:43,252 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:43,252 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:43,252 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:43,252 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:43,252 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:43,253 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "That was a nice moment of peace. Okay, I think I hear the toaster popping. Time to get my breakfast ready. First the toast, then the coffee. I'll grab a plate from the dish rac...'
2025-05-08 07:27:43,253 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "That was a nice moment of peace. Okay, I think I hear the toaster popping. Time to get my breakfast ready. First the toast, then the coffee. I'll grab a plate from the dish rac...'
2025-05-08 07:27:43,253 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "That was a nice moment of peace. Okay, I think I hear the toaster popping. Time to get my breakfast ready. First the toast, then the coffee. I'll grab a plate from the dish rac
2025-05-08 07:27:43,271 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:27:43,271 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on dish_rack_3456) classified as 'environment'.
2025-05-08 07:27:43,271 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'dish_rack_3456', 'details': 'get a plate from the dish rack'}
2025-05-08 07:27:43,271 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:27:43,293 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:43,298 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:43,312 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA2A810>
2025-05-08 07:27:43,312 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E98B850> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:43,329 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97B290>
2025-05-08 07:27:43,329 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:43,329 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:43,329 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:43,329 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:43,329 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:43,996 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:05 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=658'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:43,997 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:43,997 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:43,997 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:43,997 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:43,998 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:43,998 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 4.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:27:43,998 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 4.0, "results": {}, "outcome_description": "Eleanor Hayes got a plate from the dish rack."}...'
2025-05-08 07:27:43,999 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 4.0, "results": {}, "outcome_description": "Eleanor Hayes got a plate from the dish rack."}...'
2025-05-08 07:27:43,999 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 4.0, 'results': {}, 'outcome_description': 'Eleanor Hayes got a plate from the dish rack.'}
2025-05-08 07:27:43,999 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:27:44,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:27:44,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:27:44,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 93.43800000008196
2025-05-08 07:27:44,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: get a plate from the dish rack
2025-05-08 07:27:44,011 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 93.4s. Outcome: Eleanor Hayes got a plate from the dish rack.
2025-05-08 07:27:44,011 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:27:44,011 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes got a plate from the dish rack.'
2025-05-08 07:27:44,037 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:44,042 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:44,052 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA29190>
2025-05-08 07:27:44,052 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F0BAA50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:44,068 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1257C0>
2025-05-08 07:27:44,068 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:44,068 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:44,068 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:44,068 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:44,068 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:44,466 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:45,279 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:07 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1201'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:45,279 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:45,280 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:45,280 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:45,280 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:45,280 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:45,281 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor reaches for the dish rack (dish_rack_3456) beside the sink, its wi...
2025-05-08 07:27:45,281 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor reaches for the dish rack (dish_rack_3456) beside the sink, its wire frame slightly wobbly. She carefully selects a clean, white plate, still slightly warm from the residual ...'
2025-05-08 07:27:45,281 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor reaches for the dish rack (dish_rack_3456) beside the sink, its wire frame slightly wobbly. She carefully selects a clean, white plate, still slightly warm from the residual ...'
2025-05-08 07:27:45,281 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor reaches for the dish rack (dish_rack_3456) beside the sink, its wire frame slightly wobbly. She carefully selects a clean, white plate, still slightly warm from the residual hea
2025-05-08 07:27:45,287 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor reaches for the dish rack (dish_rack_3456) beside the sink, its wire frame slightly wobbly. She carefully selects a clean, white plate, still slightly warm from the residual heat of the drying dishes. A drop of water clings precariously to the edge, shimmering in the morning light before finally falling back into the sink with a quiet 'plink'.
2025-05-08 07:27:45,287 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor reaches for the dish rack (dish_rack_3456) beside the sink, its wire fra...
2025-05-08 07:27:47,321 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 93.5 (due at 93.4).
2025-05-08 07:27:47,321 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:27:47,321 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:47,321 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:27:47,321 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:27:47,368 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:27:47,368 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:27:47,392 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:47,398 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:47,411 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97A690>
2025-05-08 07:27:47,411 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F0B81D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:47,430 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97AFF0>
2025-05-08 07:27:47,430 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:47,430 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:47,430 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:47,430 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:47,430 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:48,254 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:10 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=810'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:48,255 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:48,255 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:48,255 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:48,256 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:48,256 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:48,256 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, plate acquired. Now to get the toast out of the toaster. I hope it's not too burnt.", "action_type": "use", "target_id": "toaster_1234", "details": "get the toast from th...'
2025-05-08 07:27:48,257 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, plate acquired. Now to get the toast out of the toaster. I hope it's not too burnt.", "action_type": "use", "target_id": "toaster_1234", "details": "get the toast from th...'
2025-05-08 07:27:48,257 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, plate acquired. Now to get the toast out of the toaster. I hope it's not too burnt.", 'action_type': 'use', 'target_id': 'toaster_1234', 'details': 'get the toast from th
2025-05-08 07:27:48,274 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:27:48,274 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on toaster_1234) classified as 'environment'.
2025-05-08 07:27:48,274 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'toaster_1234', 'details': 'get the toast from the toaster'}
2025-05-08 07:27:48,274 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:27:48,298 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:48,303 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:48,317 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9787A0>
2025-05-08 07:27:48,317 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F0B9850> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:48,335 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97A3F0>
2025-05-08 07:27:48,335 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:48,335 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:48,335 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:48,336 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:48,336 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:48,998 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:10 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=654'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:48,998 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:48,998 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:48,998 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:48,999 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:48,999 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:48,999 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:27:48,999 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "Eleanor Hayes got the toast from the toaster."}...'
2025-05-08 07:27:48,999 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "Eleanor Hayes got the toast from the toaster."}...'
2025-05-08 07:27:48,999 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 3.0, 'results': {}, 'outcome_description': 'Eleanor Hayes got the toast from the toaster.'}
2025-05-08 07:27:49,000 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:27:49,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:27:49,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:27:49,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 97.36000000010245
2025-05-08 07:27:49,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: get the toast from the toaster
2025-05-08 07:27:49,011 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 97.4s. Outcome: Eleanor Hayes got the toast from the toaster.
2025-05-08 07:27:49,011 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:27:49,011 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes got the toast from the toaster.'
2025-05-08 07:27:49,036 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:49,041 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:49,051 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA29190>
2025-05-08 07:27:49,051 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F0887D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:49,067 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA2BB00>
2025-05-08 07:27:49,067 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:49,067 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:49,067 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:49,067 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:49,067 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:49,599 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:50,226 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:12 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1150'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:50,226 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:50,226 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:50,227 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:50,227 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:50,227 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:50,228 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "With a practiced hand, Eleanor carefully lifts the two slices of toast fro...
2025-05-08 07:27:50,228 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "With a practiced hand, Eleanor carefully lifts the two slices of toast from the toaster (toaster_1234), their golden-brown surfaces releasing a warm, inviting aroma. One slice is sli...'
2025-05-08 07:27:50,228 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "With a practiced hand, Eleanor carefully lifts the two slices of toast from the toaster (toaster_1234), their golden-brown surfaces releasing a warm, inviting aroma. One slice is sli...'
2025-05-08 07:27:50,228 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'With a practiced hand, Eleanor carefully lifts the two slices of toast from the toaster (toaster_1234), their golden-brown surfaces releasing a warm, inviting aroma. One slice is slight
2025-05-08 07:27:50,234 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = With a practiced hand, Eleanor carefully lifts the two slices of toast from the toaster (toaster_1234), their golden-brown surfaces releasing a warm, inviting aroma. One slice is slightly darker than the other, but neither is burnt to a crisp. She places them carefully on the plate, a small sense of satisfaction washing over her as the elements of her simple breakfast come together.
2025-05-08 07:27:50,234 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: With a practiced hand, Eleanor carefully lifts the two slices of toast from the ...
2025-05-08 07:27:51,215 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 97.4 (due at 97.4).
2025-05-08 07:27:51,215 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:27:51,215 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:51,215 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:27:51,215 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:27:51,293 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:27:51,293 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:27:51,319 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:51,325 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:51,340 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B3AD0>
2025-05-08 07:27:51,340 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E947350> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:51,361 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E4587A0>
2025-05-08 07:27:51,361 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:51,362 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:51,362 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:51,362 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:51,362 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:52,141 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=768'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:52,141 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:52,141 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:52,142 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:52,142 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:52,142 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:52,143 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Not bad! Now to butter the toast. I'll spread a thin layer on each slice. Then, coffee!", "action_type": "use", "target_id": "butter_4567", "details": "butter the toast"}...'
2025-05-08 07:27:52,143 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Not bad! Now to butter the toast. I'll spread a thin layer on each slice. Then, coffee!", "action_type": "use", "target_id": "butter_4567", "details": "butter the toast"}...'
2025-05-08 07:27:52,143 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Not bad! Now to butter the toast. I'll spread a thin layer on each slice. Then, coffee!", 'action_type': 'use', 'target_id': 'butter_4567', 'details': 'butter the toast'}
2025-05-08 07:27:52,159 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:27:52,159 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on butter_4567) classified as 'environment'.
2025-05-08 07:27:52,159 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'butter_4567', 'details': 'butter the toast'}
2025-05-08 07:27:52,159 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:27:52,182 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:52,188 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:52,204 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA29970>
2025-05-08 07:27:52,204 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E946850> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:52,223 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA066F0>
2025-05-08 07:27:52,223 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:52,223 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:52,223 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:52,223 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:52,223 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:52,947 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:14 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=712'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:52,947 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:52,947 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:52,947 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:52,947 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:52,948 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:52,948 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 8.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:27:52,948 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 8.0, "results": {}, "outcome_description": "Eleanor Hayes buttered the toast."}...'
2025-05-08 07:27:52,948 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 8.0, "results": {}, "outcome_description": "Eleanor Hayes buttered the toast."}...'
2025-05-08 07:27:52,949 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 8.0, 'results': {}, 'outcome_description': 'Eleanor Hayes buttered the toast.'}
2025-05-08 07:27:52,949 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:27:52,961 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:27:52,961 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:27:52,961 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 106.26600000006147
2025-05-08 07:27:52,961 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: butter the toast
2025-05-08 07:27:52,961 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 106.3s. Outcome: Eleanor Hayes buttered the toast.
2025-05-08 07:27:52,961 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:27:52,961 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes buttered the toast.'
2025-05-08 07:27:52,985 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:52,996 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:53,008 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA05F70>
2025-05-08 07:27:53,008 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E945F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:53,028 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B3890>
2025-05-08 07:27:53,028 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:53,028 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:53,028 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:53,028 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:53,028 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:53,939 - src.simulation_async - INFO - [NarrativeImageGenerator] Requesting image for narrative (T100.1): "Eleanor leans against the counter, the gentle warmth of the brewing coffee and toasting bread fillin..."
2025-05-08 07:27:53,939 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:27:53,941 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:27:53,951 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002410F1265A0>
2025-05-08 07:27:53,951 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E426350> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:27:53,976 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002410E8013A0>
2025-05-08 07:27:53,976 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:27:53,977 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:27:53,977 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:27:53,977 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:27:53,977 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:27:54,245 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:16 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1205'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:54,245 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:54,245 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:54,246 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:54,246 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:54,246 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:54,247 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor carefully spreads a thin layer of butter onto each slice of toast,...
2025-05-08 07:27:54,247 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor carefully spreads a thin layer of butter onto each slice of toast, the knife gliding smoothly across the warm, porous surface. The butter melts slightly on contact, releasing...'
2025-05-08 07:27:54,247 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor carefully spreads a thin layer of butter onto each slice of toast, the knife gliding smoothly across the warm, porous surface. The butter melts slightly on contact, releasing...'
2025-05-08 07:27:54,247 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor carefully spreads a thin layer of butter onto each slice of toast, the knife gliding smoothly across the warm, porous surface. The butter melts slightly on contact, releasing a 
2025-05-08 07:27:54,253 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor carefully spreads a thin layer of butter onto each slice of toast, the knife gliding smoothly across the warm, porous surface. The butter melts slightly on contact, releasing a rich, creamy aroma that mingles with the scents of coffee and toast. As she butters the last corner, the coffee maker gurgles, signaling that her caffeine fix is finally ready.
2025-05-08 07:27:54,253 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor carefully spreads a thin layer of butter onto each slice of toast, the k...
2025-05-08 07:27:54,699 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:27:57,704 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3716'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:27:57,704 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-preview-image-generation:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:27:57,705 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:27:57,898 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:27:57,898 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:27:57,898 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:27:57,902 - google_genai.models - INFO - AFC remote call 1 is done.
2025-05-08 07:27:57,925 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-05-08 07:27:57,925 - PIL.PngImagePlugin - DEBUG - STREAM b'zTXt' 41 137
2025-05-08 07:27:57,925 - PIL.PngImagePlugin - DEBUG - STREAM b'iTXt' 190 647
2025-05-08 07:27:57,925 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 849 8192
2025-05-08 07:27:58,056 - src.simulation_async - INFO - [NarrativeImageGenerator] Successfully generated and saved image: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images\narrative_T100_20250508_072757_925832.png
2025-05-08 07:27:59,836 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:00,100 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 106.3 (due at 106.3).
2025-05-08 07:28:00,100 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:28:00,100 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:00,100 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:28:00,100 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:28:00,292 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:28:00,292 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:28:00,316 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:00,323 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:00,339 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA38410>
2025-05-08 07:28:00,339 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410EA2D6D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:00,358 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F148320>
2025-05-08 07:28:00,359 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:00,359 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:00,359 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:00,359 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:00,359 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:01,442 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1073'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:01,442 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:01,442 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:01,444 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:01,444 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:01,444 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:01,445 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Perfect timing! Okay, now for the coffee. I'll pour myself a mug and then I can finally sit down and enjoy breakfast. I'll go sit at the kitchen table.", "action_type": "use", ...'
2025-05-08 07:28:01,445 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Perfect timing! Okay, now for the coffee. I'll pour myself a mug and then I can finally sit down and enjoy breakfast. I'll go sit at the kitchen table.", "action_type": "use", ...'
2025-05-08 07:28:01,445 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Perfect timing! Okay, now for the coffee. I'll pour myself a mug and then I can finally sit down and enjoy breakfast. I'll go sit at the kitchen table.", 'action_type': 'use', 
2025-05-08 07:28:01,462 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:28:01,463 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on coffee_maker_5678) classified as 'environment'.
2025-05-08 07:28:01,463 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'coffee_maker_5678', 'details': 'pour coffee into mug'}
2025-05-08 07:28:01,463 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:28:01,488 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:01,495 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:01,506 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9B2BA0>
2025-05-08 07:28:01,506 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21C250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:01,528 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1902C0>
2025-05-08 07:28:01,528 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:01,528 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:01,528 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:01,528 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:01,528 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:02,233 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=695'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:02,234 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:02,234 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:02,234 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:02,234 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:02,234 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:02,235 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 7.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:28:02,235 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 7.0, "results": {}, "outcome_description": "Eleanor Hayes poured coffee into her mug."}...'
2025-05-08 07:28:02,235 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 7.0, "results": {}, "outcome_description": "Eleanor Hayes poured coffee into her mug."}...'
2025-05-08 07:28:02,235 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 7.0, 'results': {}, 'outcome_description': 'Eleanor Hayes poured coffee into her mug.'}
2025-05-08 07:28:02,235 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:28:02,248 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:28:02,252 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:28:02,252 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 114.59400000004098
2025-05-08 07:28:02,252 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: pour coffee into mug
2025-05-08 07:28:02,252 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 114.6s. Outcome: Eleanor Hayes poured coffee into her mug.
2025-05-08 07:28:02,252 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:28:02,252 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes poured coffee into her mug.'
2025-05-08 07:28:02,277 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:02,284 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:02,296 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B1E20>
2025-05-08 07:28:02,296 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21E6D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:02,313 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1E7350>
2025-05-08 07:28:02,314 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:02,314 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:02,314 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:02,315 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:02,315 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:03,425 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1099'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:03,425 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:03,425 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:03,425 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:03,425 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:03,426 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:03,426 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor carefully pours the freshly brewed coffee into her favorite mug, t...
2025-05-08 07:28:03,427 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor carefully pours the freshly brewed coffee into her favorite mug, the dark liquid steaming gently as it fills the chipped ceramic. The rich, aromatic scent fills the kitchen, ...'
2025-05-08 07:28:03,427 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor carefully pours the freshly brewed coffee into her favorite mug, the dark liquid steaming gently as it fills the chipped ceramic. The rich, aromatic scent fills the kitchen, ...'
2025-05-08 07:28:03,427 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor carefully pours the freshly brewed coffee into her favorite mug, the dark liquid steaming gently as it fills the chipped ceramic. The rich, aromatic scent fills the kitchen, a w
2025-05-08 07:28:03,432 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor carefully pours the freshly brewed coffee into her favorite mug, the dark liquid steaming gently as it fills the chipped ceramic. The rich, aromatic scent fills the kitchen, a welcome contrast to the lingering sweetness of the buttered toast. She takes a moment to savor the aroma before turning towards the small kitchen table, ready to finally enjoy her breakfast.
2025-05-08 07:28:03,433 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor carefully pours the freshly brewed coffee into her favorite mug, the dar...
2025-05-08 07:28:04,947 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:08,489 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 114.7 (due at 114.6).
2025-05-08 07:28:08,490 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:28:08,490 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:08,490 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:28:08,490 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:28:08,583 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:28:08,583 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:28:08,609 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:08,617 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:08,630 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F179970>
2025-05-08 07:28:08,630 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21FDD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:08,648 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0C2180>
2025-05-08 07:28:08,648 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:08,649 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:08,649 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:08,649 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:08,649 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:09,710 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1048'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:09,711 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:09,711 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:09,711 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:09,711 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:09,711 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:09,712 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Alright, toast and coffee in hand. Time to sit down and enjoy. I'll also remember to look at that grocery list while I'm eating. It's on the breadbox, so I'll need to grab it. ...'
2025-05-08 07:28:09,712 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Alright, toast and coffee in hand. Time to sit down and enjoy. I'll also remember to look at that grocery list while I'm eating. It's on the breadbox, so I'll need to grab it. ...'
2025-05-08 07:28:09,712 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Alright, toast and coffee in hand. Time to sit down and enjoy. I'll also remember to look at that grocery list while I'm eating. It's on the breadbox, so I'll need to grab it. 
2025-05-08 07:28:09,729 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:28:09,729 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 07:28:09,729 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'sit at the kitchen table'}
2025-05-08 07:28:09,730 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 07:28:09,754 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:09,762 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:09,774 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1B79E0>
2025-05-08 07:28:09,775 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21EB50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:09,795 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0C3B60>
2025-05-08 07:28:09,795 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:09,796 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:09,796 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:09,796 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:09,796 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:10,464 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=657'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:10,465 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:10,465 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:10,465 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:10,465 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:10,465 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:10,466 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:28:10,466 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes sat at the kitchen table."}...'
2025-05-08 07:28:10,466 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes sat at the kitchen table."}...'
2025-05-08 07:28:10,466 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {}, 'outcome_description': 'Eleanor Hayes sat at the kitchen table.'}
2025-05-08 07:28:10,466 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:28:10,478 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:28:10,478 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:28:10,478 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 120.89100000006147
2025-05-08 07:28:10,478 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: sit at the kitchen table
2025-05-08 07:28:10,478 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 120.9s. Outcome: Eleanor Hayes sat at the kitchen table.
2025-05-08 07:28:10,478 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:28:10,478 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes sat at the kitchen table.'
2025-05-08 07:28:10,502 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:10,510 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:10,520 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E8029C0>
2025-05-08 07:28:10,520 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F0BA5D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:10,539 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E802210>
2025-05-08 07:28:10,539 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:10,540 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:10,540 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:10,540 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:10,540 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:11,641 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1093'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:11,641 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:11,641 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:11,642 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:11,642 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:11,642 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:11,643 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor settles into the worn wooden chair at the kitchen table, placing h...
2025-05-08 07:28:11,643 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor settles into the worn wooden chair at the kitchen table, placing her plate of toast and steaming mug of coffee carefully in front of her. The morning sun streams through the ...'
2025-05-08 07:28:11,643 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor settles into the worn wooden chair at the kitchen table, placing her plate of toast and steaming mug of coffee carefully in front of her. The morning sun streams through the ...'
2025-05-08 07:28:11,643 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor settles into the worn wooden chair at the kitchen table, placing her plate of toast and steaming mug of coffee carefully in front of her. The morning sun streams through the win
2025-05-08 07:28:11,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor settles into the worn wooden chair at the kitchen table, placing her plate of toast and steaming mug of coffee carefully in front of her. The morning sun streams through the window, casting a warm glow on the simple breakfast. She takes a tentative bite of toast, the buttery crunch a welcome sensation. A moment of peace before the day truly begins.
2025-05-08 07:28:11,650 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor settles into the worn wooden chair at the kitchen table, placing her pla...
2025-05-08 07:28:14,787 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 121.0 (due at 120.9).
2025-05-08 07:28:14,787 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:28:14,787 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:14,787 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:28:14,787 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:28:14,829 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:28:14,829 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:28:14,856 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:14,863 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:14,878 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1E6F30>
2025-05-08 07:28:14,878 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21F3D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:14,896 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E800740>
2025-05-08 07:28:14,896 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:14,897 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:14,897 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:14,897 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:14,897 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:15,929 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1020'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:15,929 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:15,929 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:15,930 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:15,930 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:15,930 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:15,931 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "This is nice. Now, before I get too relaxed, I should grab that grocery list. I'll get up and go get it from the breadbox, then come back and finish my breakfast.", "action_typ...'
2025-05-08 07:28:15,931 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "This is nice. Now, before I get too relaxed, I should grab that grocery list. I'll get up and go get it from the breadbox, then come back and finish my breakfast.", "action_typ...'
2025-05-08 07:28:15,931 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "This is nice. Now, before I get too relaxed, I should grab that grocery list. I'll get up and go get it from the breadbox, then come back and finish my breakfast.", 'action_typ
2025-05-08 07:28:15,949 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:28:15,949 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 07:28:15,950 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'go to breadbox to get grocery list'}
2025-05-08 07:28:15,950 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 07:28:15,973 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:15,986 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:15,999 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E459040>
2025-05-08 07:28:15,999 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21CA50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:16,016 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E41F620>
2025-05-08 07:28:16,016 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:16,016 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:16,016 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:16,016 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:16,016 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:16,684 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:38 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=659'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:16,684 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:16,684 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:16,685 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:16,685 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:16,685 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:16,686 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:28:16,686 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes moved to the breadbox to get the grocery list."}...'
2025-05-08 07:28:16,686 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes moved to the breadbox to get the grocery list."}...'
2025-05-08 07:28:16,686 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {}, 'outcome_description': 'Eleanor Hayes moved to the breadbox to get the grocery list.'}
2025-05-08 07:28:16,686 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:28:16,698 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:28:16,698 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:28:16,698 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 127.11000000010245
2025-05-08 07:28:16,698 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: go to breadbox to get grocery list
2025-05-08 07:28:16,698 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 127.1s. Outcome: Eleanor Hayes moved to the breadbox to get the grocery list.
2025-05-08 07:28:16,698 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:28:16,698 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes moved to the breadbox to get the grocery list.'
2025-05-08 07:28:16,724 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:16,730 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:16,742 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E94A4B0>
2025-05-08 07:28:16,742 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F22BA50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:16,759 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97B440>
2025-05-08 07:28:16,759 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:16,759 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:16,759 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:16,759 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:16,759 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:18,249 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1478'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:18,250 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:18,250 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:18,250 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:18,251 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:18,251 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:18,251 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor pushes back her chair from the table and walks the few steps to th...
2025-05-08 07:28:18,252 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor pushes back her chair from the table and walks the few steps to the counter where the breadbox (breadbox_7890) sits. The scent of sourdough, faint but still present, hangs in...'
2025-05-08 07:28:18,252 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor pushes back her chair from the table and walks the few steps to the counter where the breadbox (breadbox_7890) sits. The scent of sourdough, faint but still present, hangs in...'
2025-05-08 07:28:18,252 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor pushes back her chair from the table and walks the few steps to the counter where the breadbox (breadbox_7890) sits. The scent of sourdough, faint but still present, hangs in th
2025-05-08 07:28:18,258 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor pushes back her chair from the table and walks the few steps to the counter where the breadbox (breadbox_7890) sits. The scent of sourdough, faint but still present, hangs in the air. She reaches for the small, handwritten note (note_breadbox_01) tucked beside the loaf, a crinkle of paper marking her intent. The rhythmic ticking of the kitchen clock seems to amplify the quiet of the morning.
2025-05-08 07:28:18,258 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor pushes back her chair from the table and walks the few steps to the coun...
2025-05-08 07:28:20,313 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:21,001 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 127.2 (due at 127.1).
2025-05-08 07:28:21,001 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:28:21,001 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:21,001 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:28:21,001 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:28:21,478 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:28:21,478 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:28:21,506 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:21,513 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:21,525 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA39610>
2025-05-08 07:28:21,525 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F228850> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:21,546 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F179550>
2025-05-08 07:28:21,546 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:21,547 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:21,547 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:21,547 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:21,547 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:22,400 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=844'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:22,400 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:22,400 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:22,400 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:22,400 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:22,401 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:22,401 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, got the list. Now to see what I need. I'll read it here before I go back to the table. That way I can start planning my grocery trip.", "action_type": "use", "target_id":...'
2025-05-08 07:28:22,402 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, got the list. Now to see what I need. I'll read it here before I go back to the table. That way I can start planning my grocery trip.", "action_type": "use", "target_id":...'
2025-05-08 07:28:22,402 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, got the list. Now to see what I need. I'll read it here before I go back to the table. That way I can start planning my grocery trip.", 'action_type': 'use', 'target_id':
2025-05-08 07:28:22,424 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:28:22,424 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on note_breadbox_01) classified as 'environment'.
2025-05-08 07:28:22,424 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'note_breadbox_01', 'details': 'read the grocery list'}
2025-05-08 07:28:22,424 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 07:28:22,449 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:22,457 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:22,470 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E97AAE0>
2025-05-08 07:28:22,470 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F22AA50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:22,488 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E979580>
2025-05-08 07:28:22,488 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:22,488 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:22,488 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:22,488 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:22,488 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:23,182 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=687'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:23,182 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:23,182 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:23,183 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:23,183 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:23,183 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:23,184 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-08 07:28:23,184 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Hayes read the grocery list."}...'
2025-05-08 07:28:23,184 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Hayes read the grocery list."}...'
2025-05-08 07:28:23,184 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 10.0, 'results': {}, 'outcome_description': 'Eleanor Hayes read the grocery list.'}
2025-05-08 07:28:23,184 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:28:23,196 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:28:23,196 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:28:23,196 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 138.5
2025-05-08 07:28:23,196 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: read the grocery list
2025-05-08 07:28:23,196 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 138.5s. Outcome: Eleanor Hayes read the grocery list.
2025-05-08 07:28:23,196 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:28:23,196 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes read the grocery list.'
2025-05-08 07:28:23,222 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:23,230 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:23,243 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA06BA0>
2025-05-08 07:28:23,243 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F0D4C50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:23,262 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA29190>
2025-05-08 07:28:23,262 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:23,262 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:23,262 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:23,262 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:23,262 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:24,821 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1549'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:24,822 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:24,822 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:24,822 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:24,822 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:24,822 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:24,823 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor unfolds the small, crumpled grocery list (note_breadbox_01), her b...
2025-05-08 07:28:24,823 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor unfolds the small, crumpled grocery list (note_breadbox_01), her brow furrowing slightly as she scans the items scrawled in her own handwriting. 'Milk, eggs, cheese, bread (s...'
2025-05-08 07:28:24,823 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor unfolds the small, crumpled grocery list (note_breadbox_01), her brow furrowing slightly as she scans the items scrawled in her own handwriting. 'Milk, eggs, cheese, bread (s...'
2025-05-08 07:28:24,823 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor unfolds the small, crumpled grocery list (note_breadbox_01), her brow furrowing slightly as she scans the items scrawled in her own handwriting. 'Milk, eggs, cheese, bread (sour
2025-05-08 07:28:24,830 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor unfolds the small, crumpled grocery list (note_breadbox_01), her brow furrowing slightly as she scans the items scrawled in her own handwriting. 'Milk, eggs, cheese, bread (sourdough this time!), coffee, and apples' are listed. She sighs softly; it's a pretty standard list, nothing too exciting. A robin (npc_concept_robin_01) lands on the windowsill outside, tilting its head as if listening to her silent contemplation.
2025-05-08 07:28:24,830 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor unfolds the small, crumpled grocery list (note_breadbox_01), her brow fu...
2025-05-08 07:28:25,443 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:30,561 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:32,363 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 138.5 (due at 138.5).
2025-05-08 07:28:32,363 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:28:32,363 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:32,363 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:28:32,363 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:28:32,581 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:28:32,581 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:28:32,607 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:32,615 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:32,632 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B3710>
2025-05-08 07:28:32,632 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E7F1FD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:32,651 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1E7EC0>
2025-05-08 07:28:32,651 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:32,652 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:32,652 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:32,652 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:32,652 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:33,745 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:55 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1084'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:33,745 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:33,745 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:33,746 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:33,746 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:33,746 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:33,747 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Ugh, sourdough again. I really need to remember to buy the kind I like next time. And coffee... definitely. Apples sound good though. Okay, I think I'll head back to the table ...'
2025-05-08 07:28:33,747 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Ugh, sourdough again. I really need to remember to buy the kind I like next time. And coffee... definitely. Apples sound good though. Okay, I think I'll head back to the table ...'
2025-05-08 07:28:33,747 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Ugh, sourdough again. I really need to remember to buy the kind I like next time. And coffee... definitely. Apples sound good though. Okay, I think I'll head back to the table 
2025-05-08 07:28:33,764 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:28:33,764 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 07:28:33,764 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'go back to the kitchen table'}
2025-05-08 07:28:33,764 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 07:28:33,791 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:33,799 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:33,814 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E77D460>
2025-05-08 07:28:33,814 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E7F39D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:33,833 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1E6450>
2025-05-08 07:28:33,833 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:33,833 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:33,833 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:33,834 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:33,834 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:34,513 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=668'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:34,514 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:34,514 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:34,514 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:34,514 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:34,515 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:34,516 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 07:28:34,516 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes moved back to the kitchen table."}...'
2025-05-08 07:28:34,516 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes moved back to the kitchen table."}...'
2025-05-08 07:28:34,516 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {}, 'outcome_description': 'Eleanor Hayes moved back to the kitchen table.'}
2025-05-08 07:28:34,516 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:28:34,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:28:34,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:28:34,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 144.86000000010245
2025-05-08 07:28:34,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: go back to the kitchen table
2025-05-08 07:28:34,528 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 144.9s. Outcome: Eleanor Hayes moved back to the kitchen table.
2025-05-08 07:28:34,528 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:28:34,528 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes moved back to the kitchen table.'
2025-05-08 07:28:34,553 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:34,561 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:34,572 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F0B3440>
2025-05-08 07:28:34,572 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21E4D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:34,591 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F23E4B0>
2025-05-08 07:28:34,591 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:34,591 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:34,591 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:34,591 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:34,591 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:35,685 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:35,874 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:28:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1273'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:35,875 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:35,875 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:35,875 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:35,875 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:35,875 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:35,876 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor returns to the kitchen table, the grocery list (note_breadbox_01) ...
2025-05-08 07:28:35,876 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor returns to the kitchen table, the grocery list (note_breadbox_01) clutched in her hand. Her toast is slightly cooler now, but the coffee still steams gently, a comforting bea...'
2025-05-08 07:28:35,876 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor returns to the kitchen table, the grocery list (note_breadbox_01) clutched in her hand. Her toast is slightly cooler now, but the coffee still steams gently, a comforting bea...'
2025-05-08 07:28:35,876 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor returns to the kitchen table, the grocery list (note_breadbox_01) clutched in her hand. Her toast is slightly cooler now, but the coffee still steams gently, a comforting beacon
2025-05-08 07:28:35,883 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor returns to the kitchen table, the grocery list (note_breadbox_01) clutched in her hand. Her toast is slightly cooler now, but the coffee still steams gently, a comforting beacon in the growing light of the morning. She settles back into her chair, the worn wood creaking softly beneath her. The faint sound of children playing outside drifts in through the open window, a reminder that the world is already well underway.
2025-05-08 07:28:35,883 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor returns to the kitchen table, the grocery list (note_breadbox_01) clutch...
2025-05-08 07:28:38,760 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 144.9 (due at 144.9).
2025-05-08 07:28:38,761 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 07:28:38,761 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:38,761 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 07:28:38,761 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 07:28:38,854 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 07:28:38,854 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 07:28:38,884 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:38,892 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:38,905 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F124B60>
2025-05-08 07:28:38,905 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21F550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:38,921 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F1E62A0>
2025-05-08 07:28:38,921 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:38,921 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:38,921 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:38,921 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:38,921 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:40,060 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:29:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1130'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:40,060 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:40,060 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:40,060 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:40,060 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:40,061 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:40,062 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, back at the table. I think I'll finish my breakfast and then maybe look online to see how crowded the grocery store is at different times. That robin is cute. I wonder if...'
2025-05-08 07:28:40,062 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, back at the table. I think I'll finish my breakfast and then maybe look online to see how crowded the grocery store is at different times. That robin is cute. I wonder if...'
2025-05-08 07:28:40,062 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, back at the table. I think I'll finish my breakfast and then maybe look online to see how crowded the grocery store is at different times. That robin is cute. I wonder if
2025-05-08 07:28:40,081 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 07:28:40,082 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (wait on N/A) classified as 'environment'.
2025-05-08 07:28:40,082 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'wait', 'target_id': None, 'details': 'finish breakfast and plan the grocery trip'}
2025-05-08 07:28:40,082 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (wait).
2025-05-08 07:28:40,108 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:40,117 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:40,131 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410EA076E0>
2025-05-08 07:28:40,135 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E945750> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:40,152 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410F14AA50>
2025-05-08 07:28:40,152 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:40,153 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:40,153 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:40,153 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:40,153 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:40,898 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:29:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=734'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:40,899 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:40,899 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:40,899 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:40,899 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:40,899 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:40,900 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 300.0, "results": {}, "outcome_description": "Eleanor Hay...
2025-05-08 07:28:40,900 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 300.0, "results": {}, "outcome_description": "Eleanor Hayes finished breakfast and planned the grocery trip."}...'
2025-05-08 07:28:40,900 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 300.0, "results": {}, "outcome_description": "Eleanor Hayes finished breakfast and planned the grocery trip."}...'
2025-05-08 07:28:40,900 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 300.0, 'results': {}, 'outcome_description': 'Eleanor Hayes finished breakfast and planned the grocery trip.'}
2025-05-08 07:28:40,900 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 07:28:40,912 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 07:28:40,912 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 07:28:40,912 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 446.25
2025-05-08 07:28:40,912 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: wait - Details: finish breakfast and plan the grocery trip
2025-05-08 07:28:40,912 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 446.2s. Outcome: Eleanor Hayes finished breakfast and planned the grocery trip.
2025-05-08 07:28:40,912 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location kitchen
2025-05-08 07:28:40,912 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes finished breakfast and planned the grocery trip.'
2025-05-08 07:28:40,937 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:28:40,945 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:28:40,957 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E9795B0>
2025-05-08 07:28:40,957 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410F21D150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:28:40,974 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002410E94AB40>
2025-05-08 07:28:40,974 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:28:40,974 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:28:40,974 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:28:40,974 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:28:40,974 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:28:42,481 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:29:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1498'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:28:42,481 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:28:42,481 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:28:42,482 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:28:42,482 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:28:42,482 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:28:42,482 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor savors the last bites of her toast, each mouthful accompanied by a...
2025-05-08 07:28:42,482 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor savors the last bites of her toast, each mouthful accompanied by a sip of the strong, dark coffee. She glances out the window, watching the robin (npc_concept_robin_01) flitt...'
2025-05-08 07:28:42,482 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor savors the last bites of her toast, each mouthful accompanied by a sip of the strong, dark coffee. She glances out the window, watching the robin (npc_concept_robin_01) flitt...'
2025-05-08 07:28:42,482 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor savors the last bites of her toast, each mouthful accompanied by a sip of the strong, dark coffee. She glances out the window, watching the robin (npc_concept_robin_01) flitting
2025-05-08 07:28:42,490 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor savors the last bites of her toast, each mouthful accompanied by a sip of the strong, dark coffee. She glances out the window, watching the robin (npc_concept_robin_01) flitting about in the small patch of green below. The online search for grocery store crowd levels proves surprisingly helpful, suggesting a mid-afternoon trip for the least congestion. With a plan in place, a sense of quiet accomplishment settles over her.
2025-05-08 07:28:42,490 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor savors the last bites of her toast, each mouthful accompanied by a sip o...
2025-05-08 07:28:45,952 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:51,079 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:28:56,207 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:01,333 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:06,448 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:11,562 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:16,697 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:21,816 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:26,945 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:28,065 - src.simulation_async - INFO - [NarrativeImageGenerator] Requesting image for narrative (T194.2): "Eleanor unfolds the small, crumpled grocery list (note_breadbox_01), her brow furrowing slightly as ..."
2025-05-08 07:29:28,065 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 07:29:28,067 - httpcore.connection - DEBUG - close.started
2025-05-08 07:29:28,067 - httpcore.connection - DEBUG - close.complete
2025-05-08 07:29:28,067 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 07:29:28,075 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002410F0C2810>
2025-05-08 07:29:28,076 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002410E426350> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 07:29:28,092 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002410F1B79B0>
2025-05-08 07:29:28,092 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 07:29:28,092 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 07:29:28,092 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 07:29:28,092 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 07:29:28,092 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 07:29:32,057 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:32,865 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 11:29:54 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4760'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 07:29:32,865 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-preview-image-generation:generateContent "HTTP/1.1 200 OK"
2025-05-08 07:29:32,865 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 07:29:33,061 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 07:29:33,061 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 07:29:33,061 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 07:29:33,064 - google_genai.models - INFO - AFC remote call 1 is done.
2025-05-08 07:29:33,065 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-05-08 07:29:33,065 - PIL.PngImagePlugin - DEBUG - STREAM b'zTXt' 41 137
2025-05-08 07:29:33,065 - PIL.PngImagePlugin - DEBUG - STREAM b'iTXt' 190 647
2025-05-08 07:29:33,065 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 849 8192
2025-05-08 07:29:33,189 - src.simulation_async - INFO - [NarrativeImageGenerator] Successfully generated and saved image: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images\narrative_T194_20250508_072933_065689.png
2025-05-08 07:29:37,155 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:42,291 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:47,390 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:52,521 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:29:57,638 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:30:02,771 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:30:07,886 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 07:30:12,339 - src.simulation_async - INFO - Cancelling remaining tasks...
2025-05-08 07:30:12,340 - src.simulation_async - INFO - [TimeManager] Task cancelled.
2025-05-08 07:30:12,340 - src.simulation_async - INFO - [TimeManager] Loop finished at sim time 238.4
2025-05-08 07:30:12,340 - src.simulation_async - INFO - [InteractionDispatcher] Task cancelled.
2025-05-08 07:30:12,340 - src.simulation_async - INFO - [WorldInfoGatherer] Task cancelled.
2025-05-08 07:30:12,341 - src.simulation_async - INFO - [NarrationTask] Task cancelled.
2025-05-08 07:30:12,341 - src.simulation_async - INFO - [WorldEngineLLM] Task cancelled.
2025-05-08 07:30:12,341 - src.simulation_async - INFO - [Eleanor Hayes] Task cancelled.
2025-05-08 07:30:12,341 - src.simulation_async - INFO - [Eleanor Hayes] Task finished.
2025-05-08 07:30:12,341 - src.simulation_async - INFO - All tasks cancelled or finished.
2025-05-08 07:30:12,341 - src.simulation_async - INFO - Saving final simulation state.
2025-05-08 07:30:12,342 - src.loop_utils - DEBUG - Successfully saved JSON to C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-08 07:30:12,342 - src.simulation_async - INFO - Final simulation state saved to C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-08 07:30:12,353 - __main__ - WARNING - Simulation interrupted by user.
