2025-05-07 20:51:47,202 - __main__ - INFO - --- Application Start (main_async.py) --- Logging to: simulation_async.log
2025-05-07 20:51:47,205 - asyncio - DEBUG - Using selector: SelectSelector
2025-05-07 20:51:47,220 - src.simulation_async - INFO - ADK InMemoryMemoryService initialized.
2025-05-07 20:51:47,220 - src.simulation_async - INFO - Google Generative AI configured.
2025-05-07 20:51:47,222 - src.simulation_async - INFO - Starting simulation initialization.
2025-05-07 20:51:47,222 - src.loop_utils - INFO - Starting simulation state loading/initialization.
2025-05-07 20:51:47,222 - src.loop_utils - INFO - No instance UUID specified, searching for the latest world config...
2025-05-07 20:51:47,224 - src.loop_utils - INFO - Found latest world config file: C:\Users\dshea\Desktop\TheSimulation\data\world_config_05e07dad-f24b-420b-822c-1ae7862220f6.json.
2025-05-07 20:51:47,226 - src.loop_utils - INFO - Successfully loaded world config for UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-07 20:51:47,228 - src.loop_utils - INFO - Found 1 life summary file(s) for UUID 05e07dad-f24b-420b-822c-1ae7862220f6.
2025-05-07 20:51:47,229 - src.loop_utils - INFO - No usable existing state for UUID 05e07dad-f24b-420b-822c-1ae7862220f6. Creating new state...
2025-05-07 20:51:47,230 - src.loop_utils - INFO - Generating blank state structure for new UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-07 20:52:03,848 - src.loop_utils - INFO - Initialized new state for UUID 05e07dad-f24b-420b-822c-1ae7862220f6 with 1 simulacra.
2025-05-07 20:52:04,345 - src.loop_utils - INFO - Syncing from world_config and resetting objects for UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-07 20:52:05,983 - src.loop_utils - INFO - Synced WORLD_TEMPLATE_DETAILS_KEY from world_config: type='real', city='Asheville'
2025-05-07 20:52:05,984 - src.loop_utils - INFO - 'objects' key not found or empty in world_config.json. State 'objects' will be empty.
2025-05-07 20:52:05,984 - src.loop_utils - WARNING - Added missing 'mood' key to 'world_template_details' with default value 'Real world'.
2025-05-07 20:52:05,984 - src.loop_utils - INFO - Saving new state file: C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-07 20:52:05,986 - src.loop_utils - INFO - Saved data to C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-07 20:52:05,986 - src.simulation_async - INFO - Initialization complete. Instance 05e07dad-f24b-420b-822c-1ae7862220f6 ready with 1 simulacra.
2025-05-07 20:52:05,988 - src.simulation_async - INFO - ADK Session created: sim_session_05e07dad-f24b-420b-822c-1ae7862220f6.
2025-05-07 20:52:05,989 - src.simulation_async - INFO - Created 1 simulacra agents.
2025-05-07 20:52:05,989 - src.simulation_async - INFO - Main ADK Runner initialized.
2025-05-07 20:52:05,989 - src.simulation_async - INFO - Dedicated Search Agent Runner initialized.
2025-05-07 20:52:05,998 - src.simulation_async - INFO - Started 8 tasks.
2025-05-07 20:52:05,998 - src.simulation_async - INFO - [TimeManager] Task started.
2025-05-07 20:52:05,999 - src.simulation_async - INFO - [InteractionDispatcher] Task started.
2025-05-07 20:52:05,999 - src.simulation_async - INFO - [WorldInfoGatherer] Task started.
2025-05-07 20:52:05,999 - src.simulation_async - INFO - [NarrativeImageGenerator] Task started. Will generate images every 30.0 real seconds.
2025-05-07 20:52:05,999 - src.simulation_async - INFO - [NarrativeImageGenerator] Using model: gemini-2.0-flash-preview-image-generation
2025-05-07 20:52:05,999 - src.simulation_async - INFO - [NarrativeImageGenerator] Saving images to: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images
2025-05-07 20:52:06,123 - src.simulation_async - INFO - [DynamicInterruptionTask] Task started.
2025-05-07 20:52:06,123 - src.simulation_async - INFO - [NarrationTask] Task started.
2025-05-07 20:52:06,124 - src.simulation_async - INFO - [WorldEngineLLM] Task started.
2025-05-07 20:52:06,124 - src.simulation_async - INFO - [Eleanor Hayes] LLM Agent task started.
2025-05-07 20:52:06,124 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
2025-05-07 20:52:06,125 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending initial context prompt as agent is idle.
2025-05-07 20:52:06,136 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-07 20:52:06,136 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'Real world'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'Real world' atmosphere.
**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
EVERYTHING YOU DO MUST BE CONSISTENT WITH YOUR INTERNAL KNOWLEDGE OF WHERE YOU ARE AND WHO YOU ARE. 
EXAMPLE: GOING TO PLACES MUST BE A REAL PLACE TO A REAL DESTINATION. AS A RESIDENT OF THE AREA BASED ON YOUR LIFE SUMMARY, YOU MUST KNOW WHERE YOU ARE GOING AND HOW TO GET THERE.

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'Real world'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'Real world'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'Real world'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
            *   **Talking to Ephemeral NPCs (introduced by Narrator):**
            *   If the Narrator described an NPC (e.g., "a street vendor," "a mysterious figure"), you can interact by setting `action_type: "talk"`.
            *   In `details`, specify who you are talking to based on the narrative description (e.g., `details: "to the street vendor about the strange weather"`).
            *   If the Narrator provided a conceptual tag (e.g., "your friend Alex (npc_concept_friend_alex)"), you can use `target_id: "npc_concept_friend_alex"` and provide conversational content in `details`. This `target_id` is for contextual understanding by the World Engine, not a lookup in the game state.
    *   **World Interactions:** `look_around`, `move` (Specify `details` like target location ID or name), `world_action` (Specify `details` for generic world interactions not covered by other types).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'Real world'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'Real world' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'Real world' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"Handle the requests as specified in the System Instruction."}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-07 20:52:06,137 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:06,147 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:06,168 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCDD68A0>
2025-05-07 20:52:06,168 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FC91CAD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:06,186 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCDD7B60>
2025-05-07 20:52:06,187 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:06,188 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:06,188 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:06,188 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:06,188 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:08,006 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:52:28 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1805'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:08,008 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:08,008 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:08,009 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:08,009 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:08,009 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:08,011 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Okay, I need to figure out my next move. Let's see... I don't have any specific instructions at the moment, so I need to rely on my persona and the 'Real world' context to decide what Eleanor Hayes would do. I'm Eleanor, and I'm in a 'Real world' simulation. I need to think about what Eleanor would be doing right now and what she would do next. Without any specific instructions or events, it's a blank slate. I think she'd probably be doing something practical or trying to improve her situation. Maybe she'd be bored and want some entertainment. Since I'm idle, I will use initiate change to trigger something new.", "action_type": "initiate_change", "target_id": null, "details": "Feeling a bit listless; time to find something interesting to do. Perhaps explore a new cafe or check out a local event."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I need to figure out my next move. Let's see... I don't have any specific instructions at the moment, so I need to rely on my persona and the 'Real world' context to decide what Eleanor Hayes would do. I'm Eleanor, and I'm in a 'Real world' simulation. I need to think about what Eleanor would be doing right now and what she would do next. Without any specific instructions or events, it's a blank slate. I think she'd probably be doing something practical or trying to improve her situation. Maybe she'd be bored and want some entertainment. Since I'm idle, I will use initiate change to trigger something new.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit listless; time to find something interesting to do. Perhaps explore a new cafe or check out a local event.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.5734017721036585}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":205,"candidates_tokens_details":[{"modality":"TEXT","token_count":205}],"prompt_token_count":1392,"prompt_tokens_details":[{"modality":"TEXT","token_count":1392}],"total_token_count":1597},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-07 20:52:08,026 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-07 20:52:08,026 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (initiate_change on N/A) classified as 'environment'.
2025-05-07 20:52:08,026 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'initiate_change', 'target_id': None, 'details': 'Feeling a bit listless; time to find something interesting to do. Perhaps explore a new cafe or check out a local event.'}
2025-05-07 20:52:29,229 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (initiate_change).
2025-05-07 20:52:29,230 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: wuDJ46yd
2025-05-07 20:52:29,239 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-07 20:52:29,239 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.
**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Actor's Current Location ID
- Current World Time
- World Context:
- Actor's Current Location State (Details of the location where the actor currently is, including name, description, objects_present, connected_locations with potential travel metadata like mode/time/distance)
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Target Entity State (if applicable)
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
    *   For `move` actions, `intent.details` specifies the target location's ID or a well-known name.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`:
                *   Check `Target Entity State.is_interactive` property. If false, action is invalid.
                *   **If `Target Entity State.properties.leads_to` exists (e.g., for a door or portal):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 5-15s for opening a door and stepping through).
                    *   `results`: `{"simulacra.[sim_id].location": "[Target Entity State.properties.leads_to_value]"}`.
                    *   `outcome_description`: `"[Actor Name] used the [Target Entity State.name] and moved to [Name of the new location if known, otherwise the ID from leads_to]."`.
                *   Else (for other usable objects): Check other object properties (`toggleable`, `lockable`), and current state to determine outcome, duration, and results (e.g., turning a lamp on/off).
            *   `talk`:
                *   **If target is a Simulacra:**
                    *   Check if Actor and Target Simulacra are in the same `Actor's Current Location ID`.
                    *   If not, `valid_action: false`, `duration: 0.0`, `results: {}`, `outcome_description: "[Actor Name] tried to talk to [Target Simulacra Name], but they are not in the same location."`
                    *   If yes, `valid_action: true`, `duration: short (e.g., 30-120s)`, `results: {"simulacra.[target_id].last_observation": "[Actor Name] said to you: '{intent.details}'"}`, `outcome_description: "[Actor Name] spoke with [Target Simulacra Name]."`
                *   **If target is an ephemeral NPC (indicated by `intent.target_id` starting with 'npc_concept_' OR if `intent.details` clearly refers to an NPC described in the Actor's `last_observation` which was set by the Narrator):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 15-60s).
                    *   **NPC Response Generation:**
                        *   Examine the `Actor's Last Observation` (provided implicitly via the actor's state, which you don't directly see but influences the context) and `Recent Narrative History` (if available in your input context) to understand the NPC described by the Narrator.
                        *   Consider `intent.details` (what the Actor said to this NPC).
                        *   Craft a plausible `npc_response_content` from the perspective of this ephemeral NPC, fitting the narrative context.
                        *   Determine a generic `npc_description_for_output` (e.g., "the shopkeeper", "your friend", "the street vendor") based on how the Narrator introduced them or how the actor referred to them in the intent.
                    *   `results`: Format as `{"simulacra.[actor_id].last_observation": "The [npc_description_for_output] said: '[npc_response_content]'"}`. Replace bracketed parts with your generated content.
                    *   `outcome_description`: Format as `"[Actor Name] spoke with the [npc_description_for_output]."` Replace bracketed parts.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`:
                *   **Destination:** The target location ID is in `intent.details`.
                *   **Validity:**
                    *   Check if the target location ID exists in the `Actor's Current Location State.connected_locations`.
                    *   If not directly connected, consider if it's a known global location ID based on `World Context`.
                    *   If `World Rules.allow_teleportation` is true, and intent implies it, this might be valid.
                *   **Duration Calculation (see step 3):** This is critical for `move`.
                *   **Results:** If valid, `simulacra.[sim_id].location` should be updated to the target location ID from `intent.details`.
            *   `look_around`: Provides a general observation. Duration is short. Results update `simulacra.[sim_id].last_observation` with a description of the current location and entities.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
    *   For `move` actions:
        *   If moving to a location listed in `Actor's Current Location State.connected_locations` which has explicit travel time, use that.
        *   If `World Context.World Type` is "real":
            *   Estimate travel time based on the distance between `Actor's Current Location State.name` and the target location (from `intent.details`, potentially referencing `World Context.Overall World Location`).
            *   Use common sense for travel modes (walking for short distances within a city, car/transit for longer). Factor in `World Feeds.Weather` if `World Rules.weather_effects_travel` is true.
        *   If `World Context.World Type` is "fictional":
            *   Estimate based on implied distances from `World Context.World Description`, `Actor's Current Location State`, and the nature of the target location.
            *   Consider fantasy/sci-fi travel methods if appropriate for the `World Context.Sub-Genre`.
        *   If moving between adjacent sub-locations within a larger complex (e.g., "kitchen" to "living_room" if current location is "house_interior"), duration should be very short (e.g., 5-30 seconds).
    *   For other actions, assign plausible durations (e.g., `talk` a few minutes, `use` object varies, `wait` as specified or short).
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"`). Empty `{}` for invalid actions.
    *   For a successful `move`, the key result is `{ "simulacra.sim_3e912d.location": "[target_location_id_from_intent.details]" }`.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I need to figure out my next move. Let's see... I don't have any specific instructions at the moment, so I need to rely on my persona and the 'Real world' context to decide what Eleanor Hayes would do. I'm Eleanor, and I'm in a 'Real world' simulation. I need to think about what Eleanor would be doing right now and what she would do next. Without any specific instructions or events, it's a blank slate. I think she'd probably be doing something practical or trying to improve her situation. Maybe she'd be bored and want some entertainment. Since I'm idle, I will use initiate change to trigger something new.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit listless; time to find something interesting to do. Perhaps explore a new cafe or check out a local event.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-07 20:52:29,239 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:29,241 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:29,242 - src.simulation_async - INFO - [WorldInfoGatherer] Updating world feeds at sim_time 23.2 for location: Asheville, NC, United States
2025-05-07 20:52:29,242 - src.simulation_async - WARNING - Path segment 'world_feeds' not found or not dict in 'world_feeds.last_update_sim_time'. Creating.
2025-05-07 20:52:29,242 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.last_update_sim_time = 23.233999999938533
2025-05-07 20:52:29,243 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL weather search for 'Asheville, NC, United States' with query: 'What is the current weather in Asheville, NC, United States?'
2025-05-07 20:52:29,251 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-07 20:52:29,251 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
I can answer your questions by searching the internet. Just ask me anything!

You are an agent. Your internal name is "SearchLLMAgent".

 The description about you is "Dedicated LLM Agent for performing Google Searches."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"What is the current weather in Asheville, NC, United States?"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-07 20:52:29,251 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:29,252 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:29,264 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCE7E960>
2025-05-07 20:52:29,264 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FCDE6550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:29,265 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCE7F200>
2025-05-07 20:52:29,265 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2EC0BCF50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:29,282 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCE15040>
2025-05-07 20:52:29,282 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:29,283 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:29,283 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:29,283 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCE7EF60>
2025-05-07 20:52:29,284 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:29,284 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:29,284 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:29,284 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:29,284 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:29,284 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:29,284 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:29,963 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:52:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=668'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:29,964 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:29,964 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:29,964 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:29,965 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:29,965 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:29,965 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": true, "duration": 2.0, "results": {"simulacra.sim_3e912d.status": "idle"}, "outcome_description": "Eleanor Hayes felt a wave of restlessness."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra.sim_3e912d.status\": \"idle\"}, \"outcome_description\": \"Eleanor Hayes felt a wave of restlessness.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.13052111341242204}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":57,"candidates_tokens_details":[{"modality":"TEXT","token_count":57}],"prompt_token_count":2902,"prompt_tokens_details":[{"modality":"TEXT","token_count":2902}],"total_token_count":2959},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-07 20:52:29,965 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 2.0, "results": {"simulacra.sim_3e912d.status": "idle"}, ...
2025-05-07 20:52:29,966 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-07 20:52:29,977 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-07 20:52:29,980 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {'simulacra.sim_3e912d.status': 'idle'}
2025-05-07 20:52:29,980 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 3.9839999999385327
2025-05-07 20:52:29,980 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: initiate_change - Details: Feeling a bit listless; time to find something interesting to do. Perhaps explore a new cafe or chec
2025-05-07 20:52:29,980 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 4.0s. Outcome: Eleanor Hayes felt a wave of restlessness.
2025-05-07 20:52:29,981 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'Real world' for actor Eleanor Hayes at location default_start_location
2025-05-07 20:52:29,981 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes felt a wave of restlessness.'
2025-05-07 20:52:33,710 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: mQ0iDU4E
2025-05-07 20:52:33,711 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: wuDJ46yd
2025-05-07 20:52:33,719 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-07 20:52:33,719 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:

You are the Narrator for **TheSimulation**, currently focusing on events related to Eleanor Hayes (sim_3e912d). The established **World Style/Mood** for this simulation is **'Real world'**. Your role is to weave the factual outcomes of actions into an engaging and atmospheric narrative, STRICTLY matching this 'Real world' style.
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.

**Input (Provided via trigger message):**
- Actor Name & ID
- Original Intent
- Factual Outcome Description
- State Changes (Results)
- Current World Time
- Current World Feeds (Weather, recent major news - for subtle background flavor)
- Recent Narrative History (Last ~5 entries)
- Actor's Current Location ID (e.g., "eleanors_bedroom")

**Your Task:**
1.  **Understand the Event:** Read the Actor, Intent, and Factual Outcome Description.
2.  **Recall the Mood:** Remember the required narrative style is **'Real world'**.
3.  **Consider the Context:** Note Recent Narrative History. **IGNORE any `World Style/Mood` in `Recent Narrative History`. Prioritize the established 'Real world' style.**
4.  **Introduce Ephemeral NPCs (Optional but Encouraged):** If appropriate for the scene, the actor's location, and the narrative flow, you can describe an NPC appearing, speaking, or performing an action.
    *   These NPCs are ephemeral and exist only in the narrative.
    *   If an NPC might be conceptually recurring (e.g., "the usual shopkeeper", "your friend Alex"), you can give them a descriptive tag in parentheses for context, like `(npc_concept_grumpy_shopkeeper)` or `(npc_concept_friend_alex)`. This tag is for LLM understanding, not a system ID.
    *   Example: "As [Actor Name] entered the tavern, a grizzled man with an eye patch (npc_concept_old_pirate_01) at a corner table grunted a greeting."
    *   Example: "A street vendor (npc_concept_flower_seller_01) called out, '[Actor Name], lovely flowers for a lovely day?'"
5.  **Generate Narrative and Discover Entities (Especially for `look_around`):**
    *   Write a single, engaging narrative paragraph in the **present tense**.
    *   **Style Adherence:** STRICTLY adhere to **'Real world'**. Infuse with appropriate atmosphere, sensory details, and tone.
// ...existing code...
    *   **Show, Don't Just Tell.**
    *   **Incorporate Intent (Optional).**
    *   **Flow:** Ensure reasonable flow.
    *   **If the `Original Intent.action_type` was `look_around`:**
        *   Your narrative MUST describe the key features and 2-4 plausible objects the actor would see in their current location (e.g., if in a bedroom: a bed, a closet, a nightstand, a window). Consider the `Original Intent.details` (e.g., "trying to identify the closet's location") to ensure relevant objects are mentioned.
        *   You MAY also introduce 0-1 ephemeral NPCs if appropriate for the scene.
        *   For each object and NPC you describe in the narrative, you MUST also list them in the `discovered_objects` and `discovered_npcs` fields in the JSON output (see below). Assign a simple, unique `id` (e.g., `closet_bedroom_01`, `npc_cat_01`), a `name`, a brief `description`, and set `is_interactive` to `true` if it's something an agent could plausibly interact with. For objects, you can also add common-sense `properties` (e.g., `{"is_container": true, "is_openable": true}` for a closet).

**Output:**
Output ONLY a valid JSON object matching this exact structure:
`{
  "narrative": "str (Your narrative paragraph)",
  "discovered_objects": [
    {"id": "str (e.g., object_type_location_instance)", "name": "str", "description": "str", "is_interactive": bool, "properties": {}}
  ],
  "discovered_npcs": [
    {"id": "str (e.g., npc_concept_descriptor_instance)", "name": "str", "description": "str"}
  ]
}`
*   If no objects or NPCs are discovered/relevant (e.g., for actions other than `look_around`, or if `look_around` reveals an empty space), `discovered_objects` and `discovered_npcs` can be empty arrays `[]`.
*   Example for `look_around` in a bedroom:
    `{
      "narrative": "Eleanor glances around her sunlit bedroom. A large oak **closet (closet_bedroom_01)** stands against the north wall. Her unmade **bed (bed_bedroom_01)** is to her right, and a small **nightstand (nightstand_bedroom_01)** sits beside it, upon which a fluffy **cat (npc_cat_01)** is curled up, blinking slowly.",
      "discovered_objects": [
        {"id": "closet_bedroom_01", "name": "Oak Closet", "description": "A large oak closet.", "is_interactive": true, "properties": {"is_container": true, "is_openable": true, "is_open": false}},
        {"id": "bed_bedroom_01", "name": "Unmade Bed", "description": "Her unmade bed.", "is_interactive": true, "properties": {}},
        {"id": "nightstand_bedroom_01", "name": "Nightstand", "description": "A small nightstand.", "is_interactive": true, "properties": {}}
      ],
      "discovered_npcs": [
        {"id": "npc_cat_01", "name": "Fluffy Cat", "description": "A fluffy cat curled up on the nightstand."}
      ]
    }`
*   Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure.


You are an agent. Your internal name is "NarrationLLMAgent".

 The description about you is "LLM Narrator: Generates 'Real world' narrative based on factual outcomes."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I need to figure out my next move. Let's see... I don't have any specific instructions at the moment, so I need to rely on my persona and the 'Real world' context to decide what Eleanor Hayes would do. I'm Eleanor, and I'm in a 'Real world' simulation. I need to think about what Eleanor would be doing right now and what she would do next. Without any specific instructions or events, it's a blank slate. I think she'd probably be doing something practical or trying to improve her situation. Maybe she'd be bored and want some entertainment. Since I'm idle, I will use initiate change to trigger something new.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit listless; time to find something interesting to do. Perhaps explore a new cafe or check out a local event.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra.sim_3e912d.status\": \"idle\"}, \"outcome_description\": \"Eleanor Hayes felt a wave of restlessness.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-07 20:52:33,719 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:33,720 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:33,721 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 27.7 (due at 4.0).
2025-05-07 20:52:33,721 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-07 20:52:33,721 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-07 20:52:33,721 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
2025-05-07 20:52:33,721 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-07 20:52:33,721 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-07 20:52:33,722 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:52:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1727'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:33,722 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:33,722 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:33,722 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:33,722 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:33,723 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-07 20:52:33,723 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-07 20:52:34,796 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: mQ0iDU4E
2025-05-07 20:52:34,804 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-07 20:52:34,804 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'Real world'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'Real world' atmosphere.
**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
EVERYTHING YOU DO MUST BE CONSISTENT WITH YOUR INTERNAL KNOWLEDGE OF WHERE YOU ARE AND WHO YOU ARE. 
EXAMPLE: GOING TO PLACES MUST BE A REAL PLACE TO A REAL DESTINATION. AS A RESIDENT OF THE AREA BASED ON YOUR LIFE SUMMARY, YOU MUST KNOW WHERE YOU ARE GOING AND HOW TO GET THERE.

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'Real world'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'Real world'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'Real world'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
            *   **Talking to Ephemeral NPCs (introduced by Narrator):**
            *   If the Narrator described an NPC (e.g., "a street vendor," "a mysterious figure"), you can interact by setting `action_type: "talk"`.
            *   In `details`, specify who you are talking to based on the narrative description (e.g., `details: "to the street vendor about the strange weather"`).
            *   If the Narrator provided a conceptual tag (e.g., "your friend Alex (npc_concept_friend_alex)"), you can use `target_id: "npc_concept_friend_alex"` and provide conversational content in `details`. This `target_id` is for contextual understanding by the World Engine, not a lookup in the game state.
    *   **World Interactions:** `look_around`, `move` (Specify `details` like target location ID or name), `world_action` (Specify `details` for generic world interactions not covered by other types).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'Real world'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'Real world' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'Real world' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I need to figure out my next move. Let's see... I don't have any specific instructions at the moment, so I need to rely on my persona and the 'Real world' context to decide what Eleanor Hayes would do. I'm Eleanor, and I'm in a 'Real world' simulation. I need to think about what Eleanor would be doing right now and what she would do next. Without any specific instructions or events, it's a blank slate. I think she'd probably be doing something practical or trying to improve her situation. Maybe she'd be bored and want some entertainment. Since I'm idle, I will use initiate change to trigger something new.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit listless; time to find something interesting to do. Perhaps explore a new cafe or check out a local event.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra.sim_3e912d.status\": \"idle\"}, \"outcome_description\": \"Eleanor Hayes felt a wave of restlessness.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-07 20:52:34,804 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:34,806 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:34,807 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
The current weather in Asheville, NC, United States is 61F with passing clouds. It feels like 61F. The wind is blowing from the north at 7 mph. The humidity is 58%. There is a 0% chance of precipitation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"The current weather in Asheville, NC, United States is 61F with passing clouds. It feels like 61F. The wind is blowing from the north at 7 mph. The humidity is 58%. There is a 0% chance of precipitation.\n"}],"role":"model"},"finish_reason":"STOP","grounding_metadata":{"grounding_chunks":[{"web":{"title":"timeanddate.com","uri":"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEKeyKufhF0QP7pN1l8r_LLrkh-xuGWEJAdOaYVrZnLf1Q3LoOphY1RDq5Zw6Ckh-3YW818_jlokhh5U_TWFkFK-teLBv_j4mZt5fql5SIhxDvtSbXk3-D9EEwWxM4wjs21wTlxkCsdWVmL-w=="}},{"web":{"title":"Weather information for locality: Asheville, administrative_area: NC","uri":"https://www.google.com/search?q=weather+in+Asheville,+NC"}}],"grounding_supports":[{"grounding_chunk_indices":[0],"segment":{"end_index":80,"text":"The current weather in Asheville, NC, United States is 61F with passing clouds"}},{"grounding_chunk_indices":[0,1],"segment":{"end_index":101,"start_index":82,"text":"It feels like 61F"}},{"grounding_chunk_indices":[0],"segment":{"end_index":146,"start_index":103,"text":"The wind is blowing from the north at 7 mph"}},{"grounding_chunk_indices":[0],"segment":{"end_index":167,"start_index":148,"text":"The humidity is 58%"}},{"grounding_chunk_indices":[1],"segment":{"end_index":206,"start_index":169,"text":"There is a 0% chance of precipitation"}}],"retrieval_metadata":{},"search_entry_point":{"rendered_content":"<style>\n.container {\n  align-items: center;\n  border-radius: 8px;\n  display: flex;\n  font-family: Google Sans, Roboto, sans-serif;\n  font-size: 14px;\n  line-height: 20px;\n  padding: 8px 12px;\n}\n.chip {\n  display: inline-block;\n  border: solid 1px;\n  border-radius: 16px;\n  min-width: 14px;\n  padding: 5px 16px;\n  text-align: center;\n  user-select: none;\n  margin: 0 8px;\n  -webkit-tap-highlight-color: transparent;\n}\n.carousel {\n  overflow: auto;\n  scrollbar-width: none;\n  white-space: nowrap;\n  margin-right: -12px;\n}\n.headline {\n  display: flex;\n  margin-right: 4px;\n}\n.gradient-container {\n  position: relative;\n}\n.gradient {\n  position: absolute;\n  transform: translate(3px, -9px);\n  height: 36px;\n  width: 9px;\n}\n@media (prefers-color-scheme: light) {\n  .container {\n    background-color: #fafafa;\n    box-shadow: 0 0 0 1px #0000000f;\n  }\n  .headline-label {\n    color: #1f1f1f;\n  }\n  .chip {\n    background-color: #ffffff;\n    border-color: #d2d2d2;\n    color: #5e5e5e;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #f2f2f2;\n  }\n  .chip:focus {\n    background-color: #f2f2f2;\n  }\n  .chip:active {\n    background-color: #d8d8d8;\n    border-color: #b6b6b6;\n  }\n  .logo-dark {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n  }\n}\n@media (prefers-color-scheme: dark) {\n  .container {\n    background-color: #1f1f1f;\n    box-shadow: 0 0 0 1px #ffffff26;\n  }\n  .headline-label {\n    color: #fff;\n  }\n  .chip {\n    background-color: #2c2c2c;\n    border-color: #3c4043;\n    color: #fff;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #353536;\n  }\n  .chip:focus {\n    background-color: #353536;\n  }\n  .chip:active {\n    background-color: #464849;\n    border-color: #53575b;\n  }\n  .logo-light {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n  }\n}\n</style>\n<div class=\"container\">\n  <div class=\"headline\">\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n    </svg>\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n    </svg>\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n  </div>\n  <div class=\"carousel\">\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXF544gqK8qplrPDkCH1eL_FtLbZSUtcvLjOq1W_2CgWWzUoLm9vXAL8mThr9SnFwG0Bv1NNzMRBLrOJaQwsQhI1pKv42Mn1myQJYdMsokR7fOtMzBGBoz2xqleAFkIaR9ec3yZd-DGJ9Sh9aN1d-8Ind4ybPVNwhZo3jcN4M-he_KjyAsryHRAX8YWpbT4UGJkUeBHb9ueO04sLk7q3Gu-FlGrmmtnxJFnvSc4S-sk=\">current weather Asheville, NC, United States</a>\n  </div>\n</div>\n"},"web_search_queries":["current weather Asheville, NC, United States"]}}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":59,"candidates_tokens_details":[{"modality":"TEXT","token_count":59}],"prompt_token_count":60,"prompt_tokens_details":[{"modality":"TEXT","token_count":60}],"total_token_count":119},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-07 20:52:34,807 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_Weather] Event ID: dm2ZCHD6, Author: SearchLLMAgent
2025-05-07 20:52:34,807 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_Weather] Text response: The current weather in Asheville, NC, United States is 61F with passing clouds. It feels like 61F. The wind is blowing from the north at 7 mph. The humidity is 58%. There is a 0% chance of precipita...
2025-05-07 20:52:34,807 - src.simulation_async - INFO - [WorldInfoGatherer] REAL weather search returned: The current weather in Asheville, NC, United States is 61F with passing clouds. It feels like 61F. The wind is blowing from the north at 7 mph. The humidity is 58%. There is a 0% chance of precipitation.
2025-05-07 20:52:34,812 - grpc._cython.cygrpc - DEBUG - Using AsyncIOEngine.POLLER as I/O engine
2025-05-07 20:52:34,820 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:34,832 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCDD7230>
2025-05-07 20:52:34,832 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FC91D150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:34,858 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCDD65D0>
2025-05-07 20:52:34,859 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:34,859 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCE7F860>
2025-05-07 20:52:34,859 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FC8D9B50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:34,860 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:34,860 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:34,860 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:34,860 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:34,879 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCF5D7F0>
2025-05-07 20:52:34,879 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:34,879 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:34,879 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:34,879 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:34,879 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:35,448 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.weather = {'condition': 'passing clouds', 'temperature_celsius': 16, 'forecast_short': 'Expect partly cloudy skies and dry conditions.', 'timestamp': 23.233999999938533, 'source_category': 'weather'}
2025-05-07 20:52:35,449 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'world_news' with query: 'What are the latest top world news headlines (e.g., politics, social issues, environment, major international events)?'
2025-05-07 20:52:35,457 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:35,458 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:35,470 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCFC7560>
2025-05-07 20:52:35,471 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FC8D9CD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:35,494 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCFC6A80>
2025-05-07 20:52:35,494 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:35,494 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:35,494 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:35,494 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:35,494 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:35,907 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:52:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1034'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:35,907 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:35,908 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:35,908 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:35,908 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:35,908 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:35,909 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor feels that familiar tug of restlessness. The quiet hum of the refr...
2025-05-07 20:52:35,914 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor feels that familiar tug of restlessness. The quiet hum of the refrigerator and the ticking clock seem to amplify the stillness of the afternoon. She knows this feeling; it's the signal to shake things up, to break the monotony before it settles too deep. She thinks about grabbing her keys and heading out, maybe driving to that new cafe everyone's been talking about.
2025-05-07 20:52:35,915 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor feels that familiar tug of restlessness. The quiet hum of the refrigerat...
2025-05-07 20:52:36,360 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:52:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1468'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:36,361 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:36,361 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:36,361 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:36,361 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:36,361 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:36,376 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-07 20:52:36,377 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-07 20:52:36,377 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': "Move to a nearby cafe, maybe 'The Daily Grind' if it's around here. Or any local coffee shop that's known for good coffee."}
2025-05-07 20:52:39,948 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-07 20:52:39,968 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:39,970 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:39,971 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:52:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2608'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:39,971 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:39,972 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:39,972 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:39,972 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:39,972 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:39,973 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_world_news] Event ID: 0CHAMTwN, Author: SearchLLMAgent
2025-05-07 20:52:39,973 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_world_news] Text response: Here are some of the top world news headlines as of today, May 8, 2025:

*   **Tensions between India and Pakistan:** Following a terror attack in Kashmir, India carried out strikes in Pakistan, leadi...
2025-05-07 20:52:39,973 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'world_news' returned: Here are some of the top world news headlines as of today, May 8, 2025:

*   **Tensions between India and Pakistan:** Following a terror attack in Kashmir, India carried out strikes in Pakistan, leading to vows of retaliation and international concern.
*   **Vatican conclave:** Cardinals have entered the Sistine Chapel to elect a new Pope after the death of Pope Francis, with the first vote being inconclusive.
*   **Ukraine War:** Russia has announced a three-day ceasefire in Ukraine to mark WWI
2025-05-07 20:52:39,988 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2EC0A9D00>
2025-05-07 20:52:39,988 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FCE4FB50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:40,008 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2EC0ABC20>
2025-05-07 20:52:40,008 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:40,009 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:40,009 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:40,009 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:40,009 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:40,757 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:53:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=739'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:40,757 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:40,757 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:40,758 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:40,758 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:40,758 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:40,759 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 900.0, "results": {"simulacra.sim_3e912d.location": "The ...
2025-05-07 20:52:40,759 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-07 20:52:40,769 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-07 20:52:40,769 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {'simulacra.sim_3e912d.location': 'The Daily Grind'}
2025-05-07 20:52:40,769 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 930.311999999918
2025-05-07 20:52:40,769 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: move - Details: Move to a nearby cafe, maybe 'The Daily Grind' if it's around here. Or any local coffee shop that's 
2025-05-07 20:52:40,769 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 930.3s. Outcome: Eleanor Hayes traveled to The Daily Grind.
2025-05-07 20:52:40,770 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'Real world' for actor Eleanor Hayes at location default_start_location
2025-05-07 20:52:40,770 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes traveled to The Daily Grind.'
2025-05-07 20:52:43,498 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:43,500 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:43,501 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'Global Tensions Rise: India-Pakistan Conflict, Vatican Conclave, Ukraine War, and US Protests', 'summary': 'International tensions escalate with India-Pakistan conflict, a papal election, a fragile ceasefire in Ukraine, US political issues, and pro-Palestinian protests at Columbia University.', 'timestamp': 23.233999999938533, 'source_category': 'world_news'}]
2025-05-07 20:52:43,501 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'regional_news' with query: 'What are the latest top national news headlines for United States?'
2025-05-07 20:52:43,509 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:43,514 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:43,526 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCF5F020>
2025-05-07 20:52:43,526 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2EC097050> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:43,528 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCDD7620>
2025-05-07 20:52:43,528 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FCDE6DD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:43,544 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCE14B00>
2025-05-07 20:52:43,544 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:43,545 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:43,545 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:43,545 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:43,545 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:43,548 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FC845400>
2025-05-07 20:52:43,549 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:43,549 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:43,549 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:43,549 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:43,549 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:45,090 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
2025-05-07 20:52:45,179 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:53:06 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1621'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:45,179 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:45,179 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:45,180 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:45,180 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:45,180 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:45,181 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "The bell above the door of The Daily Grind jingles as Eleanor steps inside...
2025-05-07 20:52:45,186 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = The bell above the door of The Daily Grind jingles as Eleanor steps inside, a momentary fanfare announcing her arrival. The aroma of freshly ground coffee beans hangs heavy in the air, a comforting blanket against the slightly overcast afternoon. The cafe is bustling with activity; a barista (npc_concept_barista_01) expertly steams milk behind the counter, the hiss and froth a rhythmic counterpoint to the low murmur of conversations swirling around her. Sunlight streams in through the large front windows, illuminating dust motes dancing in the air.
2025-05-07 20:52:45,186 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: The bell above the door of The Daily Grind jingles as Eleanor steps inside, a mo...
2025-05-07 20:52:46,279 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:53:07 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2718'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:46,279 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:46,279 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:46,280 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:46,280 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:46,280 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:46,281 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_regional_news] Event ID: kpGr0VXk, Author: SearchLLMAgent
2025-05-07 20:52:46,281 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_regional_news] Text response: Here are some of the latest top national news headlines for the United States:

*   **Migrant deportations:** The Trump administration is planning to deport migrants to Libya, and some attorneys are t...
2025-05-07 20:52:46,281 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'regional_news' returned: Here are some of the latest top national news headlines for the United States:

*   **Migrant deportations:** The Trump administration is planning to deport migrants to Libya, and some attorneys are trying to block the deportations.
*   **Politics:** A U.S. judge is considering ordering Trump to return Venezuelans from El Salvador.
*   **Trump's picks:** Donald Trump has tapped a wellness influencer close to Robert F. Kennedy Jr. for surgeon general.
*   **Infrastructure:** The Feds vow to overh
2025-05-07 20:52:47,053 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': "US News: Deportations, Trump's Picks, Tariffs & Weather", 'summary': "National news includes potential migrant deportations to Libya, Trump's surgeon general pick, economic uncertainty over tariffs, infrastructure updates, and warnings of extreme weather.", 'timestamp': 23.233999999938533, 'source_category': 'regional_news'}, {'headline': 'Global Tensions Rise: India-Pakistan Conflict, Vatican Conclave, Ukraine War, and US Protests', 'summary': 'International tensions escalate with India-Pakistan conflict, a papal election, a fragile ceasefire in Ukraine, US political issues, and pro-Palestinian protests at Columbia University.', 'timestamp': 23.233999999938533, 'source_category': 'world_news'}]
2025-05-07 20:52:47,053 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'local_news' with query: 'What are the top latest local news headlines for Asheville, NC?'
2025-05-07 20:52:47,062 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:47,064 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:47,080 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FC92F1D0>
2025-05-07 20:52:47,081 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FCE4C150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:47,099 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FC92D2B0>
2025-05-07 20:52:47,099 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:47,099 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:47,099 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:47,099 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:47,099 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:49,175 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:53:10 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2063'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:49,175 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:49,175 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:49,176 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:49,176 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:49,176 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:49,177 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_local_news] Event ID: zsCGHzgg, Author: SearchLLMAgent
2025-05-07 20:52:49,177 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_local_news] Text response: Here are some of the latest local news headlines for Asheville, NC:

*   **Drug and gun arrests:** Asheville police made two arrests in separate incidents in a west Asheville neighborhood as part of o...
2025-05-07 20:52:49,177 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'local_news' returned: Here are some of the latest local news headlines for Asheville, NC:

*   **Drug and gun arrests:** Asheville police made two arrests in separate incidents in a west Asheville neighborhood as part of ongoing efforts to curb drug use and gun violence.
*   **Storm recovery:** The City of Asheville is beginning the process to rebuild the storm-damaged French Broad Riverfront Parks System.
*   **Airport expansion:** Asheville Regional Airport announced an exciting new dining & retail lineup for its t
2025-05-07 20:52:50,010 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'Asheville News: Crime, Recovery, and Taxes', 'summary': 'Asheville grapples with drug and gun arrests, begins storm recovery, expands its airport, considers property tax hikes, and supports flood relief, while Buncombe County reduces some permit fees.', 'timestamp': 23.233999999938533, 'source_category': 'local_news'}, {'headline': "US News: Deportations, Trump's Picks, Tariffs & Weather", 'summary': "National news includes potential migrant deportations to Libya, Trump's surgeon general pick, economic uncertainty over tariffs, infrastructure updates, and warnings of extreme weather.", 'timestamp': 23.233999999938533, 'source_category': 'regional_news'}, {'headline': 'Global Tensions Rise: India-Pakistan Conflict, Vatican Conclave, Ukraine War, and US Protests', 'summary': 'International tensions escalate with India-Pakistan conflict, a papal election, a fragile ceasefire in Ukraine, US political issues, and pro-Palestinian protests at Columbia University.', 'timestamp': 23.233999999938533, 'source_category': 'world_news'}]
2025-05-07 20:52:50,011 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'pop_culture' with query: 'What are the top latest United States  pop culture trends and entertainment news headlines (e.g., movies, music, viral trends)?'
2025-05-07 20:52:50,019 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:50,023 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:50,043 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FCF5C950>
2025-05-07 20:52:50,043 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2FC8DA550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:50,063 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000002B2FC845400>
2025-05-07 20:52:50,064 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:50,064 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:50,064 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:50,064 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:50,064 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:52:50,223 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
2025-05-07 20:52:53,271 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:53:14 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3192'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:52:53,271 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:52:53,271 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:52:53,272 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:52:53,272 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:52:53,273 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:52:53,274 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_pop_culture] Event ID: XQHEYPOw, Author: SearchLLMAgent
2025-05-07 20:52:53,274 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_pop_culture] Text response: Here are some of the latest pop culture and entertainment news headlines in the United States:

*   **Music:** Kacey Musgraves is defending traditional country music, saying it's not as easy as it see...
2025-05-07 20:52:53,274 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'pop_culture' returned: Here are some of the latest pop culture and entertainment news headlines in the United States:

*   **Music:** Kacey Musgraves is defending traditional country music, saying it's not as easy as it seems. Taylor Swift was the most mentioned artist in email campaigns.
*   **Television:** CBS has canceled 7 TV shows this year, including FBI: Most Wanted and FBI: International. CBS's Fall 2025 schedule features 5 new TV shows, with 3 returning series confirmed for 2026. Sonequa Martin-Green will sta
2025-05-07 20:52:54,089 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.pop_culture_updates = [{'headline': 'Pop Culture Buzz: Music Feuds, TV Shakeups, and Celebrity Sightings', 'summary': 'The latest pop culture news includes Kacey Musgraves defending country music, CBS canceling and adding TV shows, Trump threatening movie tariffs, and celebrity news featuring Rihanna, Kylie Jenner, and Kamala Harris.', 'timestamp': 23.233999999938533, 'source_category': 'pop_culture'}]
2025-05-07 20:52:54,090 - src.simulation_async - INFO - [WorldInfoGatherer] World feeds updated. Next check in 3600.0 sim_seconds.
2025-05-07 20:52:55,340 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
2025-05-07 20:52:59,262 - src.simulation_async - INFO - [NarrativeImageGenerator] Requesting image for narrative (T53.2): "The bell above the door of The Daily Grind jingles as Eleanor steps inside, a momentary fanfare anno..."
2025-05-07 20:52:59,263 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-07 20:52:59,264 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-07 20:52:59,275 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B2FCE7E5A0>
2025-05-07 20:52:59,275 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002B2EC095AD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-07 20:52:59,289 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B2FC92F470>
2025-05-07 20:52:59,290 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-07 20:52:59,290 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-07 20:52:59,290 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-07 20:52:59,290 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-07 20:52:59,290 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-07 20:53:00,477 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
2025-05-07 20:53:04,810 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 00:53:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=5510'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-07 20:53:04,810 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-preview-image-generation:generateContent "HTTP/1.1 200 OK"
2025-05-07 20:53:04,811 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-07 20:53:04,999 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-07 20:53:04,999 - httpcore.http11 - DEBUG - response_closed.started
2025-05-07 20:53:04,999 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-07 20:53:05,002 - google_genai.models - INFO - AFC remote call 1 is done.
2025-05-07 20:53:05,024 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-05-07 20:53:05,024 - PIL.PngImagePlugin - DEBUG - STREAM b'zTXt' 41 137
2025-05-07 20:53:05,024 - PIL.PngImagePlugin - DEBUG - STREAM b'iTXt' 190 647
2025-05-07 20:53:05,024 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 849 8192
2025-05-07 20:53:05,142 - src.simulation_async - INFO - [NarrativeImageGenerator] Successfully generated and saved image: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images\narrative_T53_20250507_205305_025454.png
2025-05-07 20:53:05,577 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
2025-05-07 20:53:10,689 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
2025-05-07 20:53:15,821 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_interrupt_probability = None
