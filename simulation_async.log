2025-05-06 22:24:01,643 - __main__ - INFO - --- Application Start (main_async.py) --- Logging to: simulation_async.log
2025-05-06 22:24:01,645 - asyncio - DEBUG - Using selector: SelectSelector
2025-05-06 22:24:01,657 - src.simulation_async - INFO - ADK InMemoryMemoryService initialized.
2025-05-06 22:24:01,657 - src.simulation_async - INFO - Google Generative AI configured.
2025-05-06 22:24:01,659 - src.simulation_async - INFO - Starting simulation initialization.
2025-05-06 22:24:01,659 - src.loop_utils - INFO - Starting simulation state loading/initialization.
2025-05-06 22:24:01,659 - src.loop_utils - INFO - No instance UUID specified, searching for the latest world config...
2025-05-06 22:24:01,660 - src.loop_utils - INFO - Found latest world config file: C:\Users\dshea\Desktop\TheSimulation\data\world_config_05e07dad-f24b-420b-822c-1ae7862220f6.json.
2025-05-06 22:24:01,662 - src.loop_utils - INFO - Successfully loaded world config for UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-06 22:24:01,664 - src.loop_utils - INFO - Found 1 life summary file(s) for UUID 05e07dad-f24b-420b-822c-1ae7862220f6.
2025-05-06 22:24:01,664 - src.loop_utils - INFO - No usable existing state for UUID 05e07dad-f24b-420b-822c-1ae7862220f6. Creating new state...
2025-05-06 22:24:01,666 - src.loop_utils - INFO - Generating blank state structure for new UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-06 22:24:01,666 - src.loop_utils - INFO - Initialized new state for UUID 05e07dad-f24b-420b-822c-1ae7862220f6 with 1 simulacra.
2025-05-06 22:24:01,666 - src.loop_utils - INFO - Syncing from world_config and resetting objects for UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-06 22:24:01,666 - src.loop_utils - INFO - Synced WORLD_TEMPLATE_DETAILS_KEY from world_config: type='real', city='Asheville'
2025-05-06 22:24:01,666 - src.loop_utils - INFO - 'objects' key not found or empty in world_config.json. State 'objects' will be empty.
2025-05-06 22:24:01,666 - src.loop_utils - WARNING - Added missing 'mood' key to 'world_template_details' with default value 'neutral_descriptive'.
2025-05-06 22:24:01,666 - src.loop_utils - INFO - Saving new state file: C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-06 22:24:01,667 - src.loop_utils - INFO - Saved data to C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-06 22:24:01,667 - src.simulation_async - INFO - Initialization complete. Instance 05e07dad-f24b-420b-822c-1ae7862220f6 ready with 1 simulacra.
2025-05-06 22:24:01,669 - src.simulation_async - INFO - ADK Session created: sim_session_05e07dad-f24b-420b-822c-1ae7862220f6.
2025-05-06 22:24:01,669 - src.simulation_async - INFO - Created 1 simulacra agents.
2025-05-06 22:24:01,669 - src.simulation_async - INFO - Main ADK Runner initialized.
2025-05-06 22:24:01,669 - src.simulation_async - INFO - Dedicated Search Agent Runner initialized.
2025-05-06 22:24:01,675 - src.simulation_async - INFO - Started 6 tasks.
2025-05-06 22:24:01,675 - src.simulation_async - INFO - [TimeManager] Task started.
2025-05-06 22:24:01,675 - src.simulation_async - INFO - [InteractionDispatcher] Task started.
2025-05-06 22:24:01,675 - src.simulation_async - INFO - [WorldInfoGatherer] Task started.
2025-05-06 22:24:01,675 - src.simulation_async - INFO - [NarrationTask] Task started.
2025-05-06 22:24:01,676 - src.simulation_async - INFO - [WorldEngineLLM] Task started.
2025-05-06 22:24:01,676 - src.simulation_async - INFO - [Eleanor Hayes] LLM Agent task started.
2025-05-06 22:24:01,676 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending initial context prompt as agent is idle.
2025-05-06 22:24:01,784 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:01,784 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The familiar, everyday real world; starting the morning routine at home.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The familiar, everyday real world; starting the morning routine at home.' atmosphere.

**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The familiar, everyday real world; starting the morning routine at home.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The familiar, everyday real world; starting the morning routine at home.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The familiar, everyday real world; starting the morning routine at home.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
    *   **World Interactions:** `look_around`, `move` (Specify `details`), `world_action` (Specify `details`).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The familiar, everyday real world; starting the morning routine at home.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The familiar, everyday real world; starting the morning routine at home.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The familiar, everyday real world; starting the morning routine at home.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"Handle the requests as specified in the System Instruction."}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-06 22:24:01,784 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:01,790 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:01,808 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFD4F0>
2025-05-06 22:24:01,808 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A6A26BD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:01,827 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A649E1B0>
2025-05-06 22:24:01,828 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:01,828 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:01,828 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:01,828 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:01,828 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:02,877 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1038'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:02,879 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:02,879 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:02,879 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:02,879 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:02,879 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:02,880 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.", "action_type": "think", "details": "Recalling the last observation/event to decide on the next action."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.3093677560488383}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":96,"candidates_tokens_details":[{"modality":"TEXT","token_count":96}],"prompt_token_count":1166,"prompt_tokens_details":[{"modality":"TEXT","token_count":1166}],"total_token_count":1262},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:02,896 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:02,896 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (think on N/A) classified as 'environment'.
2025-05-06 22:24:02,897 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'think', 'target_id': None, 'details': 'Recalling the last observation/event to decide on the next action.'}
2025-05-06 22:24:02,897 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (think).
2025-05-06 22:24:02,897 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: kACBMhmJ
2025-05-06 22:24:02,905 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:02,905 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.

**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Actor Location ID 
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Current World Time
- Target Entity State (if applicable)
- Location State
- World Rules
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`: Check `interactive` property, object properties (`toggleable`, `lockable`), and current state.
            *   `talk`: Check target is simulacra, same location. Results: `simulacra.[target_id].last_observation`.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`: Check `connected_locations`. Results: `simulacra.[actor_id].location`.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra.[actor_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra.[actor_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"`). Empty `{}` for invalid.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-06 22:24:02,906 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:02,908 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:02,921 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A99C70>
2025-05-06 22:24:02,921 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F083D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:02,939 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED2F30>
2025-05-06 22:24:02,939 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:02,940 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:02,940 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:02,940 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:02,940 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:03,639 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=691'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:03,639 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:03,640 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:03,640 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:03,640 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:03,640 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:03,641 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": true, "duration": 1.0, "results": {}, "outcome_description": "Eleanor Hayes paused to consider her next move."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 1.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes paused to consider her next move.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.12257012128829955}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":40,"candidates_tokens_details":[{"modality":"TEXT","token_count":40}],"prompt_token_count":1428,"prompt_tokens_details":[{"modality":"TEXT","token_count":1428}],"total_token_count":1468},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:03,641 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 1.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:24:03,641 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:03,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:03,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:03,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 2.187000000034459
2025-05-06 22:24:03,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: think - Details: Recalling the last observation/event to decide on the next action.
2025-05-06 22:24:03,650 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 2.2s. Outcome: Eleanor Hayes paused to consider her next move.
2025-05-06 22:24:03,650 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:03,650 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes paused to consider her next move.'
2025-05-06 22:24:03,651 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: K5nKZxRL
2025-05-06 22:24:03,651 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: kACBMhmJ
2025-05-06 22:24:03,658 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:03,658 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:

You are the Narrator for **TheSimulation**. The established **World Style/Mood** for this simulation is **'The familiar, everyday real world; starting the morning routine at home.'**. Your role is to weave the factual outcomes of actions into an engaging and atmospheric narrative, STRICTLY matching this 'The familiar, everyday real world; starting the morning routine at home.' style.

**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Original Intent
- Factual Outcome Description
- State Changes (Results)
- Current World Time
- Current World Feeds (Weather, recent major news - for subtle background flavor)
- Recent Narrative History (Last ~5 entries)

**Your Task:**
1.  **Understand the Event:** Read the Actor, Intent, and Factual Outcome Description.
2.  **Recall the Mood:** Remember the required narrative style is **'The familiar, everyday real world; starting the morning routine at home.'**.
3.  **Consider the Context:** Note Recent Narrative History. **IGNORE any `World Style/Mood` in `Recent Narrative History`. Prioritize the established 'The familiar, everyday real world; starting the morning routine at home.' style.**
4.  **Generate Narrative:** Write a single, engaging narrative paragraph in the **present tense** describing the event based on the Factual Outcome Description.
    *   **Style Adherence:** STRICTLY adhere to **'The familiar, everyday real world; starting the morning routine at home.'**. Infuse with appropriate atmosphere, sensory details, and tone.
    *   **Show, Don't Just Tell.**
    *   **Incorporate Intent (Optional).**
    *   **Flow:** Ensure reasonable flow.

**Output:**
- Output ONLY the final narrative string. Do NOT include explanations, prefixes, or JSON formatting.


You are an agent. Your internal name is "NarrationLLMAgent".

 The description about you is "LLM Narrator: Generates 'The familiar, everyday real world; starting the morning routine at home.' narrative based on factual outcomes."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 1.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes paused to consider her next move.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-06 22:24:03,658 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:03,661 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:03,679 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F07770>
2025-05-06 22:24:03,679 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBFDD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:03,697 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F076B0>
2025-05-06 22:24:03,697 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:03,697 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:03,697 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:03,698 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:03,698 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:03,857 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 2.2 (due at 2.2).
2025-05-06 22:24:03,857 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:24:03,857 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:24:03,857 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:24:03,918 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:24:03,918 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:24:03,918 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: K5nKZxRL
2025-05-06 22:24:03,927 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:03,927 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The familiar, everyday real world; starting the morning routine at home.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The familiar, everyday real world; starting the morning routine at home.' atmosphere.

**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The familiar, everyday real world; starting the morning routine at home.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The familiar, everyday real world; starting the morning routine at home.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The familiar, everyday real world; starting the morning routine at home.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
    *   **World Interactions:** `look_around`, `move` (Specify `details`), `world_action` (Specify `details`).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The familiar, everyday real world; starting the morning routine at home.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The familiar, everyday real world; starting the morning routine at home.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The familiar, everyday real world; starting the morning routine at home.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 1.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes paused to consider her next move.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-06 22:24:03,927 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:03,930 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:03,946 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED3740>
2025-05-06 22:24:03,946 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F08350> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:03,965 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A68E3E90>
2025-05-06 22:24:03,965 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:03,965 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:03,965 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:03,965 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:03,965 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:04,371 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=663'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:04,372 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:04,372 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:04,373 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:04,373 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:04,373 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:04,373 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the momentary silence as she considers what to do next.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the momentary silence as she considers what to do next.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.2361990080939399}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":36,"candidates_tokens_details":[{"modality":"TEXT","token_count":36}],"prompt_token_count":621,"prompt_tokens_details":[{"modality":"TEXT","token_count":621}],"total_token_count":657},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:04,373 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the moment...
2025-05-06 22:24:04,378 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the momentary silence as she considers what to do next.
2025-05-06 22:24:04,378 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerato...
2025-05-06 22:24:05,208 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1232'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:05,209 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:05,209 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:05,210 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:05,210 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:05,210 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:05,211 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Right, I paused to consider my next move. I'm still in that 'familiar, everyday real world' setting, so there's no immediate crisis. I should probably decide what I want to accomplish this morning. Do I need to get ready for work, or is it the weekend? What day is it? I can't remember. I need to check my calendar or something similar to determine what I should be doing today. I should look around the room to find something I can use to check the day.", "action_type": "look_around", "details": "Looking around to find something to check the day."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Right, I paused to consider my next move. I'm still in that 'familiar, everyday real world' setting, so there's no immediate crisis. I should probably decide what I want to accomplish this morning. Do I need to get ready for work, or is it the weekend? What day is it? I can't remember. I need to check my calendar or something similar to determine what I should be doing today. I should look around the room to find something I can use to check the day.\", \"action_type\": \"look_around\", \"details\": \"Looking around to find something to check the day.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.518435018045919}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":143,"candidates_tokens_details":[{"modality":"TEXT","token_count":143}],"prompt_token_count":1304,"prompt_tokens_details":[{"modality":"TEXT","token_count":1304}],"total_token_count":1447},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:05,225 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:05,225 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-06 22:24:05,225 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'Looking around to find something to check the day.'}
2025-05-06 22:24:05,225 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-06 22:24:05,225 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: sQ7wABvB
2025-05-06 22:24:05,225 - google.adk.runners - WARNING - Event from an unknown agent: NarrationLLMAgent, event id: mNw7TqMX
2025-05-06 22:24:05,234 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:05,234 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.

**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Actor Location ID 
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Current World Time
- Target Entity State (if applicable)
- Location State
- World Rules
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`: Check `interactive` property, object properties (`toggleable`, `lockable`), and current state.
            *   `talk`: Check target is simulacra, same location. Results: `simulacra.[target_id].last_observation`.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`: Check `connected_locations`. Results: `simulacra.[actor_id].location`.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra.[actor_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra.[actor_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"`). Empty `{}` for invalid.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 1.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes paused to consider her next move.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the momentary silence as she considers what to do next.\n"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Right, I paused to consider my next move. I'm still in that 'familiar, everyday real world' setting, so there's no immediate crisis. I should probably decide what I want to accomplish this morning. Do I need to get ready for work, or is it the weekend? What day is it? I can't remember. I need to check my calendar or something similar to determine what I should be doing today. I should look around the room to find something I can use to check the day.\", \"action_type\": \"look_around\", \"details\": \"Looking around to find something to check the day.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-06 22:24:05,234 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:05,237 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:05,247 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F04EF0>
2025-05-06 22:24:05,247 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0A450> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:05,267 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6AEC0B0>
2025-05-06 22:24:05,268 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:05,268 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:05,268 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:05,268 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:05,268 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:05,912 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=634'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:05,913 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:05,913 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:05,913 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:05,913 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:05,913 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:05,914 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes looked around the room, searching for something to check the date."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 5.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes looked around the room, searching for something to check the date.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.05682573111160942}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":46,"candidates_tokens_details":[{"modality":"TEXT","token_count":46}],"prompt_token_count":1680,"prompt_tokens_details":[{"modality":"TEXT","token_count":1680}],"total_token_count":1726},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:05,914 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:24:05,914 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:05,924 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:05,924 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:05,924 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 8.46799999999348
2025-05-06 22:24:05,924 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: look_around - Details: Looking around to find something to check the day.
2025-05-06 22:24:05,924 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 8.5s. Outcome: Eleanor Hayes looked around the room, searching for something to check the date.
2025-05-06 22:24:05,924 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:05,924 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around the room, searching for something to check the date.'
2025-05-06 22:24:05,925 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: DYyyepmp
2025-05-06 22:24:05,925 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: sQ7wABvB
2025-05-06 22:24:05,934 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:05,934 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:

You are the Narrator for **TheSimulation**. The established **World Style/Mood** for this simulation is **'The familiar, everyday real world; starting the morning routine at home.'**. Your role is to weave the factual outcomes of actions into an engaging and atmospheric narrative, STRICTLY matching this 'The familiar, everyday real world; starting the morning routine at home.' style.

**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Original Intent
- Factual Outcome Description
- State Changes (Results)
- Current World Time
- Current World Feeds (Weather, recent major news - for subtle background flavor)
- Recent Narrative History (Last ~5 entries)

**Your Task:**
1.  **Understand the Event:** Read the Actor, Intent, and Factual Outcome Description.
2.  **Recall the Mood:** Remember the required narrative style is **'The familiar, everyday real world; starting the morning routine at home.'**.
3.  **Consider the Context:** Note Recent Narrative History. **IGNORE any `World Style/Mood` in `Recent Narrative History`. Prioritize the established 'The familiar, everyday real world; starting the morning routine at home.' style.**
4.  **Generate Narrative:** Write a single, engaging narrative paragraph in the **present tense** describing the event based on the Factual Outcome Description.
    *   **Style Adherence:** STRICTLY adhere to **'The familiar, everyday real world; starting the morning routine at home.'**. Infuse with appropriate atmosphere, sensory details, and tone.
    *   **Show, Don't Just Tell.**
    *   **Incorporate Intent (Optional).**
    *   **Flow:** Ensure reasonable flow.

**Output:**
- Output ONLY the final narrative string. Do NOT include explanations, prefixes, or JSON formatting.


You are an agent. Your internal name is "NarrationLLMAgent".

 The description about you is "LLM Narrator: Generates 'The familiar, everyday real world; starting the morning routine at home.' narrative based on factual outcomes."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 1.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes paused to consider her next move.\"}\n```"}],"role":"user"}
{"parts":[{"text":"Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the momentary silence as she considers what to do next.\n"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Right, I paused to consider my next move. I'm still in that 'familiar, everyday real world' setting, so there's no immediate crisis. I should probably decide what I want to accomplish this morning. Do I need to get ready for work, or is it the weekend? What day is it? I can't remember. I need to check my calendar or something similar to determine what I should be doing today. I should look around the room to find something I can use to check the day.\", \"action_type\": \"look_around\", \"details\": \"Looking around to find something to check the day.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 5.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes looked around the room, searching for something to check the date.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-06 22:24:05,934 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:05,937 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:05,945 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F43E60>
2025-05-06 22:24:05,945 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBF050> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:05,962 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F43D70>
2025-05-06 22:24:05,962 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:05,962 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:05,963 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:05,963 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:05,963 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:06,707 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=736'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:06,708 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:06,708 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:06,708 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:06,708 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:06,708 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:06,710 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
Eleanor Hayes (sim_3e912d) scans the kitchen, her gaze drifting over the familiar countertop cluttered with mail and a fruit bowl, past the calendar hanging askew by the refrigerator, all in search of something to jog her memory of the day.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"Eleanor Hayes (sim_3e912d) scans the kitchen, her gaze drifting over the familiar countertop cluttered with mail and a fruit bowl, past the calendar hanging askew by the refrigerator, all in search of something to jog her memory of the day.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.4306909040971236}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":55,"candidates_tokens_details":[{"modality":"TEXT","token_count":55}],"prompt_token_count":879,"prompt_tokens_details":[{"modality":"TEXT","token_count":879}],"total_token_count":934},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:06,710 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) scans the kitchen, her gaze drifting over the familiar countertop clutter...
2025-05-06 22:24:06,715 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) scans the kitchen, her gaze drifting over the familiar countertop cluttered with mail and a fruit bowl, past the calendar hanging askew by the refrigerator, all in search of something to jog her memory of the day.
2025-05-06 22:24:06,715 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) scans the kitchen, her gaze drifting over the familia...
2025-05-06 22:24:10,223 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 8.5 (due at 8.5).
2025-05-06 22:24:10,223 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:24:10,223 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:24:10,223 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:24:10,224 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:24:10,224 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:24:10,224 - google.adk.runners - WARNING - Event from an unknown agent: NarrationLLMAgent, event id: BiOUhart
2025-05-06 22:24:10,224 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: DYyyepmp
2025-05-06 22:24:10,233 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:10,233 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The familiar, everyday real world; starting the morning routine at home.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The familiar, everyday real world; starting the morning routine at home.' atmosphere.

**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The familiar, everyday real world; starting the morning routine at home.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The familiar, everyday real world; starting the morning routine at home.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The familiar, everyday real world; starting the morning routine at home.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
    *   **World Interactions:** `look_around`, `move` (Specify `details`), `world_action` (Specify `details`).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The familiar, everyday real world; starting the morning routine at home.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The familiar, everyday real world; starting the morning routine at home.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The familiar, everyday real world; starting the morning routine at home.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 1.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes paused to consider her next move.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the momentary silence as she considers what to do next.\n"}],"role":"user"}
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Right, I paused to consider my next move. I'm still in that 'familiar, everyday real world' setting, so there's no immediate crisis. I should probably decide what I want to accomplish this morning. Do I need to get ready for work, or is it the weekend? What day is it? I can't remember. I need to check my calendar or something similar to determine what I should be doing today. I should look around the room to find something I can use to check the day.\", \"action_type\": \"look_around\", \"details\": \"Looking around to find something to check the day.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 5.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes looked around the room, searching for something to check the date.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: Eleanor Hayes (sim_3e912d) scans the kitchen, her gaze drifting over the familiar countertop cluttered with mail and a fruit bowl, past the calendar hanging askew by the refrigerator, all in search of something to jog her memory of the day.\n"}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-06 22:24:10,233 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:10,236 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:10,251 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FD7E90>
2025-05-06 22:24:10,251 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A6A26BD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:10,274 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FD77D0>
2025-05-06 22:24:10,275 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:10,275 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:10,275 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:10,275 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:10,275 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:11,312 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1025'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:11,312 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:11,312 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:11,312 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:11,312 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:11,312 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:11,313 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Ah, a calendar! Hanging askew by the refrigerator, no less. Perfect. I should go check it to see what day it is and figure out my plans for the day. It's exactly the sort of thing one would find in a 'familiar, everyday real world; starting the morning routine at home.'", "action_type": "use", "target_id": "calendar_790", "details": "Check the calendar by the refrigerator to see what day it is."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Ah, a calendar! Hanging askew by the refrigerator, no less. Perfect. I should go check it to see what day it is and figure out my plans for the day. It's exactly the sort of thing one would find in a 'familiar, everyday real world; starting the morning routine at home.'\", \"action_type\": \"use\", \"target_id\": \"calendar_790\", \"details\": \"Check the calendar by the refrigerator to see what day it is.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.4077472852623981}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":115,"candidates_tokens_details":[{"modality":"TEXT","token_count":115}],"prompt_token_count":1620,"prompt_tokens_details":[{"modality":"TEXT","token_count":1620}],"total_token_count":1735},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:11,328 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:11,331 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on calendar_790) classified as 'environment'.
2025-05-06 22:24:11,331 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'calendar_790', 'details': 'Check the calendar by the refrigerator to see what day it is.'}
2025-05-06 22:24:11,331 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-06 22:24:11,332 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: yaP4xqWZ
2025-05-06 22:24:11,332 - google.adk.runners - WARNING - Event from an unknown agent: NarrationLLMAgent, event id: BiOUhart
2025-05-06 22:24:11,342 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:11,342 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.

**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Actor Location ID 
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Current World Time
- Target Entity State (if applicable)
- Location State
- World Rules
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`: Check `interactive` property, object properties (`toggleable`, `lockable`), and current state.
            *   `talk`: Check target is simulacra, same location. Results: `simulacra.[target_id].last_observation`.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`: Check `connected_locations`. Results: `simulacra.[actor_id].location`.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra.[actor_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra.[actor_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"`). Empty `{}` for invalid.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 1.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes paused to consider her next move.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the momentary silence as she considers what to do next.\n"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Right, I paused to consider my next move. I'm still in that 'familiar, everyday real world' setting, so there's no immediate crisis. I should probably decide what I want to accomplish this morning. Do I need to get ready for work, or is it the weekend? What day is it? I can't remember. I need to check my calendar or something similar to determine what I should be doing today. I should look around the room to find something I can use to check the day.\", \"action_type\": \"look_around\", \"details\": \"Looking around to find something to check the day.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 5.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes looked around the room, searching for something to check the date.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: Eleanor Hayes (sim_3e912d) scans the kitchen, her gaze drifting over the familiar countertop cluttered with mail and a fruit bowl, past the calendar hanging askew by the refrigerator, all in search of something to jog her memory of the day.\n"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Ah, a calendar! Hanging askew by the refrigerator, no less. Perfect. I should go check it to see what day it is and figure out my plans for the day. It's exactly the sort of thing one would find in a 'familiar, everyday real world; starting the morning routine at home.'\", \"action_type\": \"use\", \"target_id\": \"calendar_790\", \"details\": \"Check the calendar by the refrigerator to see what day it is.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-06 22:24:11,342 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:11,346 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:11,361 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A683FF20>
2025-05-06 22:24:11,361 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0BCD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:11,380 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6AEC0B0>
2025-05-06 22:24:11,380 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:11,380 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:11,380 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:11,380 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:11,380 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:11,681 - src.simulation_async - INFO - [WorldInfoGatherer] Updating world feeds at sim_time 10.0 for location: Asheville, NC, United States
2025-05-06 22:24:11,681 - src.simulation_async - WARNING - Path segment 'world_feeds' not found or not dict in 'world_feeds.last_update_sim_time'. Creating.
2025-05-06 22:24:11,682 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.last_update_sim_time = 9.984000000054948
2025-05-06 22:24:11,682 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL weather search for 'Asheville, NC, United States' with query: 'What is the current weather in Asheville, NC, United States?'
2025-05-06 22:24:11,690 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:11,690 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
I can answer your questions by searching the internet. Just ask me anything!

You are an agent. Your internal name is "SearchLLMAgent".

 The description about you is "Dedicated LLM Agent for performing Google Searches."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"What is the current weather in Asheville, NC, United States?"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-06 22:24:11,690 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:11,692 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:11,704 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F05D00>
2025-05-06 22:24:11,704 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F30AD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:11,725 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F06810>
2025-05-06 22:24:11,725 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:11,725 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:11,725 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:11,725 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:11,725 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:12,096 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=703'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:12,096 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:12,096 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:12,096 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:12,096 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:12,096 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:12,097 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Hayes walked over to the calendar and checked the date."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 10.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes walked over to the calendar and checked the date.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.13673554767261853}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":44,"candidates_tokens_details":[{"modality":"TEXT","token_count":44}],"prompt_token_count":1929,"prompt_tokens_details":[{"modality":"TEXT","token_count":1929}],"total_token_count":1973},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:12,097 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:24:12,097 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:12,106 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:12,106 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:12,106 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 19.64000000001397
2025-05-06 22:24:12,106 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: use - Details: Check the calendar by the refrigerator to see what day it is.
2025-05-06 22:24:12,106 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 19.6s. Outcome: Eleanor Hayes walked over to the calendar and checked the date.
2025-05-06 22:24:12,106 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:12,106 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes walked over to the calendar and checked the date.'
2025-05-06 22:24:12,107 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: nbKtQXfv
2025-05-06 22:24:12,107 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: yaP4xqWZ
2025-05-06 22:24:12,116 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-06 22:24:12,116 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:

You are the Narrator for **TheSimulation**. The established **World Style/Mood** for this simulation is **'The familiar, everyday real world; starting the morning routine at home.'**. Your role is to weave the factual outcomes of actions into an engaging and atmospheric narrative, STRICTLY matching this 'The familiar, everyday real world; starting the morning routine at home.' style.

**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Original Intent
- Factual Outcome Description
- State Changes (Results)
- Current World Time
- Current World Feeds (Weather, recent major news - for subtle background flavor)
- Recent Narrative History (Last ~5 entries)

**Your Task:**
1.  **Understand the Event:** Read the Actor, Intent, and Factual Outcome Description.
2.  **Recall the Mood:** Remember the required narrative style is **'The familiar, everyday real world; starting the morning routine at home.'**.
3.  **Consider the Context:** Note Recent Narrative History. **IGNORE any `World Style/Mood` in `Recent Narrative History`. Prioritize the established 'The familiar, everyday real world; starting the morning routine at home.' style.**
4.  **Generate Narrative:** Write a single, engaging narrative paragraph in the **present tense** describing the event based on the Factual Outcome Description.
    *   **Style Adherence:** STRICTLY adhere to **'The familiar, everyday real world; starting the morning routine at home.'**. Infuse with appropriate atmosphere, sensory details, and tone.
    *   **Show, Don't Just Tell.**
    *   **Incorporate Intent (Optional).**
    *   **Flow:** Ensure reasonable flow.

**Output:**
- Output ONLY the final narrative string. Do NOT include explanations, prefixes, or JSON formatting.


You are an agent. Your internal name is "NarrationLLMAgent".

 The description about you is "LLM Narrator: Generates 'The familiar, everyday real world; starting the morning routine at home.' narrative based on factual outcomes."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I'm Eleanor Hayes, and I'm starting my day. The world is familiar and everyday, just a normal morning at home. I need to figure out what just happened and what I should do next. I'll start by recalling the last observation or event.\", \"action_type\": \"think\", \"details\": \"Recalling the last observation/event to decide on the next action.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 1.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes paused to consider her next move.\"}\n```"}],"role":"user"}
{"parts":[{"text":"Eleanor Hayes (sim_3e912d) pauses for a moment, the quiet hum of the refrigerator filling the momentary silence as she considers what to do next.\n"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Right, I paused to consider my next move. I'm still in that 'familiar, everyday real world' setting, so there's no immediate crisis. I should probably decide what I want to accomplish this morning. Do I need to get ready for work, or is it the weekend? What day is it? I can't remember. I need to check my calendar or something similar to determine what I should be doing today. I should look around the room to find something I can use to check the day.\", \"action_type\": \"look_around\", \"details\": \"Looking around to find something to check the day.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 5.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes looked around the room, searching for something to check the date.\"}\n```"}],"role":"user"}
{"parts":[{"text":"Eleanor Hayes (sim_3e912d) scans the kitchen, her gaze drifting over the familiar countertop cluttered with mail and a fruit bowl, past the calendar hanging askew by the refrigerator, all in search of something to jog her memory of the day.\n"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Ah, a calendar! Hanging askew by the refrigerator, no less. Perfect. I should go check it to see what day it is and figure out my plans for the day. It's exactly the sort of thing one would find in a 'familiar, everyday real world; starting the morning routine at home.'\", \"action_type\": \"use\", \"target_id\": \"calendar_790\", \"details\": \"Check the calendar by the refrigerator to see what day it is.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 10.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes walked over to the calendar and checked the date.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-06 22:24:12,116 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:12,119 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:12,132 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F43800>
2025-05-06 22:24:12,132 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A399FA8D50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:12,153 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399F60230>
2025-05-06 22:24:12,153 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:12,153 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:12,153 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:12,154 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:12,154 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:12,929 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=765'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:12,929 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:12,929 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:12,930 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:12,930 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:12,930 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:12,930 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
Eleanor Hayes (sim_3e912d) shuffles across the kitchen tiles, the linoleum cool beneath her bare feet, and peers at the calendar hanging crookedly on the fridge, its colorful squares a promise of the day's agenda.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"Eleanor Hayes (sim_3e912d) shuffles across the kitchen tiles, the linoleum cool beneath her bare feet, and peers at the calendar hanging crookedly on the fridge, its colorful squares a promise of the day's agenda.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.21482545024943803}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":53,"candidates_tokens_details":[{"modality":"TEXT","token_count":53}],"prompt_token_count":1126,"prompt_tokens_details":[{"modality":"TEXT","token_count":1126}],"total_token_count":1179},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:12,930 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) shuffles across the kitchen tiles, the linoleum cool beneath her bare fee...
2025-05-06 22:24:12,936 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) shuffles across the kitchen tiles, the linoleum cool beneath her bare feet, and peers at the calendar hanging crookedly on the fridge, its colorful squares a promise of the day's agenda.
2025-05-06 22:24:12,936 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) shuffles across the kitchen tiles, the linoleum cool ...
2025-05-06 22:24:13,193 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1456'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:13,193 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:13,193 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:13,193 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:13,194 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:13,194 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:13,194 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
The current weather in Asheville, NC is clear with periodic clouds. The temperature is 58F (14C), and it feels like 58F (14C) with 71% humidity. The chance of rain is around 0%.
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"The current weather in Asheville, NC is clear with periodic clouds. The temperature is 58F (14C), and it feels like 58F (14C) with 71% humidity. The chance of rain is around 0%."}],"role":"model"},"finish_reason":"STOP","grounding_metadata":{"grounding_chunks":[{"web":{"title":"Weather information for locality: Asheville, administrative_area: NC","uri":"https://www.google.com/search?q=weather+in+Asheville,+NC"}}],"grounding_supports":[{"grounding_chunk_indices":[0],"segment":{"end_index":66,"text":"The current weather in Asheville, NC is clear with periodic clouds"}},{"grounding_chunk_indices":[0],"segment":{"end_index":151,"start_index":68,"text":"The temperature is 58F (14C), and it feels like 58F (14C) with 71% humidity"}},{"grounding_chunk_indices":[0],"segment":{"end_index":184,"start_index":153,"text":"The chance of rain is around 0%"}}],"retrieval_metadata":{},"search_entry_point":{"rendered_content":"<style>\n.container {\n  align-items: center;\n  border-radius: 8px;\n  display: flex;\n  font-family: Google Sans, Roboto, sans-serif;\n  font-size: 14px;\n  line-height: 20px;\n  padding: 8px 12px;\n}\n.chip {\n  display: inline-block;\n  border: solid 1px;\n  border-radius: 16px;\n  min-width: 14px;\n  padding: 5px 16px;\n  text-align: center;\n  user-select: none;\n  margin: 0 8px;\n  -webkit-tap-highlight-color: transparent;\n}\n.carousel {\n  overflow: auto;\n  scrollbar-width: none;\n  white-space: nowrap;\n  margin-right: -12px;\n}\n.headline {\n  display: flex;\n  margin-right: 4px;\n}\n.gradient-container {\n  position: relative;\n}\n.gradient {\n  position: absolute;\n  transform: translate(3px, -9px);\n  height: 36px;\n  width: 9px;\n}\n@media (prefers-color-scheme: light) {\n  .container {\n    background-color: #fafafa;\n    box-shadow: 0 0 0 1px #0000000f;\n  }\n  .headline-label {\n    color: #1f1f1f;\n  }\n  .chip {\n    background-color: #ffffff;\n    border-color: #d2d2d2;\n    color: #5e5e5e;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #f2f2f2;\n  }\n  .chip:focus {\n    background-color: #f2f2f2;\n  }\n  .chip:active {\n    background-color: #d8d8d8;\n    border-color: #b6b6b6;\n  }\n  .logo-dark {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n  }\n}\n@media (prefers-color-scheme: dark) {\n  .container {\n    background-color: #1f1f1f;\n    box-shadow: 0 0 0 1px #ffffff26;\n  }\n  .headline-label {\n    color: #fff;\n  }\n  .chip {\n    background-color: #2c2c2c;\n    border-color: #3c4043;\n    color: #fff;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #353536;\n  }\n  .chip:focus {\n    background-color: #353536;\n  }\n  .chip:active {\n    background-color: #464849;\n    border-color: #53575b;\n  }\n  .logo-light {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n  }\n}\n</style>\n<div class=\"container\">\n  <div class=\"headline\">\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n    </svg>\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n    </svg>\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n  </div>\n  <div class=\"carousel\">\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFfSPvQiUVp_NlrZApchiAKlayF0W_UerA1P-01ff9QxiWIrM9pGxZt6huEoWudUyWWDFtlV2UqfbJoxK_vilYRPhcYmoudWqlcO-Ox0NkDKoYtMhAjEqkQknfpzY8-fN80gLBGKNdatHkv4FORNNhlIbHcdyHv5DPanYGErDESMceKZ5EDJF0v-KQxI15zuP-MCx4mLpJ1Njdmli4dNljUeCI=\">current weather in Asheville NC</a>\n  </div>\n</div>\n"},"web_search_queries":["current weather in Asheville NC"]}}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":58,"candidates_tokens_details":[{"modality":"TEXT","token_count":58}],"prompt_token_count":60,"prompt_tokens_details":[{"modality":"TEXT","token_count":60}],"total_token_count":118},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-06 22:24:13,195 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_Weather] Event ID: XUUGisza, Author: SearchLLMAgent
2025-05-06 22:24:13,195 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_Weather] Text response: The current weather in Asheville, NC is clear with periodic clouds. The temperature is 58F (14C), and it feels like 58F (14C) with 71% humidity. The chance of rain is around 0%....
2025-05-06 22:24:13,195 - src.simulation_async - INFO - [WorldInfoGatherer] REAL weather search returned: The current weather in Asheville, NC is clear with periodic clouds. The temperature is 58F (14C), and it feels like 58F (14C) with 71% humidity. The chance of rain is around 0%.
2025-05-06 22:24:13,197 - grpc._cython.cygrpc - DEBUG - Using AsyncIOEngine.POLLER as I/O engine
2025-05-06 22:24:13,845 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.weather = {'condition': 'Clear with periodic clouds', 'temperature_celsius': 14, 'forecast_short': 'Clear skies with occasional clouds.', 'timestamp': 9.984000000054948, 'source_category': 'weather'}
2025-05-06 22:24:13,845 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'world_news' with query: 'What are the latest top world news headlines (e.g., politics, social issues, environment, major international events)?'
2025-05-06 22:24:13,854 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:13,857 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:13,873 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F05910>
2025-05-06 22:24:13,873 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F09A50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:13,892 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F057F0>
2025-05-06 22:24:13,892 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:13,892 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:13,892 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:13,892 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:13,892 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:16,417 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2513'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:16,417 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:16,417 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:16,418 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:16,418 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:16,418 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:16,419 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_world_news] Event ID: D7LwOXP3, Author: SearchLLMAgent
2025-05-06 22:24:16,419 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_world_news] Text response: Here are some of the top world news headlines:

*   **Tensions between India and Pakistan:** India launched missile strikes into Pakistani territory following a militant attack in Kashmir. Pakistan ha...
2025-05-06 22:24:16,419 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'world_news' returned: Here are some of the top world news headlines:

*   **Tensions between India and Pakistan:** India launched missile strikes into Pakistani territory following a militant attack in Kashmir. Pakistan has vowed to respond, raising fears of war.
*   **Middle East Conflict:** Israel has launched airstrikes on Yemen after Houthi rebels struck an Israeli airport. There are reports that Israel plans to seize the Gaza Strip.
*   **German Politics:** Friedrich Merz was elected as the new German chancellor
2025-05-06 22:24:17,117 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'Global Tensions Rise Amid Conflicts and Political Shifts', 'summary': 'Escalating tensions between India and Pakistan, conflict in the Middle East and Sudan, and a new German chancellor highlight a world facing numerous challenges.', 'timestamp': 9.984000000054948, 'source_category': 'world_news'}]
2025-05-06 22:24:17,117 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'regional_news' with query: 'What are the latest top national news headlines for United States?'
2025-05-06 22:24:17,125 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:17,128 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:17,139 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52C60>
2025-05-06 22:24:17,139 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A399FAB250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:17,155 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F42AE0>
2025-05-06 22:24:17,155 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:17,155 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:17,155 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:17,155 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:17,155 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:19,654 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:39 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2487'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:19,655 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:19,655 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:19,656 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:19,656 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:19,656 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:19,657 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_regional_news] Event ID: ZYNlRcFj, Author: SearchLLMAgent
2025-05-06 22:24:19,657 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_regional_news] Text response: Here are some of the latest top national news headlines for the United States:

*   **India-Pakistan tensions:** India launched missile strikes into Pakistani territory after a militant attack in Kash...
2025-05-06 22:24:19,657 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'regional_news' returned: Here are some of the latest top national news headlines for the United States:

*   **India-Pakistan tensions:** India launched missile strikes into Pakistani territory after a militant attack in Kashmir.
*   **REAL ID:** Homeland Security chief says travelers without a REAL ID can still fly for now, but with likely extra steps.
*   **Trump and Canada:** In an Oval Office meeting, Canadian PM Mark Carney stated that Canada isn't for sale, to which President Trump replied, "never say never".
*   
2025-05-06 22:24:20,647 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'National News Roundup: India-Pakistan Tension, REAL ID, and Trump-Canada Standoff', 'summary': 'US national news includes rising India-Pakistan tensions, REAL ID updates, a tense Trump-Canada meeting, the transgender military ban taking effect, reinstatement of 9/11 program staff, a controversial FDA appointment, and MLB draft news.', 'timestamp': 9.984000000054948, 'source_category': 'regional_news'}, {'headline': 'Global Tensions Rise Amid Conflicts and Political Shifts', 'summary': 'Escalating tensions between India and Pakistan, conflict in the Middle East and Sudan, and a new German chancellor highlight a world facing numerous challenges.', 'timestamp': 9.984000000054948, 'source_category': 'world_news'}]
2025-05-06 22:24:20,647 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'local_news' with query: 'What are the top latest local news headlines for Asheville, NC?'
2025-05-06 22:24:20,655 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:20,657 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:20,671 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F42AE0>
2025-05-06 22:24:20,671 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0A9D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:20,687 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F41850>
2025-05-06 22:24:20,687 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:20,687 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:20,687 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:20,687 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:20,687 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:21,387 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 19.7 (due at 19.6).
2025-05-06 22:24:21,387 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:24:21,387 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:24:21,387 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:24:21,496 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:24:21,496 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:24:21,517 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:21,520 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:21,533 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F51DF0>
2025-05-06 22:24:21,533 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A6A26050> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:21,552 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F42B40>
2025-05-06 22:24:21,553 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:21,553 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:21,553 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:21,553 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:21,553 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:22,465 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=900'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:22,465 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:22,465 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:22,466 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:22,466 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:22,466 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:22,482 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:22,482 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (think on N/A) classified as 'environment'.
2025-05-06 22:24:22,483 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'think', 'target_id': None, 'details': 'What day is it after checking the calendar?'}
2025-05-06 22:24:22,483 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (think).
2025-05-06 22:24:22,508 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:22,512 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:22,526 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A2B350>
2025-05-06 22:24:22,526 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA68D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:22,546 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F50AD0>
2025-05-06 22:24:22,546 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:22,546 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:22,546 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:22,546 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:22,546 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:23,226 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=666'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:23,226 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:23,226 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:23,227 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:23,227 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:23,227 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:23,227 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 1.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:24:23,228 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:23,238 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:23,238 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:23,238 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 21.79599999997299
2025-05-06 22:24:23,238 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: think - Details: What day is it after checking the calendar?
2025-05-06 22:24:23,238 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 21.8s. Outcome: Eleanor Hayes tried to recall the date after looking at the calendar.
2025-05-06 22:24:23,239 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:23,239 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes tried to recall the date after looking at the calendar.'
2025-05-06 22:24:23,261 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:23,268 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:23,283 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F51850>
2025-05-06 22:24:23,283 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F30F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:23,302 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F42CC0>
2025-05-06 22:24:23,302 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:23,302 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:23,302 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:23,303 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:23,303 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:23,557 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 21.9 (due at 21.8).
2025-05-06 22:24:23,557 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:24:23,557 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:24:23,557 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:24:23,632 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2936'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:23,632 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:23,632 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:23,633 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:23,633 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:23,633 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:23,634 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_local_news] Event ID: W8HZbaKb, Author: SearchLLMAgent
2025-05-06 22:24:23,634 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_local_news] Text response: Here are some of the latest local news headlines for Asheville, NC:

*   **Buncombe County Property Tax Hike:** The Buncombe County Board of Commissioners may need to raise the property tax rate by 3....
2025-05-06 22:24:23,634 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'local_news' returned: Here are some of the latest local news headlines for Asheville, NC:

*   **Buncombe County Property Tax Hike:** The Buncombe County Board of Commissioners may need to raise the property tax rate by 3.21 cents per $100 of taxable value to balance the budget.
*   **Asheville City Council Discusses Property Tax:** Asheville City Council members are discussing a potential property tax increase to maintain a fund balance. The city is also set to launch a new parking app called Flowbird on June 2, 202
2025-05-06 22:24:24,026 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:24:24,026 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:24:24,042 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:24,046 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:24,061 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FA91C0>
2025-05-06 22:24:24,061 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A83554D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:24,080 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F422D0>
2025-05-06 22:24:24,081 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:24,081 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:24,081 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:24,081 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:24,081 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:24,093 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=783'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:24,094 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:24,094 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:24,094 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:24,094 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:24,094 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:24,095 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) frowns slightly, a mental tug-of-war as she tries to conjure the image of...
2025-05-06 22:24:24,100 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) frowns slightly, a mental tug-of-war as she tries to conjure the image of the calendar back into focus, the grid of dates blurring slightly as she strains to remember what day it is.
2025-05-06 22:24:24,100 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) frowns slightly, a mental tug-of-war as she tries to ...
2025-05-06 22:24:24,440 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'Asheville Faces Potential Property Tax Hikes, Airport Expansion, and I-40 Closure', 'summary': 'Asheville grapples with possible property tax increases in both the city and county, prepares for a new airport concourse opening and I-40 West closure, and continues to address the ongoing issue of homelessness.', 'timestamp': 9.984000000054948, 'source_category': 'local_news'}, {'headline': 'National News Roundup: India-Pakistan Tension, REAL ID, and Trump-Canada Standoff', 'summary': 'US national news includes rising India-Pakistan tensions, REAL ID updates, a tense Trump-Canada meeting, the transgender military ban taking effect, reinstatement of 9/11 program staff, a controversial FDA appointment, and MLB draft news.', 'timestamp': 9.984000000054948, 'source_category': 'regional_news'}, {'headline': 'Global Tensions Rise Amid Conflicts and Political Shifts', 'summary': 'Escalating tensions between India and Pakistan, conflict in the Middle East and Sudan, and a new German chancellor highlight a world facing numerous challenges.', 'timestamp': 9.984000000054948, 'source_category': 'world_news'}]
2025-05-06 22:24:24,440 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'pop_culture' with query: 'What are the top latest United States  pop culture trends and entertainment news headlines (e.g., movies, music, viral trends)?'
2025-05-06 22:24:24,448 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:24,456 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:24,479 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A68E3F80>
2025-05-06 22:24:24,479 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F307D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:24,504 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A66C7EC0>
2025-05-06 22:24:24,504 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:24,504 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:24,504 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:24,504 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:24,504 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:25,015 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=922'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:25,016 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:25,016 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:25,016 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:25,016 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:25,016 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:25,033 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:25,033 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:24:25,034 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': 'Querying memory to remember what day it is after checking the calendar.'}
2025-05-06 22:24:25,034 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:24:25,056 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:25,061 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:25,073 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F53440>
2025-05-06 22:24:25,073 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F32AD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:25,092 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFCC80>
2025-05-06 22:24:25,092 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:25,093 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:25,093 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:25,093 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:25,093 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:25,733 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=629'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:25,734 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:25,734 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:25,734 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:25,734 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:25,734 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:25,735 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:24:25,735 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:25,747 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:25,747 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:25,747 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 28.34299999999348
2025-05-06 22:24:25,747 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: Querying memory to remember what day it is after checking the calendar.
2025-05-06 22:24:25,747 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 28.3s. Outcome: Eleanor Hayes attempted to recall the date by searching her memory.
2025-05-06 22:24:25,747 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:25,747 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes attempted to recall the date by searching her memory.'
2025-05-06 22:24:25,772 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:25,775 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:25,787 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52270>
2025-05-06 22:24:25,787 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A39678E9D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:25,807 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A2B350>
2025-05-06 22:24:25,807 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:25,809 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:25,809 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:25,809 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:25,809 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:26,641 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=823'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:26,642 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:26,642 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:26,643 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:26,643 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:26,643 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:26,643 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) closes her eyes for a moment, a slight furrow in her brow, as she rummage...
2025-05-06 22:24:26,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) closes her eyes for a moment, a slight furrow in her brow, as she rummages through the recesses of her mind, sifting through the mental clutter in an attempt to unearth the answer to a simple question: what day is it?
2025-05-06 22:24:26,650 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) closes her eyes for a moment, a slight furrow in her ...
2025-05-06 22:24:27,342 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2827'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:27,342 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:27,342 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:27,344 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:27,344 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:27,345 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:27,346 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_pop_culture] Event ID: K9y80XED, Author: SearchLLMAgent
2025-05-06 22:24:27,346 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_pop_culture] Text response: Here are some of the latest top pop culture and entertainment headlines in the United States:

*   **Met Gala 2025:** The Met Gala 2025 recently took place, generating significant buzz with daring and...
2025-05-06 22:24:27,346 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'pop_culture' returned: Here are some of the latest top pop culture and entertainment headlines in the United States:

*   **Met Gala 2025:** The Met Gala 2025 recently took place, generating significant buzz with daring and dramatic looks from celebrities like Zendaya, Sydney Sweeney, and Miley Cyrus. Rihanna's baby bump reveal and other top moments were also highlights. Kim Kardashian, Hailey Bieber, and other stars led risqu fashion moments at the after-parties.
*   **Celebrity News:** Robert De Niro is supporting 
2025-05-06 22:24:28,063 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.pop_culture_updates = [{'headline': 'Met Gala & Celebrity News Dominate Pop Culture', 'summary': "The Met Gala's fashion and celebrity moments, coupled with news surrounding De Niro, Diddy, and music releases, are currently shaping U.S. pop culture.", 'timestamp': 9.984000000054948, 'source_category': 'pop_culture'}]
2025-05-06 22:24:28,064 - src.simulation_async - INFO - [WorldInfoGatherer] World feeds updated. Next check in 3600.0 sim_seconds.
2025-05-06 22:24:30,108 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 28.4 (due at 28.3).
2025-05-06 22:24:30,108 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:24:30,108 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:24:30,108 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:24:30,108 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:24:30,108 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:24:30,131 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:30,135 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:30,149 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED35C0>
2025-05-06 22:24:30,150 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F325D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:30,167 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED38F0>
2025-05-06 22:24:30,167 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:30,168 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:30,168 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:30,168 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:30,168 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:31,528 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1351'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:31,529 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:31,529 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:31,530 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:31,530 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:31,530 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:31,546 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:31,546 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:24:31,546 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': 'Explicitly querying memory for the date I saw on the calendar.'}
2025-05-06 22:24:31,546 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:24:31,566 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:31,570 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:31,583 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED30E0>
2025-05-06 22:24:31,583 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0B750> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:31,602 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399F60230>
2025-05-06 22:24:31,602 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:31,602 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:31,603 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:31,603 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:31,603 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:32,283 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:52 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=671'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:32,283 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:32,283 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:32,284 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:32,284 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:32,284 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:32,285 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:24:32,285 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:32,295 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:32,295 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:32,295 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 34.85900000005495
2025-05-06 22:24:32,295 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: Explicitly querying memory for the date I saw on the calendar.
2025-05-06 22:24:32,295 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 34.9s. Outcome: Eleanor Hayes focused her thoughts, attempting to retrieve the specific date from her memory of the calendar.
2025-05-06 22:24:32,295 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:32,296 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes focused her thoughts, attempting to retrieve the specific date from her memory of the calendar.'
2025-05-06 22:24:32,318 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:32,322 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:32,338 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F535F0>
2025-05-06 22:24:32,338 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBFAD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:32,360 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F51700>
2025-05-06 22:24:32,360 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:32,360 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:32,360 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:32,360 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:32,360 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:33,218 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:53 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=843'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:33,218 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:33,218 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:33,218 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:33,219 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:33,219 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:33,219 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) takes a slow, deliberate breath, and once more dives into the labyrinth o...
2025-05-06 22:24:33,225 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) takes a slow, deliberate breath, and once more dives into the labyrinth of her memory, this time focusing intently on the visual impression of the calendar, the numbers and abbreviations swimming behind her eyelids as she tries to pinpoint the exact date it displayed.
2025-05-06 22:24:33,225 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) takes a slow, deliberate breath, and once more dives ...
2025-05-06 22:24:36,621 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 35.0 (due at 34.9).
2025-05-06 22:24:36,621 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:24:36,621 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:24:36,621 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:24:37,143 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:24:37,143 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:24:37,164 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:37,169 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:37,179 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F501A0>
2025-05-06 22:24:37,179 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A6A275D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:37,197 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F527E0>
2025-05-06 22:24:37,197 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:37,198 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:37,198 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:37,198 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:37,198 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:38,797 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:59 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1589'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:38,797 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:38,797 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:38,798 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:38,798 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:38,798 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:38,815 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:38,816 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:24:38,816 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': "Querying memory to determine if it's a weekday or weekend."}
2025-05-06 22:24:38,816 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:24:38,841 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:38,846 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:38,862 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A29010>
2025-05-06 22:24:38,863 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A6A260D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:38,882 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F06C60>
2025-05-06 22:24:38,882 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:38,882 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:38,882 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:38,882 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:38,882 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:39,565 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:24:59 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=671'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:39,566 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:39,566 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:39,566 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:39,566 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:39,566 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:39,567 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:24:39,567 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:39,578 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:39,578 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:39,578 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 42.125
2025-05-06 22:24:39,578 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: Querying memory to determine if it's a weekday or weekend.
2025-05-06 22:24:39,578 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 42.1s. Outcome: Eleanor Hayes searched her memory, attempting to determine if it was a weekday or weekend.
2025-05-06 22:24:39,578 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:39,578 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes searched her memory, attempting to determine if it was a weekday or weekend.'
2025-05-06 22:24:39,599 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:39,604 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:39,619 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F408C0>
2025-05-06 22:24:39,619 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA79D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:39,639 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F40EF0>
2025-05-06 22:24:39,639 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:39,639 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:39,639 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:39,639 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:39,639 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:40,445 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=794'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:40,445 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:40,445 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:40,446 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:40,446 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:40,446 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:40,447 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) chews on her lip, the question echoing in her mind  weekday or weekend? ...
2025-05-06 22:24:40,452 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) chews on her lip, the question echoing in her mind  weekday or weekend?  as she once again sifts through the mental debris, hoping to find a definitive answer that will dictate the course of her morning.
2025-05-06 22:24:40,452 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) chews on her lip, the question echoing in her mind  ...
2025-05-06 22:24:43,802 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 42.1 (due at 42.1).
2025-05-06 22:24:43,802 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:24:43,802 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:24:43,802 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:24:43,864 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:24:43,864 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:24:43,890 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:43,895 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:43,913 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6905640>
2025-05-06 22:24:43,913 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBF6D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:43,932 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6AEE1E0>
2025-05-06 22:24:43,932 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:43,932 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:43,932 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:43,933 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:43,933 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:45,436 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:05 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1493'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:45,436 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:45,436 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:45,437 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:45,437 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:45,437 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:45,453 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:45,453 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-06 22:24:45,454 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'Looking around for a newspaper or phone to check the day.'}
2025-05-06 22:24:45,454 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-06 22:24:45,475 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:45,480 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:45,494 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A2A7E0>
2025-05-06 22:24:45,494 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA5F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:45,514 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED3A40>
2025-05-06 22:24:45,514 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:45,514 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:45,514 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:45,514 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:45,515 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:46,166 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:06 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=639'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:46,166 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:46,166 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:46,167 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:46,167 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:46,167 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:46,168 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:24:46,168 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:46,178 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:46,182 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:46,182 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 48.75
2025-05-06 22:24:46,182 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: look_around - Details: Looking around for a newspaper or phone to check the day.
2025-05-06 22:24:46,182 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 48.8s. Outcome: Eleanor Hayes looked around the room again, searching for a newspaper or phone.
2025-05-06 22:24:46,182 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:46,182 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around the room again, searching for a newspaper or phone.'
2025-05-06 22:24:46,205 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:46,210 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:46,222 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52030>
2025-05-06 22:24:46,222 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8355250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:46,241 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FABBC0>
2025-05-06 22:24:46,241 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:46,242 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:46,242 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:46,242 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:46,242 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:47,009 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:07 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=753'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:47,009 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:47,009 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:47,010 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:47,010 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:47,010 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:47,011 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) pivots slowly, her gaze sweeping across the kitchen once more, this time ...
2025-05-06 22:24:47,016 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) pivots slowly, her gaze sweeping across the kitchen once more, this time with a renewed focus, searching for a telltale newspaper lying forgotten on the counter or the comforting glint of her phone amidst the morning clutter.
2025-05-06 22:24:47,016 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) pivots slowly, her gaze sweeping across the kitchen o...
2025-05-06 22:24:50,459 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 48.8 (due at 48.8).
2025-05-06 22:24:50,459 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:24:50,459 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:24:50,459 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:24:50,614 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:24:50,614 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:24:50,640 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:50,646 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:50,658 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52DE0>
2025-05-06 22:24:50,658 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBEED0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:50,677 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F525D0>
2025-05-06 22:24:50,677 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:50,677 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:50,677 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:50,677 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:50,677 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:51,683 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:11 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=992'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:51,683 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:51,683 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:51,684 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:51,684 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:51,684 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:51,701 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:24:51,701 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-06 22:24:51,701 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'Leave the kitchen to find my phone.'}
2025-05-06 22:24:51,701 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-06 22:24:51,727 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:51,732 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:51,744 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8330650>
2025-05-06 22:24:51,744 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBD650> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:51,765 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F53FB0>
2025-05-06 22:24:51,765 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:51,765 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:51,765 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:51,765 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:51,765 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:52,408 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:12 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=630'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:52,408 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:52,409 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:52,409 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:52,409 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:52,409 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:52,410 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:24:52,410 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:24:52,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:24:52,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:24:52,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 59.96799999999348
2025-05-06 22:24:52,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: move - Details: Leave the kitchen to find my phone.
2025-05-06 22:24:52,421 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 60.0s. Outcome: Eleanor Hayes left the kitchen.
2025-05-06 22:24:52,421 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:24:52,421 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes left the kitchen.'
2025-05-06 22:24:52,443 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:24:52,448 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:24:52,459 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52A50>
2025-05-06 22:24:52,459 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0A2D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:24:52,480 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A652D4C0>
2025-05-06 22:24:52,480 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:24:52,480 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:24:52,480 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:24:52,481 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:24:52,481 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:24:53,336 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=843'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:24:53,336 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:24:53,336 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:24:53,337 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:24:53,337 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:24:53,337 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:24:53,338 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) pushes away from the lingering scent of coffee and the half-formed intent...
2025-05-06 22:24:53,344 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) pushes away from the lingering scent of coffee and the half-formed intention of breakfast, abandoning the kitchen in pursuit of the elusive, yet essential, connection to the outside world  her phone.
2025-05-06 22:24:53,344 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) pushes away from the lingering scent of coffee and th...
2025-05-06 22:25:01,664 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 60.0 (due at 60.0).
2025-05-06 22:25:01,664 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:25:01,664 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:25:01,664 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:25:01,835 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:25:01,835 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:25:01,858 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:01,864 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:01,880 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F078F0>
2025-05-06 22:25:01,880 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0A950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:01,900 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F525A0>
2025-05-06 22:25:01,900 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:01,901 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:01,901 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:01,901 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:01,901 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:03,047 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1133'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:03,048 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:03,048 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:03,048 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:03,048 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:03,048 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:03,065 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:25:03,065 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-06 22:25:03,065 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'Move to the living room to look for my phone.'}
2025-05-06 22:25:03,065 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-06 22:25:03,087 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:03,092 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:03,105 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F06C90>
2025-05-06 22:25:03,105 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A83543D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:03,126 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399F60230>
2025-05-06 22:25:03,126 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:03,126 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:03,126 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:03,126 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:03,126 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:03,814 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=676'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:03,814 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:03,814 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:03,815 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:03,815 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:03,815 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:03,816 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:25:03,816 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:25:03,827 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:25:03,827 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:25:03,827 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 71.375
2025-05-06 22:25:03,827 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: move - Details: Move to the living room to look for my phone.
2025-05-06 22:25:03,827 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 71.4s. Outcome: Eleanor Hayes went to the living room to look for her phone.
2025-05-06 22:25:03,827 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:25:03,827 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes went to the living room to look for her phone.'
2025-05-06 22:25:03,851 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:03,857 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:03,868 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FA8A10>
2025-05-06 22:25:03,868 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A83565D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:03,888 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FABFB0>
2025-05-06 22:25:03,888 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:03,888 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:03,888 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:03,888 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:03,888 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:04,801 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=903'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:04,801 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:04,801 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:04,801 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:04,802 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:04,802 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:04,802 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) pads down the hallway, the muted light of the morning filtering through t...
2025-05-06 22:25:04,808 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) pads down the hallway, the muted light of the morning filtering through the blinds, and enters the living room, her eyes already scanning the familiar landscape of the coffee table, the sofa cushions, and the cluttered bookshelves, all potential hiding places for her missing phone.
2025-05-06 22:25:04,809 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) pads down the hallway, the muted light of the morning...
2025-05-06 22:25:13,089 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 71.4 (due at 71.4).
2025-05-06 22:25:13,089 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:25:13,089 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:25:13,089 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:25:13,233 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:25:13,233 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:25:13,257 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:13,264 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:13,278 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F06F60>
2025-05-06 22:25:13,278 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA7BD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:13,297 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6906330>
2025-05-06 22:25:13,297 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:13,297 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:13,297 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:13,297 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:13,297 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:14,374 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1067'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:14,374 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:14,374 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:14,375 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:14,375 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:14,375 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:14,393 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:25:14,393 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-06 22:25:14,393 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'Looking around the living room for my phone.'}
2025-05-06 22:25:14,393 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-06 22:25:14,415 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:14,426 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:14,440 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6907080>
2025-05-06 22:25:14,440 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8355ED0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:14,459 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A652D4C0>
2025-05-06 22:25:14,459 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:14,459 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:14,459 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:14,459 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:14,459 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:15,131 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=661'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:15,132 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:15,132 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:15,132 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:15,132 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:15,132 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:15,133 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:25:15,133 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:25:15,144 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:25:15,144 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:25:15,144 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 77.68700000003446
2025-05-06 22:25:15,144 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: look_around - Details: Looking around the living room for my phone.
2025-05-06 22:25:15,144 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 77.7s. Outcome: Eleanor Hayes looked around the living room, searching for her phone.
2025-05-06 22:25:15,144 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:25:15,144 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around the living room, searching for her phone.'
2025-05-06 22:25:15,168 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:15,174 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:15,187 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8333170>
2025-05-06 22:25:15,187 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBF6D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:15,204 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8333A10>
2025-05-06 22:25:15,205 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:15,205 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:15,205 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:15,205 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:15,205 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:16,036 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=820'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:16,036 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:16,037 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:16,037 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:16,037 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:16,037 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:16,038 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) surveys the living room once more, her gaze lingering on the soft contour...
2025-05-06 22:25:16,044 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) surveys the living room once more, her gaze lingering on the soft contours of the sofa, half-expecting to see the telltale outline of her phone nestled between the cushions, a familiar casualty of a relaxing evening.
2025-05-06 22:25:16,044 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) surveys the living room once more, her gaze lingering...
2025-05-06 22:25:19,445 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 77.8 (due at 77.7).
2025-05-06 22:25:19,445 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:25:19,445 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:25:19,445 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:25:19,445 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:25:19,445 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:25:19,470 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:19,477 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:19,487 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BD2E0>
2025-05-06 22:25:19,487 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8356550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:19,504 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BCB00>
2025-05-06 22:25:19,504 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:19,504 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:19,504 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:19,505 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:19,505 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:20,796 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1284'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:20,797 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:20,797 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:20,797 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:20,797 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:20,797 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:20,815 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:25:20,815 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on sofa_295) classified as 'environment'.
2025-05-06 22:25:20,815 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'sofa_295', 'details': 'Check the sofa cushions for my phone.'}
2025-05-06 22:25:20,815 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-06 22:25:20,841 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:20,848 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:20,861 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F53A70>
2025-05-06 22:25:20,861 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0B1D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:20,882 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A68E3E90>
2025-05-06 22:25:20,883 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:20,883 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:20,883 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:20,883 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:20,883 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:21,492 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=598'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:21,493 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:21,493 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:21,493 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:21,493 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:21,493 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:21,494 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 15.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:25:21,494 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:25:21,504 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:25:21,504 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:25:21,504 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 94.07799999997951
2025-05-06 22:25:21,504 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: use - Details: Check the sofa cushions for my phone.
2025-05-06 22:25:21,504 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 94.1s. Outcome: Eleanor Hayes checked the sofa cushions.
2025-05-06 22:25:21,504 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:25:21,504 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes checked the sofa cushions.'
2025-05-06 22:25:21,527 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:21,534 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:21,547 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F50D10>
2025-05-06 22:25:21,548 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA55D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:21,571 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A2AED0>
2025-05-06 22:25:21,571 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:21,572 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:21,572 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:21,572 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:21,572 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:22,405 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=821'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:22,405 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:22,405 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:22,406 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:22,406 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:22,406 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:22,407 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) kneels by the sofa, plunging her hands between the plush cushions, her fi...
2025-05-06 22:25:22,412 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) kneels by the sofa, plunging her hands between the plush cushions, her fingers exploring the hidden depths in a silent, hopeful search for the missing device, a common ritual in the familiar landscape of her living room.
2025-05-06 22:25:22,412 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) kneels by the sofa, plunging her hands between the pl...
2025-05-06 22:25:35,803 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 94.1 (due at 94.1).
2025-05-06 22:25:35,803 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:25:35,803 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:25:35,803 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:25:35,970 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:25:35,970 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:25:35,994 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:36,002 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:36,032 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FAA510>
2025-05-06 22:25:36,032 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F09050> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:36,052 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FA9850>
2025-05-06 22:25:36,052 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:36,052 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:36,052 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:36,052 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:36,052 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:37,173 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1110'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:37,173 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:37,173 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:37,174 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:37,174 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:37,174 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:37,191 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:25:37,191 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (think on N/A) classified as 'environment'.
2025-05-06 22:25:37,191 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'think', 'target_id': None, 'details': 'Did I find my phone in the sofa cushions?'}
2025-05-06 22:25:37,191 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (think).
2025-05-06 22:25:37,219 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:37,226 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:37,239 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6ABECF0>
2025-05-06 22:25:37,239 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA54D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:37,258 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A58FA000>
2025-05-06 22:25:37,258 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:37,258 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:37,258 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:37,258 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:37,258 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:37,997 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=729'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:37,997 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:37,997 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:37,998 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:37,998 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:37,998 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:37,999 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 1.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:25:37,999 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:25:38,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:25:38,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:25:38,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 96.5
2025-05-06 22:25:38,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: think - Details: Did I find my phone in the sofa cushions?
2025-05-06 22:25:38,011 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 96.5s. Outcome: Eleanor Hayes paused to consider whether she had found her phone in the sofa cushions.
2025-05-06 22:25:38,011 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:25:38,011 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes paused to consider whether she had found her phone in the sofa cushions.'
2025-05-06 22:25:38,035 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:38,042 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:38,055 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FA8CB0>
2025-05-06 22:25:38,055 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0A550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:38,075 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A29A90>
2025-05-06 22:25:38,075 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:38,076 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:38,076 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:38,076 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:38,076 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:38,263 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 96.6 (due at 96.5).
2025-05-06 22:25:38,263 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:25:38,263 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:25:38,263 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:25:38,733 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:25:38,733 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:25:38,749 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:38,757 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:38,773 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8331C70>
2025-05-06 22:25:38,773 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA7C50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:38,795 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8330A40>
2025-05-06 22:25:38,796 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:38,796 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:38,796 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:38,796 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:38,796 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:38,866 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:25:59 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=779'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:38,866 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:38,866 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:38,866 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:38,866 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:38,866 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:38,867 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) pauses, her hand still buried beneath the cushions, a moment of quiet ant...
2025-05-06 22:25:38,873 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) pauses, her hand still buried beneath the cushions, a moment of quiet anticipation hanging in the air as she mentally replays the tactile search, trying to discern whether her fingers brushed against the familiar, rectangular shape of her phone.
2025-05-06 22:25:38,873 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) pauses, her hand still buried beneath the cushions, a...
2025-05-06 22:25:40,029 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1221'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:40,029 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:40,029 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:40,030 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:40,030 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:40,030 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:40,052 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:25:40,052 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:25:40,052 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': 'Querying memory to see if I found my phone in the sofa cushions.'}
2025-05-06 22:25:40,052 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:25:40,077 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:40,084 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:40,098 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A2A150>
2025-05-06 22:25:40,098 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844F450> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:40,115 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F421B0>
2025-05-06 22:25:40,115 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:40,115 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:40,115 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:40,115 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:40,115 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:40,837 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=711'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:40,838 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:40,838 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:40,838 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:40,838 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:40,838 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:40,839 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:25:40,839 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:25:40,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:25:40,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:25:40,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 103.29599999997299
2025-05-06 22:25:40,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: Querying memory to see if I found my phone in the sofa cushions.
2025-05-06 22:25:40,850 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 103.3s. Outcome: Eleanor Hayes attempted to recall if she found her phone in the sofa cushions by searching her memory.
2025-05-06 22:25:40,850 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:25:40,850 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes attempted to recall if she found her phone in the sofa cushions by searching her memory.'
2025-05-06 22:25:40,876 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:40,883 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:40,895 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F51B20>
2025-05-06 22:25:40,895 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8356A50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:40,914 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FA9DC0>
2025-05-06 22:25:40,914 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:40,914 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:40,914 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:40,914 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:40,914 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:41,848 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=926'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:41,848 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:41,848 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:41,848 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:41,848 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:41,848 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:41,849 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) closes her eyes, a slight grimace flickering across her face, and delves ...
2025-05-06 22:25:41,855 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) closes her eyes, a slight grimace flickering across her face, and delves back into the recent past, mentally retracing her hand's journey through the sofa cushions, desperately seeking confirmation of a successful find, or bracing herself for the inevitable move to the next potential location.
2025-05-06 22:25:41,855 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) closes her eyes, a slight grimace flickering across h...
2025-05-06 22:25:45,052 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 103.4 (due at 103.3).
2025-05-06 22:25:45,052 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:25:45,052 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:25:45,052 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:25:45,114 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:25:45,114 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:25:45,140 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:45,152 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:45,167 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A58F93A0>
2025-05-06 22:25:45,167 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8354ED0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:45,185 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6AEC0B0>
2025-05-06 22:25:45,185 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:45,186 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:45,186 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:45,186 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:45,186 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:46,413 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:06 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1215'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:46,413 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:46,413 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:46,413 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:46,413 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:46,414 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:46,430 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:25:46,430 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:25:46,430 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': 'Asking memory again if I found my phone in the sofa cushions.'}
2025-05-06 22:25:46,430 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:25:46,453 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:46,461 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:46,476 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED30B0>
2025-05-06 22:25:46,477 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834D650> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:46,495 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6ABECF0>
2025-05-06 22:25:46,495 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:46,496 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:46,496 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:46,496 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:46,496 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:47,229 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:07 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=721'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:47,230 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:47,230 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:47,230 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:47,230 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:47,230 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:47,231 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:25:47,231 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:25:47,242 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:25:47,242 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:25:47,242 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 109.68700000003446
2025-05-06 22:25:47,242 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: Asking memory again if I found my phone in the sofa cushions.
2025-05-06 22:25:47,242 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 109.7s. Outcome: Eleanor Hayes focused her mind, attempting once more to recall if the phone had been in the sofa cushions.
2025-05-06 22:25:47,242 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:25:47,242 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes focused her mind, attempting once more to recall if the phone had been in the sofa cushions.'
2025-05-06 22:25:47,266 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:47,274 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:47,301 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FAB380>
2025-05-06 22:25:47,301 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBE950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:47,321 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FAA840>
2025-05-06 22:25:47,321 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:47,322 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:47,322 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:47,322 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:47,322 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:48,265 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:08 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=926'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:48,265 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:48,265 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:48,266 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:48,266 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:48,266 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:48,267 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) takes a deep breath and redoubles her mental efforts, her brow furrowed i...
2025-05-06 22:25:48,273 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) takes a deep breath and redoubles her mental efforts, her brow furrowed in concentration as she revisits the tactile landscape of the sofa cushions, determined to extract a definitive answer from the frustratingly vague recesses of her memory: was the phone there, or wasn't it?
2025-05-06 22:25:48,273 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) takes a deep breath and redoubles her mental efforts,...
2025-05-06 22:25:51,421 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 109.8 (due at 109.7).
2025-05-06 22:25:51,421 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:25:51,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:25:51,421 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:25:51,468 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:25:51,468 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:25:51,493 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:51,502 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:51,515 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FAAF90>
2025-05-06 22:25:51,515 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA5ED0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:51,534 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BECC0>
2025-05-06 22:25:51,534 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:51,534 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:51,535 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:51,535 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:51,535 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:52,854 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1308'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:52,854 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:52,854 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:52,855 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:52,855 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:52,855 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:52,872 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:25:52,872 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-06 22:25:52,872 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'Move to the bedroom to look for my phone.'}
2025-05-06 22:25:52,872 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-06 22:25:52,895 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:52,903 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:52,916 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6905250>
2025-05-06 22:25:52,916 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F30050> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:52,934 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399F60230>
2025-05-06 22:25:52,934 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:52,934 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:52,934 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:52,934 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:52,934 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:53,684 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=737'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:53,684 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:53,685 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:53,686 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:53,686 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:53,686 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:53,687 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:25:53,687 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:25:53,699 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:25:53,699 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:25:53,699 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 121.14000000001397
2025-05-06 22:25:53,699 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: move - Details: Move to the bedroom to look for my phone.
2025-05-06 22:25:53,699 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 121.1s. Outcome: Eleanor Hayes left the living room and went to the bedroom to look for her phone.
2025-05-06 22:25:53,699 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:25:53,699 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes left the living room and went to the bedroom to look for her phone.'
2025-05-06 22:25:53,728 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:25:53,736 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:25:53,751 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FAA9C0>
2025-05-06 22:25:53,751 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844FBD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:25:53,770 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8332030>
2025-05-06 22:25:53,770 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:25:53,771 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:25:53,771 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:25:53,771 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:25:53,771 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:25:54,642 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:14 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=861'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:25:54,642 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:25:54,643 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:25:54,643 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:25:54,643 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:25:54,643 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:25:54,644 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) sighs, abandoning the fruitless search of the sofa, and heads toward the ...
2025-05-06 22:25:54,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) sighs, abandoning the fruitless search of the sofa, and heads toward the bedroom, the morning light growing slightly brighter as she anticipates, with a mixture of hope and resignation, the next stage of her phone-seeking quest.
2025-05-06 22:25:54,650 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) sighs, abandoning the fruitless search of the sofa, a...
2025-05-06 22:26:02,815 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 121.1 (due at 121.1).
2025-05-06 22:26:02,815 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:26:02,815 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:26:02,815 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:26:03,069 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:26:03,069 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:26:03,093 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:03,102 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:03,114 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83338F0>
2025-05-06 22:26:03,114 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844CC50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:03,130 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8331A60>
2025-05-06 22:26:03,130 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:03,131 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:03,131 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:03,131 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:03,131 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:04,267 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:24 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1123'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:04,267 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:04,267 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:04,267 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:04,267 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:04,267 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:04,288 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:26:04,288 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-06 22:26:04,288 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'Look around the bedroom for my phone.'}
2025-05-06 22:26:04,288 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-06 22:26:04,311 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:04,320 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:04,334 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6AEE9F0>
2025-05-06 22:26:04,334 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7FA5F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:04,355 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6904D70>
2025-05-06 22:26:04,355 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:04,356 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:04,356 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:04,356 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:04,356 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:05,029 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=659'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:05,029 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:05,029 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:05,029 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:05,029 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:05,029 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:05,030 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:26:05,035 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:26:05,046 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:26:05,046 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:26:05,046 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 127.53099999995902
2025-05-06 22:26:05,046 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: look_around - Details: Look around the bedroom for my phone.
2025-05-06 22:26:05,046 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 127.5s. Outcome: Eleanor Hayes looked around the bedroom, searching for her phone.
2025-05-06 22:26:05,046 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:26:05,046 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around the bedroom, searching for her phone.'
2025-05-06 22:26:05,072 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:05,081 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:05,093 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F519A0>
2025-05-06 22:26:05,093 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F30DD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:05,112 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BD6D0>
2025-05-06 22:26:05,113 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:05,113 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:05,113 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:05,113 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:05,113 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:05,902 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=774'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:05,902 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:05,902 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:05,903 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:05,903 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:05,903 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:05,904 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) enters the bedroom and immediately scans the room, her eyes drawn to the ...
2025-05-06 22:26:05,910 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) enters the bedroom and immediately scans the room, her eyes drawn to the bedside table, hoping for a quick resolution to her search in the familiar jumble of books, glasses, and charging cables.
2025-05-06 22:26:05,910 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) enters the bedroom and immediately scans the room, he...
2025-05-06 22:26:09,251 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 127.6 (due at 127.5).
2025-05-06 22:26:09,251 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:26:09,251 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:26:09,251 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:26:09,406 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:26:09,406 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:26:09,431 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:09,440 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:09,456 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFD1F0>
2025-05-06 22:26:09,456 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844DFD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:09,476 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6906330>
2025-05-06 22:26:09,476 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:09,476 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:09,477 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:09,477 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:09,477 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:10,611 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:30 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1124'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:10,611 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:10,611 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:10,612 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:10,612 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:10,612 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:10,628 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:26:10,629 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on bedside_table_154) classified as 'environment'.
2025-05-06 22:26:10,629 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'bedside_table_154', 'details': 'Check the bedside table for my phone.'}
2025-05-06 22:26:10,629 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-06 22:26:10,651 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:10,660 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:10,674 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BC7A0>
2025-05-06 22:26:10,674 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBEA50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:10,714 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A652D4C0>
2025-05-06 22:26:10,714 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:10,714 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:10,714 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:10,714 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:10,714 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:11,366 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=640'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:11,366 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:11,366 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:11,367 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:11,367 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:11,367 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:11,367 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 15.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:26:11,367 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:26:11,378 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:26:11,378 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:26:11,378 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 143.875
2025-05-06 22:26:11,378 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: use - Details: Check the bedside table for my phone.
2025-05-06 22:26:11,378 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 143.9s. Outcome: Eleanor Hayes checked the bedside table.
2025-05-06 22:26:11,379 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:26:11,379 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes checked the bedside table.'
2025-05-06 22:26:11,405 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:11,415 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:11,428 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A2A1E0>
2025-05-06 22:26:11,428 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834EA50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:11,447 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A58FA000>
2025-05-06 22:26:11,447 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:11,448 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:11,448 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:11,448 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:11,448 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:12,293 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=836'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:12,293 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:12,293 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:12,294 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:12,294 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:12,294 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:12,295 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) crosses the bedroom and peers closely at the bedside table, carefully exa...
2025-05-06 22:26:12,301 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) crosses the bedroom and peers closely at the bedside table, carefully examining the surface and the small drawer beneath, her fingers gently nudging aside the clutter in her increasingly desperate search for the missing phone.
2025-05-06 22:26:12,301 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) crosses the bedroom and peers closely at the bedside ...
2025-05-06 22:26:25,606 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 143.9 (due at 143.9).
2025-05-06 22:26:25,606 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:26:25,606 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:26:25,606 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:26:25,979 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:26:25,979 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:26:26,007 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:26,016 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:26,031 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F43110>
2025-05-06 22:26:26,031 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834C250> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:26,049 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F43DD0>
2025-05-06 22:26:26,049 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:26,050 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:26,050 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:26,050 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:26,050 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:27,029 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=971'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:27,029 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:27,030 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:27,030 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:27,030 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:27,030 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:27,047 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:26:27,047 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (think on N/A) classified as 'environment'.
2025-05-06 22:26:27,047 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'think', 'target_id': None, 'details': 'Did I find my phone on the bedside table?'}
2025-05-06 22:26:27,047 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (think).
2025-05-06 22:26:27,071 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:27,081 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:27,093 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFD2E0>
2025-05-06 22:26:27,093 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8474D50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:27,111 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFD340>
2025-05-06 22:26:27,111 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:27,111 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:27,111 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:27,111 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:27,111 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:27,925 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=804'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:27,926 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:27,926 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:27,926 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:27,926 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:27,926 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:27,927 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 1.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:26:27,927 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:26:27,939 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:26:27,939 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:26:27,939 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 146.295999999973
2025-05-06 22:26:27,939 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: think - Details: Did I find my phone on the bedside table?
2025-05-06 22:26:27,939 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 146.3s. Outcome: Eleanor Hayes paused to consider if she had found her phone on the bedside table.
2025-05-06 22:26:27,939 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:26:27,939 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes paused to consider if she had found her phone on the bedside table.'
2025-05-06 22:26:27,968 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:27,977 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:27,978 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 146.3 (due at 146.3).
2025-05-06 22:26:27,978 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:26:27,978 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:26:27,978 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:26:27,992 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F07380>
2025-05-06 22:26:27,992 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844FAD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:28,012 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFD400>
2025-05-06 22:26:28,012 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:28,012 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:28,012 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:28,012 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:28,012 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:28,079 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:26:28,080 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:26:28,098 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:28,108 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:28,119 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BCF50>
2025-05-06 22:26:28,119 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8476150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:28,141 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BDE50>
2025-05-06 22:26:28,141 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:28,141 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:28,141 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:28,141 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:28,141 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:28,918 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=893'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:28,918 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:28,918 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:28,919 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:28,919 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:28,919 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:28,920 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) straightens up, a hopeful yet wary expression on her face, pausing to men...
2025-05-06 22:26:28,926 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) straightens up, a hopeful yet wary expression on her face, pausing to mentally review her search of the bedside table, the image of its contents lingering in her mind as she tries to determine if the object of her quest was finally within reach.
2025-05-06 22:26:28,926 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) straightens up, a hopeful yet wary expression on her ...
2025-05-06 22:26:29,302 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1149'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:29,302 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:29,302 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:29,303 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:29,303 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:29,303 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:29,320 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:26:29,320 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:26:29,320 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': 'Querying memory to see if I found my phone on the bedside table.'}
2025-05-06 22:26:29,320 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:26:29,345 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:29,356 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:29,367 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F41A60>
2025-05-06 22:26:29,367 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A6A258D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:29,386 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A649E1B0>
2025-05-06 22:26:29,387 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:29,387 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:29,387 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:29,387 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:29,387 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:30,113 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=717'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:30,113 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:30,114 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:30,114 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:30,114 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:30,114 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:30,115 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:26:30,115 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:26:30,126 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:26:30,126 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:26:30,126 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 152.60900000005495
2025-05-06 22:26:30,126 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: Querying memory to see if I found my phone on the bedside table.
2025-05-06 22:26:30,126 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 152.6s. Outcome: Eleanor Hayes attempted to recall if her phone was on the bedside table by searching her memory.
2025-05-06 22:26:30,126 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:26:30,126 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes attempted to recall if her phone was on the bedside table by searching her memory.'
2025-05-06 22:26:30,157 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:30,167 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:30,179 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F07B90>
2025-05-06 22:26:30,179 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84B5BD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:30,197 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A2AF00>
2025-05-06 22:26:30,197 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:30,198 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:30,198 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:30,198 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:30,198 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:30,945 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=738'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:30,945 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:30,945 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:30,945 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:30,946 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:30,946 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:30,947 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) closes her eyes once more, a tiny crease forming between her brows, and d...
2025-05-06 22:26:30,953 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) closes her eyes once more, a tiny crease forming between her brows, and dives back into the mental snapshot of the bedside table, desperately seeking the familiar, reassuring presence of her phone amidst the everyday clutter.
2025-05-06 22:26:30,953 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) closes her eyes once more, a tiny crease forming betw...
2025-05-06 22:26:34,344 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 152.7 (due at 152.6).
2025-05-06 22:26:34,344 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:26:34,344 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:26:34,344 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:26:34,375 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:26:34,375 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:26:34,406 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:34,417 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:34,430 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F50A40>
2025-05-06 22:26:34,430 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8475B50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:34,448 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F439B0>
2025-05-06 22:26:34,448 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:34,448 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:34,448 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:34,448 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:34,448 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:36,042 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:56 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1580'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:36,042 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:36,042 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:36,043 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:36,043 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:36,043 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:36,059 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:26:36,059 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:26:36,059 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': 'Querying memory for the *last time* to determine if the phone was on the bedside table.'}
2025-05-06 22:26:36,059 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:26:36,082 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:36,094 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:36,111 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F53500>
2025-05-06 22:26:36,111 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84B54D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:36,132 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F40FE0>
2025-05-06 22:26:36,132 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:36,132 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:36,132 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:36,132 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:36,132 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:36,909 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=768'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:36,910 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:36,910 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:36,910 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:36,910 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:36,910 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:36,911 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:26:36,911 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:26:36,923 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:26:36,923 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:26:36,923 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 159.35900000005495
2025-05-06 22:26:36,923 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: Querying memory for the *last time* to determine if the phone was on the bedside table.
2025-05-06 22:26:36,923 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 159.4s. Outcome: Eleanor Hayes focused her thoughts, attempting one last time to recall if her phone had been on the bedside table.
2025-05-06 22:26:36,923 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:26:36,923 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes focused her thoughts, attempting one last time to recall if her phone had been on the bedside table.'
2025-05-06 22:26:36,948 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:36,959 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:36,970 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BFB60>
2025-05-06 22:26:36,971 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834DAD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:36,989 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A66F7500>
2025-05-06 22:26:36,990 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:36,990 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:36,990 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:36,990 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:36,990 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:37,868 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:26:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=869'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:37,869 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:37,869 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:37,869 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:37,869 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:37,870 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:37,871 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) summons all her mental fortitude for one final push, focusing intently on...
2025-05-06 22:26:37,877 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) summons all her mental fortitude for one final push, focusing intently on the image of the bedside table, willing her memory to yield a definitive answer to the increasingly maddening question: was her phone there, or wasn't it?
2025-05-06 22:26:37,877 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) summons all her mental fortitude for one final push, ...
2025-05-06 22:26:41,071 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 159.4 (due at 159.4).
2025-05-06 22:26:41,071 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:26:41,071 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:26:41,071 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:26:41,180 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:26:41,180 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:26:41,206 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:41,217 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:41,234 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52060>
2025-05-06 22:26:41,234 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834E6D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:41,253 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED3CE0>
2025-05-06 22:26:41,253 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:41,253 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:41,253 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:41,254 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:41,254 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:42,617 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1352'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:42,618 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:42,618 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:42,618 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:42,618 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:42,618 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:42,639 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:26:42,642 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-06 22:26:42,642 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'Move to the living room to use the computer to check the date.'}
2025-05-06 22:26:42,643 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-06 22:26:42,668 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:42,680 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:42,694 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A66F7500>
2025-05-06 22:26:42,694 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844D9D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:42,712 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83332F0>
2025-05-06 22:26:42,712 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:42,713 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:42,713 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:42,713 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:42,713 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:43,473 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:03 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=749'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:43,474 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:43,474 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:43,474 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:43,474 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:43,474 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:43,475 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:26:43,475 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:26:43,486 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:26:43,486 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:26:43,486 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 170.85900000005495
2025-05-06 22:26:43,486 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: move - Details: Move to the living room to use the computer to check the date.
2025-05-06 22:26:43,486 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 170.9s. Outcome: Eleanor Hayes went to the living room to use the computer to check the date.
2025-05-06 22:26:43,486 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:26:43,486 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes went to the living room to use the computer to check the date.'
2025-05-06 22:26:43,511 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:43,522 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:43,538 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840E2D0>
2025-05-06 22:26:43,538 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834FE50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:43,557 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840EB40>
2025-05-06 22:26:43,558 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:43,558 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:43,558 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:43,558 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:43,558 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:44,391 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=821'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:44,392 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:44,392 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:44,392 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:44,392 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:44,392 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:44,393 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) throws her hands up in a gesture of defeated surrender, abandoning the fr...
2025-05-06 22:26:44,400 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) throws her hands up in a gesture of defeated surrender, abandoning the frustrating search for her phone, and heads back to the living room, now determined to wrest the elusive date from the cold, hard logic of her computer.
2025-05-06 22:26:44,400 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) throws her hands up in a gesture of defeated surrende...
2025-05-06 22:26:52,551 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 170.9 (due at 170.9).
2025-05-06 22:26:52,551 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:26:52,551 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:26:52,551 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:26:52,831 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:26:52,831 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:26:52,860 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:52,872 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:52,885 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840E3C0>
2025-05-06 22:26:52,885 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBFE50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:52,905 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840DF40>
2025-05-06 22:26:52,905 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:52,906 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:52,906 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:52,906 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:52,906 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:53,816 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:14 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=898'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:53,816 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:53,816 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:53,817 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:53,817 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:53,817 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:53,838 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:26:53,838 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-06 22:26:53,838 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'Look around the living room to find the computer.'}
2025-05-06 22:26:53,838 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-06 22:26:54,019 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:54,031 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:54,044 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A66C7EC0>
2025-05-06 22:26:54,044 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834F5D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:54,069 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F51820>
2025-05-06 22:26:54,069 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:54,069 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:54,070 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:54,070 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:54,070 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:54,795 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:15 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=715'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:54,795 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:54,795 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:54,796 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:54,796 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:54,796 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:54,797 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:26:54,797 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:26:54,808 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:26:54,808 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:26:54,808 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 177.06200000003446
2025-05-06 22:26:54,808 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: look_around - Details: Look around the living room to find the computer.
2025-05-06 22:26:54,808 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 177.1s. Outcome: Eleanor Hayes looked around the living room to find the computer.
2025-05-06 22:26:54,808 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:26:54,808 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around the living room to find the computer.'
2025-05-06 22:26:54,835 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:54,847 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:54,863 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F50CB0>
2025-05-06 22:26:54,863 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844D7D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:54,878 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6905250>
2025-05-06 22:26:54,878 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:54,880 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:54,880 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:54,880 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:54,880 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:55,666 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:15 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=778'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:55,666 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:55,666 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:55,668 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:55,668 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:55,668 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:26:55,669 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) surveys the living room, her gaze sweeping over the familiar furniture, n...
2025-05-06 22:26:55,675 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) surveys the living room, her gaze sweeping over the familiar furniture, now with a renewed sense of purpose, searching for the reassuring presence of her computer, the key to unlocking the mysteries of the day.
2025-05-06 22:26:55,675 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) surveys the living room, her gaze sweeping over the f...
2025-05-06 22:26:58,784 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 177.1 (due at 177.1).
2025-05-06 22:26:58,784 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:26:58,784 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:26:58,784 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:26:58,862 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:26:58,862 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:26:58,893 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:26:58,905 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:26:58,922 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52600>
2025-05-06 22:26:58,922 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7EBFAD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:26:58,941 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F500B0>
2025-05-06 22:26:58,941 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:26:58,941 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:26:58,941 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:26:58,942 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:26:58,942 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:26:59,986 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1032'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:26:59,986 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:26:59,986 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:26:59,986 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:26:59,986 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:26:59,987 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:00,004 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:27:00,004 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on computer_414) classified as 'environment'.
2025-05-06 22:27:00,004 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'computer_414', 'details': 'Use the computer to check the date.'}
2025-05-06 22:27:00,004 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-06 22:27:00,031 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:00,043 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:00,057 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A65F4620>
2025-05-06 22:27:00,057 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834F350> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:00,075 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8330FB0>
2025-05-06 22:27:00,075 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:00,076 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:00,076 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:00,076 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:00,076 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:00,751 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=667'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:00,751 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:00,751 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:00,752 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:00,753 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:00,753 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:00,754 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 20.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:27:00,754 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:27:00,766 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:27:00,766 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:27:00,766 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 198.31200000003446
2025-05-06 22:27:00,766 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: use - Details: Use the computer to check the date.
2025-05-06 22:27:00,766 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 198.3s. Outcome: Eleanor Hayes used the computer.
2025-05-06 22:27:00,766 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:27:00,766 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes used the computer.'
2025-05-06 22:27:00,794 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:00,806 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:00,819 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840F320>
2025-05-06 22:27:00,819 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834F450> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:00,836 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F53890>
2025-05-06 22:27:00,836 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:00,837 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:00,837 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:00,837 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:00,837 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:01,600 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:21 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=749'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:01,600 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:01,600 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:01,601 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:01,601 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:01,601 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:01,602 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) approaches the desk, the soft glow of the computer screen beckoning like ...
2025-05-06 22:27:01,608 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) approaches the desk, the soft glow of the computer screen beckoning like a beacon, and settles into the chair, her fingers hovering over the keyboard, ready to finally uncover the truth about the day.
2025-05-06 22:27:01,608 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) approaches the desk, the soft glow of the computer sc...
2025-05-06 22:27:20,003 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 198.3 (due at 198.3).
2025-05-06 22:27:20,003 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:27:20,003 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:27:20,003 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:27:20,327 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:27:20,327 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:27:20,353 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:20,366 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:20,377 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BE990>
2025-05-06 22:27:20,377 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8477E50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:20,397 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BEDB0>
2025-05-06 22:27:20,397 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:20,398 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:20,398 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:20,398 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:20,398 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:21,542 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1130'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:21,542 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:21,542 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:21,543 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:21,543 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:21,543 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:21,560 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:27:21,561 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (think on N/A) classified as 'environment'.
2025-05-06 22:27:21,561 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'think', 'target_id': None, 'details': 'Checking the computer to see the date and figure out the day of the week.'}
2025-05-06 22:27:21,561 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (think).
2025-05-06 22:27:21,587 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:21,600 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:21,613 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED2A50>
2025-05-06 22:27:21,613 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8355CD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:21,631 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED3E60>
2025-05-06 22:27:21,631 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:21,631 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:21,631 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:21,632 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:21,632 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:22,345 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=703'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:22,345 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:22,345 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:22,346 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:22,346 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:22,346 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:22,347 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 1.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:27:22,347 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:27:22,358 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:27:22,358 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:27:22,358 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 200.85900000005495
2025-05-06 22:27:22,358 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: think - Details: Checking the computer to see the date and figure out the day of the week.
2025-05-06 22:27:22,358 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 200.9s. Outcome: Eleanor Hayes paused to consider the date after using the computer.
2025-05-06 22:27:22,358 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:27:22,358 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes paused to consider the date after using the computer.'
2025-05-06 22:27:22,390 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:22,402 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:22,414 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52930>
2025-05-06 22:27:22,414 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834DCD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:22,433 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F52F30>
2025-05-06 22:27:22,433 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:22,434 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:22,434 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:22,434 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:22,434 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:22,612 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 200.9 (due at 200.9).
2025-05-06 22:27:22,612 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:27:22,612 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:27:22,612 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:27:23,044 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:27:23,044 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:27:23,066 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:23,078 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:23,091 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FAA930>
2025-05-06 22:27:23,091 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844E2D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:23,110 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FAA240>
2025-05-06 22:27:23,110 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:23,110 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:23,110 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:23,111 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:23,111 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:23,350 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=903'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:23,351 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:23,351 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:23,351 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:23,351 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:23,351 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:23,353 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) leans forward, her eyes scanning the screen, a faint line of concentratio...
2025-05-06 22:27:23,359 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) leans forward, her eyes scanning the screen, a faint line of concentration etching itself between her eyebrows as she processes the information displayed, the answer to her morning-long quest now tantalizingly close.
2025-05-06 22:27:23,362 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) leans forward, her eyes scanning the screen, a faint ...
2025-05-06 22:27:24,113 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=991'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:24,113 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:24,113 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:24,114 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:24,114 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:24,114 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:24,136 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:27:24,136 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:27:24,136 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': 'Using load_memory to check the date on the computer.'}
2025-05-06 22:27:24,136 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:27:24,163 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:24,176 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:24,191 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399F60230>
2025-05-06 22:27:24,191 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834D6D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:24,211 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FA9430>
2025-05-06 22:27:24,211 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:24,211 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:24,211 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:24,212 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:24,212 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:25,002 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:45 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=781'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:25,002 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:25,002 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:25,003 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:25,003 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:25,003 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:25,004 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:27:25,005 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:27:25,015 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:27:25,015 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:27:25,015 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 207.43700000003446
2025-05-06 22:27:25,015 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: Using load_memory to check the date on the computer.
2025-05-06 22:27:25,015 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 207.4s. Outcome: Eleanor Hayes attempted to recall the date she saw on the computer by searching her memory.
2025-05-06 22:27:25,015 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:27:25,015 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes attempted to recall the date she saw on the computer by searching her memory.'
2025-05-06 22:27:25,043 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:25,056 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:25,069 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BC9E0>
2025-05-06 22:27:25,069 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834E550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:25,087 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BECF0>
2025-05-06 22:27:25,087 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:25,087 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:25,087 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:25,087 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:25,087 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:25,982 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=885'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:25,982 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:25,982 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:25,983 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:25,983 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:25,983 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:25,984 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) closes her eyes, takes a steadying breath, and once more dives into the l...
2025-05-06 22:27:25,990 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) closes her eyes, takes a steadying breath, and once more dives into the labyrinth of her memory, this time focusing on the image of the computer screen, willing the numbers and words to coalesce into a clear and unambiguous date.
2025-05-06 22:27:25,990 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) closes her eyes, takes a steadying breath, and once m...
2025-05-06 22:27:29,197 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 207.5 (due at 207.4).
2025-05-06 22:27:29,197 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:27:29,197 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:27:29,197 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:27:29,233 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:27:29,233 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:27:29,260 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:29,273 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:29,290 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FA80B0>
2025-05-06 22:27:29,291 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834F8D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:29,310 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FA93D0>
2025-05-06 22:27:29,310 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:29,310 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:29,310 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:29,311 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:29,311 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:30,551 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1225'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:30,551 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:30,551 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:30,552 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:30,552 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:30,552 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:30,569 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:27:30,569 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (load_memory on N/A) classified as 'environment'.
2025-05-06 22:27:30,570 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'load_memory', 'target_id': None, 'details': 'One last attempt to load the date from the computer.'}
2025-05-06 22:27:30,570 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (load_memory).
2025-05-06 22:27:30,598 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:30,612 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:30,625 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8333A70>
2025-05-06 22:27:30,625 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844CC50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:30,643 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A8333140>
2025-05-06 22:27:30,643 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:30,643 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:30,643 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:30,644 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:30,644 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:31,466 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=814'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:31,466 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:31,466 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:31,466 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:31,466 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:31,466 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:31,467 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:27:31,468 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:27:31,478 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:27:31,478 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:27:31,478 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 213.795999999973
2025-05-06 22:27:31,478 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: load_memory - Details: One last attempt to load the date from the computer.
2025-05-06 22:27:31,478 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 213.8s. Outcome: Eleanor Hayes focused her thoughts, attempting one final time to recall the day of the week shown on the computer.
2025-05-06 22:27:31,478 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:27:31,478 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes focused her thoughts, attempting one final time to recall the day of the week shown on the computer.'
2025-05-06 22:27:31,505 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:31,518 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:31,530 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A691CAD0>
2025-05-06 22:27:31,531 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A83552D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:31,551 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED3E00>
2025-05-06 22:27:31,551 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:31,551 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:31,551 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:31,551 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:31,551 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:32,367 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:52 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=804'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:32,367 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:32,367 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:32,368 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:32,368 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:32,368 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:32,369 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) steels herself for one last mental plunge, her brow furrowed in concentra...
2025-05-06 22:27:32,375 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) steels herself for one last mental plunge, her brow furrowed in concentration as she strains to recall the day of the week displayed on the computer screen, hoping to finally break free from the frustrating cycle of forgotten information.
2025-05-06 22:27:32,375 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) steels herself for one last mental plunge, her brow f...
2025-05-06 22:27:35,488 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 213.8 (due at 213.8).
2025-05-06 22:27:35,488 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:27:35,488 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:27:35,488 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:27:35,647 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:27:35,647 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:27:35,674 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:35,688 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:35,700 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840C140>
2025-05-06 22:27:35,700 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84B7150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:35,716 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F53D40>
2025-05-06 22:27:35,716 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:35,716 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:35,716 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:35,716 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:35,716 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:37,041 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1316'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:37,041 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:37,041 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:37,041 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:37,041 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:37,041 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:37,058 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:27:37,059 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-06 22:27:37,059 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'Move to the bathroom to start my morning routine.'}
2025-05-06 22:27:37,059 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-06 22:27:37,087 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:37,101 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:37,116 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FD77D0>
2025-05-06 22:27:37,116 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834FE50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:37,134 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399F60230>
2025-05-06 22:27:37,134 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:37,134 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:37,135 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:37,135 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:37,135 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:37,916 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=767'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:37,916 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:37,916 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:37,916 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:37,916 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:37,916 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:37,917 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:27:37,917 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:27:37,929 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:27:37,929 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:27:37,929 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 225.295999999973
2025-05-06 22:27:37,929 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: move - Details: Move to the bathroom to start my morning routine.
2025-05-06 22:27:37,929 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 225.3s. Outcome: Eleanor Hayes went to the bathroom to start her morning routine.
2025-05-06 22:27:37,929 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:27:37,929 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes went to the bathroom to start her morning routine.'
2025-05-06 22:27:37,959 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:37,972 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:37,986 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840E210>
2025-05-06 22:27:37,986 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A834C1D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:38,003 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FAA6C0>
2025-05-06 22:27:38,003 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:38,004 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:38,004 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:38,004 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:38,004 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:38,839 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:27:59 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=827'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:38,840 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:38,840 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:38,840 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:38,841 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:38,841 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:38,842 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) pushes back from the computer, a sigh escaping her lips, and heads toward...
2025-05-06 22:27:38,847 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) pushes back from the computer, a sigh escaping her lips, and heads towards the bathroom, resigning herself to the assumption that it's Monday and mentally preparing for the familiar rituals of her morning routine.
2025-05-06 22:27:38,847 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) pushes back from the computer, a sigh escaping her li...
2025-05-06 22:27:46,981 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 225.3 (due at 225.3).
2025-05-06 22:27:46,981 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:27:46,981 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:27:46,981 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:27:47,275 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:27:47,275 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:27:47,307 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:47,320 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:47,340 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BF2C0>
2025-05-06 22:27:47,341 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F0B6D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:47,359 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BFE90>
2025-05-06 22:27:47,359 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:47,360 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:47,360 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:47,360 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:47,360 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:48,524 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:28:08 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1150'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:48,524 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:48,524 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:48,524 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:48,525 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:48,525 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:48,542 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:27:48,542 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-06 22:27:48,542 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'Look around the bathroom to find the sink and toothbrush.'}
2025-05-06 22:27:48,542 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-06 22:27:48,568 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:48,582 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:48,595 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840CC50>
2025-05-06 22:27:48,595 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8527450> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:48,613 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A5627DA0>
2025-05-06 22:27:48,613 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:48,613 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:48,613 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:48,614 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:48,614 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:49,329 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:28:09 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=706'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:49,329 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:49,330 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:49,330 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:49,330 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:49,330 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:49,332 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:27:49,332 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:27:49,342 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:27:49,342 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:27:49,342 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 231.81200000003446
2025-05-06 22:27:49,342 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: look_around - Details: Look around the bathroom to find the sink and toothbrush.
2025-05-06 22:27:49,342 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 231.8s. Outcome: Eleanor Hayes looked around the bathroom to find the sink and toothbrush.
2025-05-06 22:27:49,342 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:27:49,342 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around the bathroom to find the sink and toothbrush.'
2025-05-06 22:27:49,373 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:49,387 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:49,398 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7FABEF0>
2025-05-06 22:27:49,398 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8505850> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:49,417 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840F800>
2025-05-06 22:27:49,417 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:49,417 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:49,417 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:49,417 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:49,417 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:50,215 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:28:10 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=786'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:50,216 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:50,216 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:50,216 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:50,216 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:50,216 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:50,217 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) steps into the bathroom, her gaze sweeping across the familiar space, con...
2025-05-06 22:27:50,223 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) steps into the bathroom, her gaze sweeping across the familiar space, confirming the presence of the sink, the mirror, and the toothbrush holder, the essential tools of her morning ablutions.
2025-05-06 22:27:50,224 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) steps into the bathroom, her gaze sweeping across the...
2025-05-06 22:27:53,579 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 231.9 (due at 231.8).
2025-05-06 22:27:53,579 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:27:53,579 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:27:53,579 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:27:53,641 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:27:53,641 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:27:53,669 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:53,683 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:53,699 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BE720>
2025-05-06 22:27:53,699 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8474C50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:53,717 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A5627DA0>
2025-05-06 22:27:53,717 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:53,718 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:53,718 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:53,718 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:53,718 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:54,772 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:28:15 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1041'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:54,772 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:54,772 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:54,773 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:54,773 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:54,773 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:54,791 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:27:54,794 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on toothbrush_824) classified as 'environment'.
2025-05-06 22:27:54,794 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'toothbrush_824', 'details': 'Use the toothbrush to brush my teeth.'}
2025-05-06 22:27:54,794 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-06 22:27:54,821 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:54,836 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:54,850 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFD910>
2025-05-06 22:27:54,850 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84B4CD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:54,870 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840E630>
2025-05-06 22:27:54,870 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:54,870 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:54,870 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:54,870 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:54,870 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:55,610 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:28:15 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=729'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:55,611 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:55,611 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:55,611 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:55,612 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:55,612 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:55,613 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 120.0, "results": {}, "outcome_description": "Eleanor Hay...
2025-05-06 22:27:55,613 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:27:55,624 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:27:55,624 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:27:55,624 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 353.0929999999935
2025-05-06 22:27:55,624 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: use - Details: Use the toothbrush to brush my teeth.
2025-05-06 22:27:55,624 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 353.1s. Outcome: Eleanor Hayes brushed her teeth.
2025-05-06 22:27:55,624 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:27:55,625 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes brushed her teeth.'
2025-05-06 22:27:55,652 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:27:55,667 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:27:55,678 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BE6C0>
2025-05-06 22:27:55,678 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8505050> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:27:55,697 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BE420>
2025-05-06 22:27:55,697 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:27:55,697 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:27:55,697 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:27:55,697 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:27:55,697 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:27:56,603 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:28:16 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=895'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:27:56,603 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:27:56,603 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:27:56,604 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:27:56,604 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:27:56,604 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:27:56,605 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) picks up her toothbrush, squeezes a stripe of toothpaste onto the bristle...
2025-05-06 22:27:56,611 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) picks up her toothbrush, squeezes a stripe of toothpaste onto the bristles, and begins to brush, the minty freshness filling her mouth as the familiar rhythm of the morning takes hold.
2025-05-06 22:27:56,611 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) picks up her toothbrush, squeezes a stripe of toothpa...
2025-05-06 22:29:54,804 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 353.1 (due at 353.1).
2025-05-06 22:29:54,804 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:29:54,804 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:29:54,804 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:29:55,222 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:29:55,223 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:29:55,249 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:29:55,269 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:29:55,283 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BC350>
2025-05-06 22:29:55,283 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84B5B50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:29:55,300 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F052B0>
2025-05-06 22:29:55,300 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:29:55,300 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:29:55,300 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:29:55,301 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:29:55,301 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:29:56,364 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:30:16 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1054'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:29:56,365 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:29:56,365 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:29:56,365 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:29:56,365 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:29:56,365 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:29:56,382 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:29:56,382 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on sink_229) classified as 'environment'.
2025-05-06 22:29:56,382 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'sink_229', 'details': 'Wash my face at the sink.'}
2025-05-06 22:29:56,382 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-06 22:29:56,413 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:29:56,428 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:29:56,441 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6558AD0>
2025-05-06 22:29:56,441 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8506AD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:29:56,459 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6906360>
2025-05-06 22:29:56,459 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:29:56,459 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:29:56,459 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:29:56,459 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:29:56,459 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:29:57,211 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:30:17 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=742'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:29:57,211 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:29:57,212 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:29:57,212 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:29:57,212 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:29:57,212 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:29:57,213 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 60.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:29:57,213 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:29:57,224 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:29:57,224 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:29:57,224 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 414.670999999973
2025-05-06 22:29:57,224 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: use - Details: Wash my face at the sink.
2025-05-06 22:29:57,224 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 414.7s. Outcome: Eleanor Hayes washed her face at the sink.
2025-05-06 22:29:57,224 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:29:57,224 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes washed her face at the sink.'
2025-05-06 22:29:57,252 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:29:57,267 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:29:57,286 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F53950>
2025-05-06 22:29:57,286 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A8504F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:29:57,303 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A681A720>
2025-05-06 22:29:57,303 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:29:57,303 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:29:57,303 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:29:57,303 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:29:57,303 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:29:58,123 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:30:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=810'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:29:58,123 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:29:58,123 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:29:58,123 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:29:58,124 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:29:58,124 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:29:58,125 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) rinses the toothpaste from her mouth and splashes cool water onto her fac...
2025-05-06 22:29:58,131 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) rinses the toothpaste from her mouth and splashes cool water onto her face, the refreshing sensation awakening her senses and washing away the last vestiges of sleepiness.
2025-05-06 22:29:58,131 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) rinses the toothpaste from her mouth and splashes coo...
2025-05-06 22:30:56,433 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 414.8 (due at 414.7).
2025-05-06 22:30:56,433 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:30:56,433 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:30:56,433 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:30:56,727 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:30:56,727 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:30:56,755 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:30:56,770 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:30:56,799 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6A28DA0>
2025-05-06 22:30:56,799 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84B5150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:30:56,825 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A696B3B0>
2025-05-06 22:30:56,825 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:30:56,825 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:30:56,825 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:30:56,825 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:30:56,825 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:30:58,064 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1226'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:30:58,064 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:30:58,064 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:30:58,064 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:30:58,065 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:30:58,065 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:30:58,082 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:30:58,082 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-06 22:30:58,082 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'Move back to the bedroom to get dressed.'}
2025-05-06 22:30:58,083 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-06 22:30:58,109 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:30:58,128 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:30:58,140 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A57E47D0>
2025-05-06 22:30:58,141 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844E1D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:30:58,157 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6558AD0>
2025-05-06 22:30:58,158 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:30:58,158 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:30:58,158 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:30:58,158 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:30:58,158 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:30:58,899 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=733'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:30:58,899 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:30:58,899 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:30:58,899 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:30:58,900 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:30:58,900 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:30:58,901 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-06 22:30:58,901 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:30:58,911 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:30:58,911 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:30:58,912 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 426.39000000001397
2025-05-06 22:30:58,912 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: move - Details: Move back to the bedroom to get dressed.
2025-05-06 22:30:58,912 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 426.4s. Outcome: Eleanor Hayes returned to the bedroom to get dressed.
2025-05-06 22:30:58,912 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:30:58,912 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes returned to the bedroom to get dressed.'
2025-05-06 22:30:58,941 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:30:58,956 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:30:58,982 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F528A0>
2025-05-06 22:30:58,982 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A6A254D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:30:59,002 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3970BF680>
2025-05-06 22:30:59,002 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:30:59,003 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:30:59,003 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:30:59,003 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:30:59,003 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:30:59,883 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=870'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:30:59,883 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:30:59,883 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:30:59,884 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:30:59,884 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:30:59,884 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:30:59,886 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) leaves the bathroom and heads back to the bedroom, the prospect of changi...
2025-05-06 22:30:59,891 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) leaves the bathroom and heads back to the bedroom, the prospect of changing out of her pajamas and into her work clothes signaling a definitive transition into the day ahead.
2025-05-06 22:30:59,892 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) leaves the bathroom and heads back to the bedroom, th...
2025-05-06 22:31:08,130 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 426.5 (due at 426.4).
2025-05-06 22:31:08,130 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:31:08,130 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:31:08,130 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:31:08,239 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:31:08,239 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:31:08,268 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:31:08,284 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:31:08,300 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F04620>
2025-05-06 22:31:08,300 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844EF50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:31:08,319 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A840E930>
2025-05-06 22:31:08,319 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:31:08,320 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:31:08,320 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:31:08,320 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:31:08,320 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:31:09,334 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1000'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:31:09,334 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:31:09,334 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:31:09,335 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:31:09,335 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:31:09,335 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:31:09,351 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:31:09,351 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-06 22:31:09,352 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'Look around to find the closet or dresser where I keep my clothes.'}
2025-05-06 22:31:09,352 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-06 22:31:09,379 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:31:09,394 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:31:09,408 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A6558AD0>
2025-05-06 22:31:09,408 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A7F303D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:31:09,428 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A696BF80>
2025-05-06 22:31:09,428 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:31:09,428 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:31:09,428 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:31:09,428 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:31:09,428 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:31:10,184 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:30 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=746'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:31:10,184 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:31:10,184 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:31:10,184 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:31:10,184 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:31:10,185 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:31:10,186 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-06 22:31:10,186 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:31:10,197 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:31:10,198 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:31:10,198 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 432.5929999999935
2025-05-06 22:31:10,198 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: look_around - Details: Look around to find the closet or dresser where I keep my clothes.
2025-05-06 22:31:10,198 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 432.6s. Outcome: Eleanor Hayes looked around the bedroom to find the closet or dresser.
2025-05-06 22:31:10,198 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:31:10,198 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around the bedroom to find the closet or dresser.'
2025-05-06 22:31:10,226 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:31:10,242 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:31:10,257 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83BF0B0>
2025-05-06 22:31:10,257 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84B77D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:31:10,274 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7F53200>
2025-05-06 22:31:10,274 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:31:10,274 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:31:10,274 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:31:10,274 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:31:10,274 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:31:11,068 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:31 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=784'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:31:11,068 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:31:11,068 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:31:11,069 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:31:11,069 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:31:11,069 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:31:11,070 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) surveys the bedroom, her eyes seeking out the familiar forms of the close...
2025-05-06 22:31:11,077 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) surveys the bedroom, her eyes seeking out the familiar forms of the closet and the dresser, the twin repositories of her daily wardrobe, ready to equip her for the day ahead.
2025-05-06 22:31:11,077 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) surveys the bedroom, her eyes seeking out the familia...
2025-05-06 22:31:14,348 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 432.7 (due at 432.6).
2025-05-06 22:31:14,348 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-06 22:31:14,348 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = idle
2025-05-06 22:31:14,348 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-06 22:31:14,349 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-06 22:31:14,349 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-06 22:31:14,379 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:31:14,395 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:31:14,409 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFC860>
2025-05-06 22:31:14,409 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84745D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:31:14,426 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A66F7500>
2025-05-06 22:31:14,426 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:31:14,426 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:31:14,426 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:31:14,427 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:31:14,427 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:31:15,474 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1034'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:31:15,475 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:31:15,475 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:31:15,476 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:31:15,476 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:31:15,476 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:31:15,494 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = thinking
2025-05-06 22:31:15,494 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on closet_951) classified as 'environment'.
2025-05-06 22:31:15,494 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'closet_951', 'details': 'Use the closet to get dressed for work.'}
2025-05-06 22:31:15,494 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-06 22:31:15,525 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:31:15,541 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:31:15,555 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A83332C0>
2025-05-06 22:31:15,555 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A844E8D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:31:15,577 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A7ED32F0>
2025-05-06 22:31:15,577 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:31:15,577 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:31:15,577 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:31:15,577 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:31:15,577 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:31:16,312 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:36 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=724'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:31:16,312 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:31:16,312 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:31:16,312 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:31:16,312 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:31:16,312 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:31:16,313 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 300.0, "results": {}, "outcome_description": "Eleanor Hay...
2025-05-06 22:31:16,314 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-06 22:31:16,324 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.status = busy
2025-05-06 22:31:16,324 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.pending_results = {}
2025-05-06 22:31:16,324 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_end_time = 733.765000000014
2025-05-06 22:31:16,324 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.current_action_description = Action: use - Details: Use the closet to get dressed for work.
2025-05-06 22:31:16,325 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 733.8s. Outcome: Eleanor Hayes got dressed using the closet.
2025-05-06 22:31:16,325 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The familiar, everyday real world; starting the morning routine at home.'
2025-05-06 22:31:16,325 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes got dressed using the closet.'
2025-05-06 22:31:16,355 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-06 22:31:16,371 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-06 22:31:16,383 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A3A57E47D0>
2025-05-06 22:31:16,383 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001A3A84B7650> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-06 22:31:16,408 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001A399FFDB80>
2025-05-06 22:31:16,408 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-06 22:31:16,408 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-06 22:31:16,408 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-06 22:31:16,408 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-06 22:31:16,408 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-06 22:31:17,370 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 07 May 2025 02:31:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=951'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-06 22:31:17,371 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-06 22:31:17,371 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-06 22:31:17,371 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-06 22:31:17,371 - httpcore.http11 - DEBUG - response_closed.started
2025-05-06 22:31:17,372 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-06 22:31:17,373 - src.simulation_async - DEBUG - NarrationLLM Final Content: Eleanor Hayes (sim_3e912d) opens the closet door and steps inside, the scent of clean laundry and fa...
2025-05-06 22:31:17,379 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra.sim_3e912d.last_observation = Eleanor Hayes (sim_3e912d) opens the closet door and steps inside, the scent of clean laundry and familiar fabrics enveloping her as she begins the process of selecting her outfit, choosing the clothes that will carry her through the day's demands.
2025-05-06 22:31:17,379 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor Hayes (sim_3e912d) opens the closet door and steps inside, the scent of ...
