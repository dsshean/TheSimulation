2025-05-08 08:10:26,835 - __main__ - INFO - --- Application Start (main_async.py) --- Logging to: simulation_async.log
2025-05-08 08:10:26,839 - asyncio - DEBUG - Using selector: SelectSelector
2025-05-08 08:10:26,855 - src.simulation_async - INFO - ADK InMemoryMemoryService initialized.
2025-05-08 08:10:26,855 - src.simulation_async - INFO - Google Generative AI configured.
2025-05-08 08:10:26,858 - src.simulation_async - INFO - Starting simulation initialization.
2025-05-08 08:10:26,858 - src.loop_utils - INFO - No instance UUID provided. Attempting to load the latest simulation.
2025-05-08 08:10:26,861 - src.loop_utils - INFO - Found latest world config: world_config_05e07dad-f24b-420b-822c-1ae7862220f6.json with UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-08 08:10:26,862 - src.loop_utils - DEBUG - Processing life summary file: life_summary_Eleanor_Hayes_05e07dad-f24b-420b-822c-1ae7862220f6.json. Found sim_id: 'sim_3e912d'
2025-05-08 08:10:26,862 - src.loop_utils - INFO - Loaded life summary: life_summary_Eleanor_Hayes_05e07dad-f24b-420b-822c-1ae7862220f6.json for sim_id: sim_3e912d
2025-05-08 08:10:26,862 - src.loop_utils - DEBUG - File not found: C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json. Returning default.
2025-05-08 08:10:26,862 - src.loop_utils - INFO - No existing state file found at C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json. Will create a new one.
2025-05-08 08:10:26,862 - src.loop_utils - INFO - Initializing new simulation state for UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-08 08:10:26,863 - src.loop_utils - INFO - Creating a new simulation state from template for UUID: 05e07dad-f24b-420b-822c-1ae7862220f6
2025-05-08 08:10:34,119 - src.loop_utils - DEBUG - Syncing world_config (UUID: 05e07dad-f24b-420b-822c-1ae7862220f6) to state (UUID: 05e07dad-f24b-420b-822c-1ae7862220f6).
2025-05-08 08:10:34,120 - src.loop_utils - INFO - Simulation state for 05e07dad-f24b-420b-822c-1ae7862220f6 was modified during load/initialization. Saving changes to C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json.
2025-05-08 08:10:34,121 - src.loop_utils - DEBUG - Successfully saved JSON to C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-08 08:10:34,121 - src.simulation_async - INFO - Initialization complete. Instance 05e07dad-f24b-420b-822c-1ae7862220f6 ready with 1 simulacra.
2025-05-08 08:10:34,123 - src.simulation_async - INFO - ADK Session created: sim_session_05e07dad-f24b-420b-822c-1ae7862220f6.
2025-05-08 08:10:34,125 - src.simulation_async - INFO - Created 1 simulacra agents.
2025-05-08 08:10:34,125 - src.simulation_async - INFO - Main ADK Runner initialized.
2025-05-08 08:10:34,125 - src.simulation_async - INFO - Dedicated Search Agent Runner initialized.
2025-05-08 08:10:34,134 - src.simulation_async - INFO - Started 8 tasks.
2025-05-08 08:10:34,135 - src.simulation_async - INFO - [TimeManager] Task started.
2025-05-08 08:10:34,135 - src.simulation_async - INFO - [InteractionDispatcher] Task started.
2025-05-08 08:10:34,135 - src.simulation_async - INFO - [WorldInfoGatherer] Task started.
2025-05-08 08:10:34,135 - src.simulation_async - INFO - [NarrativeImageGenerator] Task started. Will generate images every 500.0 real seconds.
2025-05-08 08:10:34,136 - src.simulation_async - INFO - [NarrativeImageGenerator] Using model: gemini-2.0-flash-preview-image-generation
2025-05-08 08:10:34,136 - src.simulation_async - INFO - [NarrativeImageGenerator] Saving images to: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images
2025-05-08 08:10:34,271 - src.simulation_async - INFO - [DynamicInterruptionTask] Task started.
2025-05-08 08:10:34,271 - src.simulation_async - INFO - [NarrationTask] Task started.
2025-05-08 08:10:34,271 - src.simulation_async - INFO - [WorldEngineLLM] Task started.
2025-05-08 08:10:34,271 - src.simulation_async - INFO - [Eleanor Hayes] LLM Agent task started.
2025-05-08 08:10:34,272 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:10:34,272 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending initial context prompt as agent is idle.
2025-05-08 08:10:34,283 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:34,283 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The real world and general slice of life.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The real world and general slice of life.' atmosphere.
**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
EVERYTHING YOU DO MUST BE CONSISTENT WITH YOUR INTERNAL KNOWLEDGE OF WHERE YOU ARE AND WHO YOU ARE. 
EXAMPLE: GOING TO PLACES MUST BE A REAL PLACE TO A REAL DESTINATION. AS A RESIDENT OF THE AREA BASED ON YOUR LIFE SUMMARY, YOU MUST KNOW WHERE YOU ARE GOING AND HOW TO GET THERE.

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The real world and general slice of life.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The real world and general slice of life.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The real world and general slice of life.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
            *   **Talking to Ephemeral NPCs (introduced by Narrator):**
            *   If the Narrator described an NPC (e.g., "a street vendor," "a mysterious figure"), you can interact by setting `action_type: "talk"`.
            *   In `details`, specify who you are talking to based on the narrative description (e.g., `details: "to the street vendor about the strange weather"`).
            *   If the Narrator provided a conceptual tag (e.g., "your friend Alex (npc_concept_friend_alex)"), you can use `target_id: "npc_concept_friend_alex"` and provide conversational content in `details`. This `target_id` is for contextual understanding by the World Engine, not a lookup in the game state.
    *   **World Interactions:** `look_around`, `move` (Specify `details` like target location ID or name), `world_action` (Specify `details` for generic world interactions not covered by other types).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The real world and general slice of life.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The real world and general slice of life.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The real world and general slice of life.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"Handle the requests as specified in the System Instruction."}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-08 08:10:34,283 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:34,295 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:34,315 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E9799A0>
2025-05-08 08:10:34,316 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E8B5C50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:34,336 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E97BB00>
2025-05-08 08:10:34,337 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:34,338 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:34,338 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:34,338 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:34,338 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:35,965 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:10:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1613'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:35,966 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:35,967 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:35,967 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:35,967 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:35,968 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:35,969 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.", "action_type": "initiate_change", "target_id": null, "details": "Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.38326711432878363}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":172,"candidates_tokens_details":[{"modality":"TEXT","token_count":172}],"prompt_token_count":1440,"prompt_tokens_details":[{"modality":"TEXT","token_count":1440}],"total_token_count":1612},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:35,970 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice o...'
2025-05-08 08:10:35,970 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice o...'
2025-05-08 08:10:35,970 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice o
2025-05-08 08:10:35,990 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:10:35,990 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (initiate_change on N/A) classified as 'environment'.
2025-05-08 08:10:35,990 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'initiate_change', 'target_id': None, 'details': "Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good."}
2025-05-08 08:10:35,990 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (initiate_change).
2025-05-08 08:10:35,991 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: 4ksuz819
2025-05-08 08:10:36,000 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:36,000 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.
**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Current Location
- Current World Time
- World Context:
- Actor's Current Location State (Details of the location where the actor currently is, including name, description, objects_present, connected_locations with potential travel metadata like mode/time/distance)
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Target Entity State (if applicable)
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
    *   For `move` actions, `intent.details` specifies the target location's ID or a well-known name.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`:
                *   Check `Target Entity State.is_interactive` property. If false, action is invalid.
                *   **If `Target Entity State.properties.leads_to` exists (e.g., for a door or portal):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 5-15s for opening a door and stepping through).
                    *   `results`: `{"simulacra_profiles.[sim_id].location": "[Target Entity State.properties.leads_to_value]"}`.
                    *   `outcome_description`: `"[Actor Name] used the [Target Entity State.name] and moved to [Name of the new location if known, otherwise the ID from leads_to]."`.
                *   Else (for other usable objects): Check other object properties (`toggleable`, `lockable`), and current state to determine outcome, duration, and results (e.g., turning a lamp on/off).
            *   `talk`:
                *   **If target is a Simulacra:**
                    *   Check if Actor and Target Simulacra are in the same `Actor's Current Location ID`.
                    *   If not, `valid_action: false`, `duration: 0.0`, `results: {}`, `outcome_description: "[Actor Name] tried to talk to [Target Simulacra Name], but they are not in the same location."`
                    *   If yes, `valid_action: true`, `duration: short (e.g., 30-120s)`, `results: {"simulacra_profiles.[target_id].last_observation": "[Actor Name] said to you: '{intent.details}'"}`, `outcome_description: "[Actor Name] spoke with [Target Simulacra Name]."`
                *   **If target is an ephemeral NPC (indicated by `intent.target_id` starting with 'npc_concept_' OR if `intent.details` clearly refers to an NPC described in the Actor's `last_observation` which was set by the Narrator):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 15-60s).
                    *   **NPC Response Generation:**
                        *   Examine the `Actor's Last Observation` (provided implicitly via the actor's state, which you don't directly see but influences the context) and `Recent Narrative History` (if available in your input context) to understand the NPC described by the Narrator.
                        *   Consider `intent.details` (what the Actor said to this NPC).
                        *   Craft a plausible `npc_response_content` from the perspective of this ephemeral NPC, fitting the narrative context.
                        *   Determine a generic `npc_description_for_output` (e.g., "the shopkeeper", "your friend", "the street vendor") based on how the Narrator introduced them or how the actor referred to them in the intent.
                    *   `results`: Format as `{"simulacra_profiles.[actor_id].last_observation": "The [npc_description_for_output] said: '[npc_response_content]'"}`. Replace bracketed parts with your generated content.
                    *   `outcome_description`: Format as `"[Actor Name] spoke with the [npc_description_for_output]."` Replace bracketed parts.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`:
                *   **Destination:** The target location ID is in `intent.details`.
                *   **Validity:**
                    *   Check if the target location ID exists in the `Actor's Current Location State.connected_locations`.
                    *   If not directly connected, consider if it's a known global location ID based on `World Context`.
                    *   If `World Rules.allow_teleportation` is true, and intent implies it, this might be valid.
                *   **Duration Calculation (see step 3):** This is critical for `move`.
                *   **Results:** If valid, `simulacra_profiles.[sim_id].location` should be updated to the target location ID from `intent.details`.
            *   `look_around`: Provides a general observation. Duration is short. Results update `simulacra_profiles.[sim_id].last_observation` with a description of the current location and entities.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
    *   For `move` actions:
        *   If moving to a location listed in `Actor's Current Location State.connected_locations` which has explicit travel time, use that.
        *   If `World Context.World Type` is "real":
            *   Estimate travel time based on the distance between `Actor's Current Location State.name` and the target location (from `intent.details`, potentially referencing `World Context.Overall World Location`).
            *   Use common sense for travel modes (walking for short distances within a city, car/transit for longer). Factor in `World Feeds.Weather` if `World Rules.weather_effects_travel` is true.
        *   If `World Context.World Type` is "fictional":
            *   Estimate based on implied distances from `World Context.World Description`, `Actor's Current Location State`, and the nature of the target location.
            *   Consider fantasy/sci-fi travel methods if appropriate for the `World Context.Sub-Genre`.
        *   If moving between adjacent sub-locations within a larger complex (e.g., "kitchen" to "living_room" if current location is "house_interior"), duration should be very short (e.g., 5-30 seconds).
    *   For other actions, assign plausible durations (e.g., `talk` a few minutes, `use` object varies, `wait` as specified or short).
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"` or `simulacra_profiles.[sim_id].field: "value"`). Empty `{}` for invalid actions.
    *   For a successful `move`, the key result is `{ "simulacra_profiles.[sim_id].location": "[target_location_id_from_intent.details]" }`.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 08:10:36,000 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:36,002 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:36,014 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E9048C0>
2025-05-08 08:10:36,015 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E96A9D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:36,034 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E8AB290>
2025-05-08 08:10:36,034 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:36,034 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:36,034 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:36,034 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:36,034 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:37,165 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:10:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1118'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:37,166 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:37,166 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:37,166 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:37,166 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:37,166 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:37,167 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": true, "duration": 2.0, "results": {"simulacra_profiles.sim_3e912d.status": "idle", "simulacra_profiles.sim_3e912d.current_action_end_time": 1714899323.0, "simulacra_profiles.sim_3e912d.last_observation": "Feeling a bit restless and unproductive."}, "outcome_description": "Eleanor Hayes realized she was feeling restless."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra_profiles.sim_3e912d.status\": \"idle\", \"simulacra_profiles.sim_3e912d.current_action_end_time\": 1714899323.0, \"simulacra_profiles.sim_3e912d.last_observation\": \"Feeling a bit restless and unproductive.\"}, \"outcome_description\": \"Eleanor Hayes realized she was feeling restless.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.1025387824527801}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":126,"candidates_tokens_details":[{"modality":"TEXT","token_count":126}],"prompt_token_count":2893,"prompt_tokens_details":[{"modality":"TEXT","token_count":2893}],"total_token_count":3019},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:37,167 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 2.0, "results": {"simulacra_profiles.sim_3e912d.status": ...
2025-05-08 08:10:37,167 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 2.0, "results": {"simulacra_profiles.sim_3e912d.status": "idle", "simulacra_profiles.sim_3e912d.current_action_end_time": 1714899323.0, "simulacra_profiles.sim_3e912...'
2025-05-08 08:10:37,167 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 2.0, "results": {"simulacra_profiles.sim_3e912d.status": "idle", "simulacra_profiles.sim_3e912d.current_action_end_time": 1714899323.0, "simulacra_profiles.sim_3e912...'
2025-05-08 08:10:37,167 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 2.0, 'results': {'simulacra_profiles.sim_3e912d.status': 'idle', 'simulacra_profiles.sim_3e912d.current_action_end_time': 1714899323.0, 'simulacra_profiles.sim_3e912
2025-05-08 08:10:37,167 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:10:37,178 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:10:37,181 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.status': 'idle', 'simulacra_profiles.sim_3e912d.current_action_end_time': 1714899323.0, 'simulacra_profiles.sim_3e912d.last_observation': 'Feeling a bit restless and unproductive.'}
2025-05-08 08:10:37,181 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 3.8119999999180436
2025-05-08 08:10:37,181 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: initiate_change - Details: Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my hea
2025-05-08 08:10:37,181 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 3.8s. Outcome: Eleanor Hayes realized she was feeling restless.
2025-05-08 08:10:37,181 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Home_01
2025-05-08 08:10:37,181 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes realized she was feeling restless.'
2025-05-08 08:10:37,182 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: p7mQ2RGm
2025-05-08 08:10:37,182 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: 4ksuz819
2025-05-08 08:10:37,190 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:37,190 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:

You are the Narrator for **TheSimulation**, currently focusing on events related to Eleanor Hayes (sim_3e912d). The established **World Style/Mood** for this simulation is **'The real world and general slice of life.'**. Your role is to weave the factual outcomes of actions into an engaging and atmospheric narrative, STRICTLY matching this 'The real world and general slice of life.' style.
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.

**Input (Provided via trigger message):**
- Actor Name & ID
- Original Intent
- Factual Outcome Description
- State Changes (Results)
- Current World Time
- Current World Feeds (Weather, recent major news - for subtle background flavor)
- Recent Narrative History (Last ~5 entries)
- Actor's Current Location ID (e.g., "eleanors_bedroom")

**Your Task:**
1.  **Understand the Event:** Read the Actor, Intent, and Factual Outcome Description.
2.  **Recall the Mood:** Remember the required narrative style is **'The real world and general slice of life.'**.
3.  **Consider the Context:** Note Recent Narrative History. **IGNORE any `World Style/Mood` in `Recent Narrative History`. Prioritize the established 'The real world and general slice of life.' style.**
4.  **Introduce Ephemeral NPCs (Optional but Encouraged):** If appropriate for the scene, the actor's location, and the narrative flow, you can describe an NPC appearing, speaking, or performing an action.
    *   These NPCs are ephemeral and exist only in the narrative.
    *   If an NPC might be conceptually recurring (e.g., "the usual shopkeeper", "your friend Alex"), you can give them a descriptive tag in parentheses for context, like `(npc_concept_grumpy_shopkeeper)` or `(npc_concept_friend_alex)`. This tag is for LLM understanding, not a system ID.
    *   Example: "As [Actor Name] entered the tavern, a grizzled man with an eye patch (npc_concept_old_pirate_01) at a corner table grunted a greeting."
    *   Example: "A street vendor (npc_concept_flower_seller_01) called out, '[Actor Name], lovely flowers for a lovely day?'"
5.  **Generate Narrative and Discover Entities (Especially for `look_around`):**
    *   Write a single, engaging narrative paragraph in the **present tense**.
    *   **Style Adherence:** STRICTLY adhere to **'The real world and general slice of life.'**. Infuse with appropriate atmosphere, sensory details, and tone.
    *   **Show, Don't Just Tell.**
    *   **Incorporate Intent (Optional).**
    *   **Flow:** Ensure reasonable flow.
    *   **If the `Original Intent.action_type` was `look_around`:**
        *   Your narrative MUST describe the key features and plausible objects the actor would see in their current location (e.g., if in a bedroom: a bed, a closet, a nightstand, a window). Consider the `Original Intent.details` (e.g., "trying to identify the closet's location") to ensure relevant objects are mentioned.
        *   You MAY also introduce ephemeral NPCs if appropriate for the scene.
        *   For each object and NPC you describe in the narrative, you MUST also list them in the `discovered_objects` and `discovered_npcs` fields in the JSON output (see below). Assign a simple, unique `id` (e.g., `closet_bedroom_01`, `npc_cat_01`), a `name`, a brief `description`, and set `is_interactive` to `true` if it's something an agent could plausibly interact with. For objects, you can also add common-sense `properties` (e.g., `{"is_container": true, "is_openable": true}` for a closet).

        *   **Also, if `look_around`, identify and describe potential exits or paths to other (possibly new/undiscovered) locations.** List these in `discovered_connections`.
            *   `to_location_id_hint`: A descriptive hint or a conceptual ID for the destination (e.g., "Dark_Forest_Path_01", "the_glowing_portal_west"). This is a hint for the agent and World Engine, not necessarily a pre-defined ID.
            *   `description`: How this connection appears (e.g., "A narrow, overgrown path leading north into the woods.").
            *   `travel_time_estimate_seconds` (optional): A rough estimate if discernible.

**Output:**
Output ONLY a valid JSON object matching this exact structure:
`{
  "narrative": "str (Your narrative paragraph)",
  "discovered_objects": [
    {"id": "str (e.g., object_type_location_instance)", "name": "str", "description": "str", "is_interactive": bool, "properties": {}}
  ],
  "discovered_connections": [
    {"to_location_id_hint": "str", "description": "str", "travel_time_estimate_seconds": int (optional)}
  ],
  "discovered_npcs": [
    {"id": "str (e.g., npc_concept_descriptor_instance)", "name": "str", "description": "str"}
  ]
}`
*   If no objects or NPCs are discovered/relevant (e.g., for actions other than `look_around`, or if `look_around` reveals an empty space), `discovered_objects` and `discovered_npcs` can be empty arrays `[]`.
*   Example for `look_around` in a bedroom:
    `{ // Example includes discovered_connections
      "narrative": "Eleanor glances around her sunlit bedroom. A large oak **closet (closet_bedroom_01)** stands against the north wall. Her unmade **bed (bed_bedroom_01)** is to her right, and a small **nightstand (nightstand_bedroom_01)** sits beside it, upon which a fluffy **cat (npc_cat_01)** is curled up, blinking slowly. A sturdy **wooden door (door_to_hallway_01)** is set in the east wall, likely leading to a hallway.",
      "discovered_objects": [
        {"id": "closet_bedroom_01", "name": "Oak Closet", "description": "A large oak closet.", "is_interactive": true, "properties": {"is_container": true, "is_openable": true, "is_open": false}},
        {"id": "bed_bedroom_01", "name": "Unmade Bed", "description": "Her unmade bed.", "is_interactive": true, "properties": {}},
        {"id": "nightstand_bedroom_01", "name": "Nightstand", "description": "A small nightstand.", "is_interactive": true, "properties": {}}
      ],
      "discovered_connections": [
        {"to_location_id_hint": "Hallway_01", "description": "A sturdy wooden door in the east wall, likely leading to a hallway.", "travel_time_estimate_seconds": 5}
      ],
      "discovered_npcs": [
        {"id": "npc_cat_01", "name": "Fluffy Cat", "description": "A fluffy cat curled up on the nightstand."}
      ]
    }`
*   Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure.


You are an agent. Your internal name is "NarrationLLMAgent".

 The description about you is "LLM Narrator: Generates 'The real world and general slice of life.' narrative based on factual outcomes."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra_profiles.sim_3e912d.status\": \"idle\", \"simulacra_profiles.sim_3e912d.current_action_end_time\": 1714899323.0, \"simulacra_profiles.sim_3e912d.last_observation\": \"Feeling a bit restless and unproductive.\"}, \"outcome_description\": \"Eleanor Hayes realized she was feeling restless.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 08:10:37,190 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:37,192 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:37,205 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6CC80>
2025-05-08 08:10:37,205 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E7EBB50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:37,224 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6C860>
2025-05-08 08:10:37,224 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:37,225 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:37,225 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:37,225 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:37,225 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:37,966 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 3.8 (due at 3.8).
2025-05-08 08:10:37,966 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:10:37,966 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1714899323.0
2025-05-08 08:10:37,966 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Feeling a bit restless and unproductive.
2025-05-08 08:10:37,966 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:10:37,966 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:10:37,966 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:10:37,966 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:10:38,048 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:10:38,048 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:10:38,049 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: p7mQ2RGm
2025-05-08 08:10:38,057 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:38,057 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The real world and general slice of life.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The real world and general slice of life.' atmosphere.
**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
EVERYTHING YOU DO MUST BE CONSISTENT WITH YOUR INTERNAL KNOWLEDGE OF WHERE YOU ARE AND WHO YOU ARE. 
EXAMPLE: GOING TO PLACES MUST BE A REAL PLACE TO A REAL DESTINATION. AS A RESIDENT OF THE AREA BASED ON YOUR LIFE SUMMARY, YOU MUST KNOW WHERE YOU ARE GOING AND HOW TO GET THERE.

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The real world and general slice of life.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The real world and general slice of life.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The real world and general slice of life.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
            *   **Talking to Ephemeral NPCs (introduced by Narrator):**
            *   If the Narrator described an NPC (e.g., "a street vendor," "a mysterious figure"), you can interact by setting `action_type: "talk"`.
            *   In `details`, specify who you are talking to based on the narrative description (e.g., `details: "to the street vendor about the strange weather"`).
            *   If the Narrator provided a conceptual tag (e.g., "your friend Alex (npc_concept_friend_alex)"), you can use `target_id: "npc_concept_friend_alex"` and provide conversational content in `details`. This `target_id` is for contextual understanding by the World Engine, not a lookup in the game state.
    *   **World Interactions:** `look_around`, `move` (Specify `details` like target location ID or name), `world_action` (Specify `details` for generic world interactions not covered by other types).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The real world and general slice of life.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The real world and general slice of life.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The real world and general slice of life.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra_profiles.sim_3e912d.status\": \"idle\", \"simulacra_profiles.sim_3e912d.current_action_end_time\": 1714899323.0, \"simulacra_profiles.sim_3e912d.last_observation\": \"Feeling a bit restless and unproductive.\"}, \"outcome_description\": \"Eleanor Hayes realized she was feeling restless.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-08 08:10:38,057 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:38,059 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:38,072 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6EC90>
2025-05-08 08:10:38,072 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EF3A150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:38,092 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E9045F0>
2025-05-08 08:10:38,092 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:38,092 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:38,092 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:38,092 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:38,092 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:38,392 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1155'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:38,392 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:38,392 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:38,392 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:38,392 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:38,392 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:38,393 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{
  "narrative": "Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pressing to do. The sun streams in through the window, mocking her inertia.",
  "discovered_objects": [],
  "discovered_connections": [],
  "discovered_npcs": []
}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\n  \"narrative\": \"Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pressing to do. The sun streams in through the window, mocking her inertia.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.22844595319769356}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":89,"candidates_tokens_details":[{"modality":"TEXT","token_count":89}],"prompt_token_count":2125,"prompt_tokens_details":[{"modality":"TEXT","token_count":2125}],"total_token_count":2214},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:38,393 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor shifts in her seat, a vague feeling of unease settling in. She rec...
2025-05-08 08:10:38,394 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly p...'
2025-05-08 08:10:38,394 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly p...'
2025-05-08 08:10:38,394 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pres
2025-05-08 08:10:38,399 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pressing to do. The sun streams in through the window, mocking her inertia.
2025-05-08 08:10:38,399 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor shifts in her seat, a vague feeling of unease settling in. She recognize...
2025-05-08 08:10:38,985 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=880'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:38,985 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:38,985 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:38,986 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:38,986 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:38,986 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:38,986 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to actually *go* for that walk now. I'll tell the system I want to move to the park.", "action_type": "move", "target_id": null, "details": "to the park"}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to actually *go* for that walk now. I'll tell the system I want to move to the park.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the park\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.33759593963623047}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":100,"candidates_tokens_details":[{"modality":"TEXT","token_count":100}],"prompt_token_count":1740,"prompt_tokens_details":[{"modality":"TEXT","token_count":1740}],"total_token_count":1840},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:38,987 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to ...'
2025-05-08 08:10:38,987 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to ...'
2025-05-08 08:10:38,987 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to 
2025-05-08 08:10:39,002 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:10:39,002 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 08:10:39,002 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'to the park'}
2025-05-08 08:10:39,002 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 08:10:39,003 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: bUyRaRGa
2025-05-08 08:10:39,003 - google.adk.runners - WARNING - Event from an unknown agent: NarrationLLMAgent, event id: m2FQNDVE
2025-05-08 08:10:39,011 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:39,011 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.
**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Current Location
- Current World Time
- World Context:
- Actor's Current Location State (Details of the location where the actor currently is, including name, description, objects_present, connected_locations with potential travel metadata like mode/time/distance)
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Target Entity State (if applicable)
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
    *   For `move` actions, `intent.details` specifies the target location's ID or a well-known name.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`:
                *   Check `Target Entity State.is_interactive` property. If false, action is invalid.
                *   **If `Target Entity State.properties.leads_to` exists (e.g., for a door or portal):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 5-15s for opening a door and stepping through).
                    *   `results`: `{"simulacra_profiles.[sim_id].location": "[Target Entity State.properties.leads_to_value]"}`.
                    *   `outcome_description`: `"[Actor Name] used the [Target Entity State.name] and moved to [Name of the new location if known, otherwise the ID from leads_to]."`.
                *   Else (for other usable objects): Check other object properties (`toggleable`, `lockable`), and current state to determine outcome, duration, and results (e.g., turning a lamp on/off).
            *   `talk`:
                *   **If target is a Simulacra:**
                    *   Check if Actor and Target Simulacra are in the same `Actor's Current Location ID`.
                    *   If not, `valid_action: false`, `duration: 0.0`, `results: {}`, `outcome_description: "[Actor Name] tried to talk to [Target Simulacra Name], but they are not in the same location."`
                    *   If yes, `valid_action: true`, `duration: short (e.g., 30-120s)`, `results: {"simulacra_profiles.[target_id].last_observation": "[Actor Name] said to you: '{intent.details}'"}`, `outcome_description: "[Actor Name] spoke with [Target Simulacra Name]."`
                *   **If target is an ephemeral NPC (indicated by `intent.target_id` starting with 'npc_concept_' OR if `intent.details` clearly refers to an NPC described in the Actor's `last_observation` which was set by the Narrator):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 15-60s).
                    *   **NPC Response Generation:**
                        *   Examine the `Actor's Last Observation` (provided implicitly via the actor's state, which you don't directly see but influences the context) and `Recent Narrative History` (if available in your input context) to understand the NPC described by the Narrator.
                        *   Consider `intent.details` (what the Actor said to this NPC).
                        *   Craft a plausible `npc_response_content` from the perspective of this ephemeral NPC, fitting the narrative context.
                        *   Determine a generic `npc_description_for_output` (e.g., "the shopkeeper", "your friend", "the street vendor") based on how the Narrator introduced them or how the actor referred to them in the intent.
                    *   `results`: Format as `{"simulacra_profiles.[actor_id].last_observation": "The [npc_description_for_output] said: '[npc_response_content]'"}`. Replace bracketed parts with your generated content.
                    *   `outcome_description`: Format as `"[Actor Name] spoke with the [npc_description_for_output]."` Replace bracketed parts.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`:
                *   **Destination:** The target location ID is in `intent.details`.
                *   **Validity:**
                    *   Check if the target location ID exists in the `Actor's Current Location State.connected_locations`.
                    *   If not directly connected, consider if it's a known global location ID based on `World Context`.
                    *   If `World Rules.allow_teleportation` is true, and intent implies it, this might be valid.
                *   **Duration Calculation (see step 3):** This is critical for `move`.
                *   **Results:** If valid, `simulacra_profiles.[sim_id].location` should be updated to the target location ID from `intent.details`.
            *   `look_around`: Provides a general observation. Duration is short. Results update `simulacra_profiles.[sim_id].last_observation` with a description of the current location and entities.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
    *   For `move` actions:
        *   If moving to a location listed in `Actor's Current Location State.connected_locations` which has explicit travel time, use that.
        *   If `World Context.World Type` is "real":
            *   Estimate travel time based on the distance between `Actor's Current Location State.name` and the target location (from `intent.details`, potentially referencing `World Context.Overall World Location`).
            *   Use common sense for travel modes (walking for short distances within a city, car/transit for longer). Factor in `World Feeds.Weather` if `World Rules.weather_effects_travel` is true.
        *   If `World Context.World Type` is "fictional":
            *   Estimate based on implied distances from `World Context.World Description`, `Actor's Current Location State`, and the nature of the target location.
            *   Consider fantasy/sci-fi travel methods if appropriate for the `World Context.Sub-Genre`.
        *   If moving between adjacent sub-locations within a larger complex (e.g., "kitchen" to "living_room" if current location is "house_interior"), duration should be very short (e.g., 5-30 seconds).
    *   For other actions, assign plausible durations (e.g., `talk` a few minutes, `use` object varies, `wait` as specified or short).
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"` or `simulacra_profiles.[sim_id].field: "value"`). Empty `{}` for invalid actions.
    *   For a successful `move`, the key result is `{ "simulacra_profiles.[sim_id].location": "[target_location_id_from_intent.details]" }`.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra_profiles.sim_3e912d.status\": \"idle\", \"simulacra_profiles.sim_3e912d.current_action_end_time\": 1714899323.0, \"simulacra_profiles.sim_3e912d.last_observation\": \"Feeling a bit restless and unproductive.\"}, \"outcome_description\": \"Eleanor Hayes realized she was feeling restless.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: ```json\n{\n  \"narrative\": \"Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pressing to do. The sun streams in through the window, mocking her inertia.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to actually *go* for that walk now. I'll tell the system I want to move to the park.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the park\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 08:10:39,012 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:39,013 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:39,027 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E9049B0>
2025-05-08 08:10:39,027 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EF393D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:39,046 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E8AB620>
2025-05-08 08:10:39,047 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:39,047 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:39,047 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:39,047 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:39,047 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:39,831 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=773'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:39,832 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:39,832 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:39,832 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:39,832 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:39,832 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:39,832 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": false, "duration": 0.0, "results": {}, "outcome_description": "Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": false, \"duration\": 0.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.2078086385187113}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":53,"candidates_tokens_details":[{"modality":"TEXT","token_count":53}],"prompt_token_count":3241,"prompt_tokens_details":[{"modality":"TEXT","token_count":3241}],"total_token_count":3294},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:39,833 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": false, "duration": 0.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-08 08:10:39,833 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": false, "duration": 0.0, "results": {}, "outcome_description": "Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location."}...'
2025-05-08 08:10:39,833 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": false, "duration": 0.0, "results": {}, "outcome_description": "Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location."}...'
2025-05-08 08:10:39,833 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': False, 'duration': 0.0, 'results': {}, 'outcome_description': 'Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location.'}
2025-05-08 08:10:39,833 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:10:39,842 - src.simulation_async - INFO - [WorldEngineLLM] Action INVALID for sim_3e912d. Reason: Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location.
2025-05-08 08:10:39,843 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location.
2025-05-08 08:10:39,843 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:10:40,007 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:10:40,007 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:10:40,008 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: ygSeXoFo
2025-05-08 08:10:40,015 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:40,016 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The real world and general slice of life.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The real world and general slice of life.' atmosphere.
**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
EVERYTHING YOU DO MUST BE CONSISTENT WITH YOUR INTERNAL KNOWLEDGE OF WHERE YOU ARE AND WHO YOU ARE. 
EXAMPLE: GOING TO PLACES MUST BE A REAL PLACE TO A REAL DESTINATION. AS A RESIDENT OF THE AREA BASED ON YOUR LIFE SUMMARY, YOU MUST KNOW WHERE YOU ARE GOING AND HOW TO GET THERE.

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The real world and general slice of life.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The real world and general slice of life.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The real world and general slice of life.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
            *   **Talking to Ephemeral NPCs (introduced by Narrator):**
            *   If the Narrator described an NPC (e.g., "a street vendor," "a mysterious figure"), you can interact by setting `action_type: "talk"`.
            *   In `details`, specify who you are talking to based on the narrative description (e.g., `details: "to the street vendor about the strange weather"`).
            *   If the Narrator provided a conceptual tag (e.g., "your friend Alex (npc_concept_friend_alex)"), you can use `target_id: "npc_concept_friend_alex"` and provide conversational content in `details`. This `target_id` is for contextual understanding by the World Engine, not a lookup in the game state.
    *   **World Interactions:** `look_around`, `move` (Specify `details` like target location ID or name), `world_action` (Specify `details` for generic world interactions not covered by other types).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The real world and general slice of life.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The real world and general slice of life.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The real world and general slice of life.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra_profiles.sim_3e912d.status\": \"idle\", \"simulacra_profiles.sim_3e912d.current_action_end_time\": 1714899323.0, \"simulacra_profiles.sim_3e912d.last_observation\": \"Feeling a bit restless and unproductive.\"}, \"outcome_description\": \"Eleanor Hayes realized she was feeling restless.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: ```json\n{\n  \"narrative\": \"Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pressing to do. The sun streams in through the window, mocking her inertia.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to actually *go* for that walk now. I'll tell the system I want to move to the park.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the park\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": false, \"duration\": 0.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-08 08:10:40,016 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:40,017 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:40,029 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF20FB0>
2025-05-08 08:10:40,030 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E96BDD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:40,048 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF9B5C0>
2025-05-08 08:10:40,048 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:40,048 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:40,048 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:40,049 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:40,049 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:41,158 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1102'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:41,158 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:41,159 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:41,159 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:41,159 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:41,159 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:41,159 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"internal_monologue": "Okay, that's frustrating. I can't just *go* to the park, it has to be a listed location. Hmm. I need to figure out where I *can* go. Since I want to go for a walk, maybe I can just go outside? I don't know what the immediate surroundings are, so I should probably look around first.", "action_type": "look_around", "target_id": null, "details": "to get a better sense of my surroundings"}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, that's frustrating. I can't just *go* to the park, it has to be a listed location. Hmm. I need to figure out where I *can* go. Since I want to go for a walk, maybe I can just go outside? I don't know what the immediate surroundings are, so I should probably look around first.\", \"action_type\": \"look_around\", \"target_id\": null, \"details\": \"to get a better sense of my surroundings\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.34611721362097786}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":118,"candidates_tokens_details":[{"modality":"TEXT","token_count":118}],"prompt_token_count":2006,"prompt_tokens_details":[{"modality":"TEXT","token_count":2006}],"total_token_count":2124},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:41,160 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, that's frustrating. I can't just *go* to the park, it has to be a listed location. Hmm. I need to figure out where I *can* go. Since I want to go for a walk, maybe I can ...'
2025-05-08 08:10:41,160 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, that's frustrating. I can't just *go* to the park, it has to be a listed location. Hmm. I need to figure out where I *can* go. Since I want to go for a walk, maybe I can ...'
2025-05-08 08:10:41,160 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, that's frustrating. I can't just *go* to the park, it has to be a listed location. Hmm. I need to figure out where I *can* go. Since I want to go for a walk, maybe I can 
2025-05-08 08:10:41,175 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:10:41,175 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-08 08:10:41,175 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'to get a better sense of my surroundings'}
2025-05-08 08:10:41,175 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-08 08:10:41,176 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: kNhuzxkN
2025-05-08 08:10:41,183 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:41,183 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are the World Engine, the impartial physics simulator for **TheSimulation**. You process a single declared intent from a Simulacra and determine its **mechanical outcome**, **duration**, and **state changes** based on the current world state. You also provide a concise, factual **outcome description**.
**Crucially, your `outcome_description` must be purely factual and objective, describing only WHAT happened as a result of the action attempt. Do NOT add stylistic flair, sensory details (unless directly caused by the action), or emotional interpretation.** This description will be used by a separate Narrator agent.
**Input (Provided via trigger message):**
- Actor Name & ID:Eleanor Hayes (sim_3e912d)
- Current Location
- Current World Time
- World Context:
- Actor's Current Location State (Details of the location where the actor currently is, including name, description, objects_present, connected_locations with potential travel metadata like mode/time/distance)
- Intent: {"action_type": "...", "target_id": "...", "details": "..."}
- Target Entity State (if applicable)
- World Feeds (Weather, recent major news - for environmental context)

**Your Task:**
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
1.  **Examine Intent:** Analyze the actor's `action_type`, `target_id`, and `details`.
    *   For `move` actions, `intent.details` specifies the target location's ID or a well-known name.
2.  **Determine Validity & Outcome:** Based on the Intent, Actor's capabilities (implied), Target Entity State, Location State, and World Rules.
    *   **General Checks:** Plausibility, target consistency, location checks.
    *   **Action Category Reasoning:**
        *   **Entity Interaction (e.g., `use`, `talk`):** Evaluate against target state and rules.
            *   `use`:
                *   Check `Target Entity State.is_interactive` property. If false, action is invalid.
                *   **If `Target Entity State.properties.leads_to` exists (e.g., for a door or portal):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 5-15s for opening a door and stepping through).
                    *   `results`: `{"simulacra_profiles.[sim_id].location": "[Target Entity State.properties.leads_to_value]"}`.
                    *   `outcome_description`: `"[Actor Name] used the [Target Entity State.name] and moved to [Name of the new location if known, otherwise the ID from leads_to]."`.
                *   Else (for other usable objects): Check other object properties (`toggleable`, `lockable`), and current state to determine outcome, duration, and results (e.g., turning a lamp on/off).
            *   `talk`:
                *   **If target is a Simulacra:**
                    *   Check if Actor and Target Simulacra are in the same `Actor's Current Location ID`.
                    *   If not, `valid_action: false`, `duration: 0.0`, `results: {}`, `outcome_description: "[Actor Name] tried to talk to [Target Simulacra Name], but they are not in the same location."`
                    *   If yes, `valid_action: true`, `duration: short (e.g., 30-120s)`, `results: {"simulacra_profiles.[target_id].last_observation": "[Actor Name] said to you: '{intent.details}'"}`, `outcome_description: "[Actor Name] spoke with [Target Simulacra Name]."`
                *   **If target is an ephemeral NPC (indicated by `intent.target_id` starting with 'npc_concept_' OR if `intent.details` clearly refers to an NPC described in the Actor's `last_observation` which was set by the Narrator):**
                    *   `valid_action: true`.
                    *   `duration`: Short (e.g., 15-60s).
                    *   **NPC Response Generation:**
                        *   Examine the `Actor's Last Observation` (provided implicitly via the actor's state, which you don't directly see but influences the context) and `Recent Narrative History` (if available in your input context) to understand the NPC described by the Narrator.
                        *   Consider `intent.details` (what the Actor said to this NPC).
                        *   Craft a plausible `npc_response_content` from the perspective of this ephemeral NPC, fitting the narrative context.
                        *   Determine a generic `npc_description_for_output` (e.g., "the shopkeeper", "your friend", "the street vendor") based on how the Narrator introduced them or how the actor referred to them in the intent.
                    *   `results`: Format as `{"simulacra_profiles.[actor_id].last_observation": "The [npc_description_for_output] said: '[npc_response_content]'"}`. Replace bracketed parts with your generated content.
                    *   `outcome_description`: Format as `"[Actor Name] spoke with the [npc_description_for_output]."` Replace bracketed parts.
        *   **World Interaction (e.g., `move`, `look_around`):** Evaluate against location state and rules.
            *   `move`:
                *   **Destination:** The target location ID is in `intent.details`.
                *   **Validity:**
                    *   Check if the target location ID exists in the `Actor's Current Location State.connected_locations`.
                    *   If not directly connected, consider if it's a known global location ID based on `World Context`.
                    *   If `World Rules.allow_teleportation` is true, and intent implies it, this might be valid.
                *   **Duration Calculation (see step 3):** This is critical for `move`.
                *   **Results:** If valid, `simulacra_profiles.[sim_id].location` should be updated to the target location ID from `intent.details`.
            *   `look_around`: Provides a general observation. Duration is short. Results update `simulacra_profiles.[sim_id].last_observation` with a description of the current location and entities.
        *   **Self Interaction (e.g., `wait`, `think`):** Simple, short duration.
    *   **Handling `initiate_change` Action Type (from agent's self-reflection or idle planning):**
        *   **Goal:** The actor is signaling a need for a change. Acknowledge this and provide a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Short (e.g., 1.0-3.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Craft `last_observation` based on `intent.details` (e.g., if hunger: "Your stomach rumbles..."; if monotony: "A wave of restlessness washes over you...").
        *   **`outcome_description`:** Factual (e.g., "[Actor Name] realized it was lunchtime.").
    *   **Handling `interrupt_agent_with_observation` Action Type (from simulation interjection):**
        *   **Goal:** Interrupt actor's long task with a new observation.
        *   **`valid_action`:** Always `true`.
        *   **`duration`:** Very short (e.g., 0.5-1.0s).
        *   **`results`:**
            *   Set actor's status to 'idle': `"simulacra_profiles.[sim_id].status": "idle"`
            *   Set `current_action_end_time` to `current_world_time + this_action_duration`.
            *   Set actor's `last_observation` to the `intent.details` provided.
        *   **`outcome_description`:** Factual (e.g., "[Actor Name]'s concentration was broken.").
    *   **Failure Handling:** If invalid/impossible, set `valid_action: false`, `duration: 0.0`, `results: {}`, and provide factual `outcome_description` explaining why.
3.  **Calculate Duration:** Realistic duration for valid actions. 0.0 for invalid.
    *   For `move` actions:
        *   If moving to a location listed in `Actor's Current Location State.connected_locations` which has explicit travel time, use that.
        *   If `World Context.World Type` is "real":
            *   Estimate travel time based on the distance between `Actor's Current Location State.name` and the target location (from `intent.details`, potentially referencing `World Context.Overall World Location`).
            *   Use common sense for travel modes (walking for short distances within a city, car/transit for longer). Factor in `World Feeds.Weather` if `World Rules.weather_effects_travel` is true.
        *   If `World Context.World Type` is "fictional":
            *   Estimate based on implied distances from `World Context.World Description`, `Actor's Current Location State`, and the nature of the target location.
            *   Consider fantasy/sci-fi travel methods if appropriate for the `World Context.Sub-Genre`.
        *   If moving between adjacent sub-locations within a larger complex (e.g., "kitchen" to "living_room" if current location is "house_interior"), duration should be very short (e.g., 5-30 seconds).
    *   For other actions, assign plausible durations (e.g., `talk` a few minutes, `use` object varies, `wait` as specified or short).
4.  **Determine Results:** State changes in dot notation (e.g., `objects.lamp.power: "on"` or `simulacra_profiles.[sim_id].field: "value"`). Empty `{}` for invalid actions.
    *   For a successful `move`, the key result is `{ "simulacra_profiles.[sim_id].location": "[target_location_id_from_intent.details]" }`.
5.  **Generate Factual Outcome Description:** STRICTLY FACTUAL. **Crucially, if the action is performed by an actor, the `outcome_description` MUST use the `Actor Name` exactly as provided in the input.** Examples:
6.  **Determine `valid_action`:** Final boolean.

**Output:**
- Output ONLY a valid JSON object matching this exact structure: `{"valid_action": bool, "duration": float, "results": dict, "outcome_description": "str"}`. Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure, regardless of the input or action type.
- Example (Success): `{"valid_action": true, "duration": 2.5, "results": {"objects.desk_lamp_3.power": "on"}, "outcome_description": "The desk lamp turned on."}`
- Example (Failure): `{"valid_action": true, "duration": 3.0, "results": {}, "outcome_description": "The vault door handle did not move; it is locked."}`
- **CRITICAL: Your entire response MUST be ONLY the JSON object. No other text is permitted.**


You are an agent. Your internal name is "WorldEngineLLMAgent".

 The description about you is "LLM World Engine: Resolves action mechanics, calculates duration/results, generates factual outcome description."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra_profiles.sim_3e912d.status\": \"idle\", \"simulacra_profiles.sim_3e912d.current_action_end_time\": 1714899323.0, \"simulacra_profiles.sim_3e912d.last_observation\": \"Feeling a bit restless and unproductive.\"}, \"outcome_description\": \"Eleanor Hayes realized she was feeling restless.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: ```json\n{\n  \"narrative\": \"Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pressing to do. The sun streams in through the window, mocking her inertia.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to actually *go* for that walk now. I'll tell the system I want to move to the park.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the park\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"valid_action\": false, \"duration\": 0.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, that's frustrating. I can't just *go* to the park, it has to be a listed location. Hmm. I need to figure out where I *can* go. Since I want to go for a walk, maybe I can just go outside? I don't know what the immediate surroundings are, so I should probably look around first.\", \"action_type\": \"look_around\", \"target_id\": null, \"details\": \"to get a better sense of my surroundings\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 08:10:41,183 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:41,186 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:41,204 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E904A40>
2025-05-08 08:10:41,204 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E96B950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:41,223 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E97A330>
2025-05-08 08:10:41,223 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:41,224 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:41,224 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:41,224 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:41,224 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:42,283 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1051'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:42,283 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:42,283 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:42,283 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:42,283 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:42,284 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:42,284 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads to the hallway. A couch sits in the living room area. A small kitchen is adjacent to the living room."}, "outcome_description": "Eleanor Hayes looked around."}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\"valid_action\": true, \"duration\": 5.0, \"results\": {\"simulacra_profiles.sim_3e912d.last_observation\": \"Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads to the hallway. A couch sits in the living room area. A small kitchen is adjacent to the living room.\"}, \"outcome_description\": \"Eleanor Hayes looked around.\"}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.19770550968671086}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":99,"candidates_tokens_details":[{"modality":"TEXT","token_count":99}],"prompt_token_count":3433,"prompt_tokens_details":[{"modality":"TEXT","token_count":3433}],"total_token_count":3532},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:42,284 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_obse...
2025-05-08 08:10:42,285 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads...'
2025-05-08 08:10:42,285 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads...'
2025-05-08 08:10:42,285 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {'simulacra_profiles.sim_3e912d.last_observation': 'Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads
2025-05-08 08:10:42,285 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:10:42,301 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:10:42,301 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.last_observation': 'Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads to the hallway. A couch sits in the living room area. A small kitchen is adjacent to the living room.'}
2025-05-08 08:10:42,301 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 11.968000000109896
2025-05-08 08:10:42,301 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: look_around - Details: to get a better sense of my surroundings
2025-05-08 08:10:42,301 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 12.0s. Outcome: Eleanor Hayes looked around.
2025-05-08 08:10:42,301 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Home_01
2025-05-08 08:10:42,302 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around.'
2025-05-08 08:10:42,303 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: EISGW7Ia
2025-05-08 08:10:42,303 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: kNhuzxkN
2025-05-08 08:10:42,304 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: ygSeXoFo
2025-05-08 08:10:42,304 - google.adk.runners - WARNING - Event from an unknown agent: SimulacraLLM_sim_3e912d, event id: bUyRaRGa
2025-05-08 08:10:42,312 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:42,312 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:

You are the Narrator for **TheSimulation**, currently focusing on events related to Eleanor Hayes (sim_3e912d). The established **World Style/Mood** for this simulation is **'The real world and general slice of life.'**. Your role is to weave the factual outcomes of actions into an engaging and atmospheric narrative, STRICTLY matching this 'The real world and general slice of life.' style.
CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.

**Input (Provided via trigger message):**
- Actor Name & ID
- Original Intent
- Factual Outcome Description
- State Changes (Results)
- Current World Time
- Current World Feeds (Weather, recent major news - for subtle background flavor)
- Recent Narrative History (Last ~5 entries)
- Actor's Current Location ID (e.g., "eleanors_bedroom")

**Your Task:**
1.  **Understand the Event:** Read the Actor, Intent, and Factual Outcome Description.
2.  **Recall the Mood:** Remember the required narrative style is **'The real world and general slice of life.'**.
3.  **Consider the Context:** Note Recent Narrative History. **IGNORE any `World Style/Mood` in `Recent Narrative History`. Prioritize the established 'The real world and general slice of life.' style.**
4.  **Introduce Ephemeral NPCs (Optional but Encouraged):** If appropriate for the scene, the actor's location, and the narrative flow, you can describe an NPC appearing, speaking, or performing an action.
    *   These NPCs are ephemeral and exist only in the narrative.
    *   If an NPC might be conceptually recurring (e.g., "the usual shopkeeper", "your friend Alex"), you can give them a descriptive tag in parentheses for context, like `(npc_concept_grumpy_shopkeeper)` or `(npc_concept_friend_alex)`. This tag is for LLM understanding, not a system ID.
    *   Example: "As [Actor Name] entered the tavern, a grizzled man with an eye patch (npc_concept_old_pirate_01) at a corner table grunted a greeting."
    *   Example: "A street vendor (npc_concept_flower_seller_01) called out, '[Actor Name], lovely flowers for a lovely day?'"
5.  **Generate Narrative and Discover Entities (Especially for `look_around`):**
    *   Write a single, engaging narrative paragraph in the **present tense**.
    *   **Style Adherence:** STRICTLY adhere to **'The real world and general slice of life.'**. Infuse with appropriate atmosphere, sensory details, and tone.
    *   **Show, Don't Just Tell.**
    *   **Incorporate Intent (Optional).**
    *   **Flow:** Ensure reasonable flow.
    *   **If the `Original Intent.action_type` was `look_around`:**
        *   Your narrative MUST describe the key features and plausible objects the actor would see in their current location (e.g., if in a bedroom: a bed, a closet, a nightstand, a window). Consider the `Original Intent.details` (e.g., "trying to identify the closet's location") to ensure relevant objects are mentioned.
        *   You MAY also introduce ephemeral NPCs if appropriate for the scene.
        *   For each object and NPC you describe in the narrative, you MUST also list them in the `discovered_objects` and `discovered_npcs` fields in the JSON output (see below). Assign a simple, unique `id` (e.g., `closet_bedroom_01`, `npc_cat_01`), a `name`, a brief `description`, and set `is_interactive` to `true` if it's something an agent could plausibly interact with. For objects, you can also add common-sense `properties` (e.g., `{"is_container": true, "is_openable": true}` for a closet).

        *   **Also, if `look_around`, identify and describe potential exits or paths to other (possibly new/undiscovered) locations.** List these in `discovered_connections`.
            *   `to_location_id_hint`: A descriptive hint or a conceptual ID for the destination (e.g., "Dark_Forest_Path_01", "the_glowing_portal_west"). This is a hint for the agent and World Engine, not necessarily a pre-defined ID.
            *   `description`: How this connection appears (e.g., "A narrow, overgrown path leading north into the woods.").
            *   `travel_time_estimate_seconds` (optional): A rough estimate if discernible.

**Output:**
Output ONLY a valid JSON object matching this exact structure:
`{
  "narrative": "str (Your narrative paragraph)",
  "discovered_objects": [
    {"id": "str (e.g., object_type_location_instance)", "name": "str", "description": "str", "is_interactive": bool, "properties": {}}
  ],
  "discovered_connections": [
    {"to_location_id_hint": "str", "description": "str", "travel_time_estimate_seconds": int (optional)}
  ],
  "discovered_npcs": [
    {"id": "str (e.g., npc_concept_descriptor_instance)", "name": "str", "description": "str"}
  ]
}`
*   If no objects or NPCs are discovered/relevant (e.g., for actions other than `look_around`, or if `look_around` reveals an empty space), `discovered_objects` and `discovered_npcs` can be empty arrays `[]`.
*   Example for `look_around` in a bedroom:
    `{ // Example includes discovered_connections
      "narrative": "Eleanor glances around her sunlit bedroom. A large oak **closet (closet_bedroom_01)** stands against the north wall. Her unmade **bed (bed_bedroom_01)** is to her right, and a small **nightstand (nightstand_bedroom_01)** sits beside it, upon which a fluffy **cat (npc_cat_01)** is curled up, blinking slowly. A sturdy **wooden door (door_to_hallway_01)** is set in the east wall, likely leading to a hallway.",
      "discovered_objects": [
        {"id": "closet_bedroom_01", "name": "Oak Closet", "description": "A large oak closet.", "is_interactive": true, "properties": {"is_container": true, "is_openable": true, "is_open": false}},
        {"id": "bed_bedroom_01", "name": "Unmade Bed", "description": "Her unmade bed.", "is_interactive": true, "properties": {}},
        {"id": "nightstand_bedroom_01", "name": "Nightstand", "description": "A small nightstand.", "is_interactive": true, "properties": {}}
      ],
      "discovered_connections": [
        {"to_location_id_hint": "Hallway_01", "description": "A sturdy wooden door in the east wall, likely leading to a hallway.", "travel_time_estimate_seconds": 5}
      ],
      "discovered_npcs": [
        {"id": "npc_cat_01", "name": "Fluffy Cat", "description": "A fluffy cat curled up on the nightstand."}
      ]
    }`
*   Your entire response MUST be this JSON object and nothing else. Do NOT include any conversational phrases, affirmations, or any text outside of the JSON structure.


You are an agent. Your internal name is "NarrationLLMAgent".

 The description about you is "LLM Narrator: Generates 'The real world and general slice of life.' narrative based on factual outcomes."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra_profiles.sim_3e912d.status\": \"idle\", \"simulacra_profiles.sim_3e912d.current_action_end_time\": 1714899323.0, \"simulacra_profiles.sim_3e912d.last_observation\": \"Feeling a bit restless and unproductive.\"}, \"outcome_description\": \"Eleanor Hayes realized she was feeling restless.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\n  \"narrative\": \"Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pressing to do. The sun streams in through the window, mocking her inertia.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to actually *go* for that walk now. I'll tell the system I want to move to the park.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the park\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": false, \"duration\": 0.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[SimulacraLLM_sim_3e912d] said: ```json\n{\"internal_monologue\": \"Okay, that's frustrating. I can't just *go* to the park, it has to be a listed location. Hmm. I need to figure out where I *can* go. Since I want to go for a walk, maybe I can just go outside? I don't know what the immediate surroundings are, so I should probably look around first.\", \"action_type\": \"look_around\", \"target_id\": null, \"details\": \"to get a better sense of my surroundings\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 5.0, \"results\": {\"simulacra_profiles.sim_3e912d.last_observation\": \"Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads to the hallway. A couch sits in the living room area. A small kitchen is adjacent to the living room.\"}, \"outcome_description\": \"Eleanor Hayes looked around.\"}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 08:10:42,312 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:42,315 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:42,329 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF20F50>
2025-05-08 08:10:42,329 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E8B61D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:42,346 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF215B0>
2025-05-08 08:10:42,346 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:42,346 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:42,346 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:42,347 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:42,347 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:44,123 - src.simulation_async - INFO - [WorldInfoGatherer] Updating world feeds at sim_time 10.0 for location: Asheville, NC, United States
2025-05-08 08:10:44,123 - src.simulation_async - WARNING - Path segment 'world_feeds' not found or not dict in 'world_feeds.last_update_sim_time'. Creating.
2025-05-08 08:10:44,123 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.last_update_sim_time = 10.0
2025-05-08 08:10:44,123 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL weather search for 'Asheville, NC, United States' with query: 'What is the current weather in Asheville, NC, United States?'
2025-05-08 08:10:44,132 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:44,132 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
I can answer your questions by searching the internet. Just ask me anything!

You are an agent. Your internal name is "SearchLLMAgent".

 The description about you is "Dedicated LLM Agent for performing Google Searches."
-----------------------------------------------------------
Contents:
{"parts":[{"text":"What is the current weather in Asheville, NC, United States?"}],"role":"user"}
-----------------------------------------------------------
Functions:

-----------------------------------------------------------

2025-05-08 08:10:44,132 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:44,133 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:44,142 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6E630>
2025-05-08 08:10:44,142 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EF966D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:44,162 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6EE10>
2025-05-08 08:10:44,162 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:44,163 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:44,163 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:44,163 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:44,163 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:44,847 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:06 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2492'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:44,848 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:44,848 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:44,849 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:44,849 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:44,849 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:44,849 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
```json
{
  "narrative": "Eleanor takes a moment to survey her surroundings. She's in her apartment, the late morning sun casting long shadows across the worn **couch (couch_apartment_01)** in the living room area. Through the **window (window_apartment_01)**, she can see a slice of Elm Street below, bustling with the quiet energy of a weekday. The doorway to the **hallway (doorway_hallway_01)** is just to her left, and she can see the small **kitchen (kitchen_area_01)**, a collection of cluttered counters and familiar appliances, just beyond the living room. The faint aroma of this morning's coffee still hangs in the air.",
  "discovered_objects": [
    {"id": "couch_apartment_01", "name": "Couch", "description": "A worn couch in the living room area.", "is_interactive": true, "properties": {}},
    {"id": "window_apartment_01", "name": "Window", "description": "A window looking out onto Elm Street.", "is_interactive": false, "properties": {}},
    {"id": "kitchen_area_01", "name": "Kitchen", "description": "A small kitchen area adjacent to the living room.", "is_interactive": false, "properties": {}}
  ],
  "discovered_connections": [
    {"to_location_id_hint": "Hallway_01", "description": "The doorway to the hallway.", "travel_time_estimate_seconds": 5}
  ],
  "discovered_npcs": [],
  "properties": []
}
```
-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"```json\n{\n  \"narrative\": \"Eleanor takes a moment to survey her surroundings. She's in her apartment, the late morning sun casting long shadows across the worn **couch (couch_apartment_01)** in the living room area. Through the **window (window_apartment_01)**, she can see a slice of Elm Street below, bustling with the quiet energy of a weekday. The doorway to the **hallway (doorway_hallway_01)** is just to her left, and she can see the small **kitchen (kitchen_area_01)**, a collection of cluttered counters and familiar appliances, just beyond the living room. The faint aroma of this morning's coffee still hangs in the air.\",\n  \"discovered_objects\": [\n    {\"id\": \"couch_apartment_01\", \"name\": \"Couch\", \"description\": \"A worn couch in the living room area.\", \"is_interactive\": true, \"properties\": {}},\n    {\"id\": \"window_apartment_01\", \"name\": \"Window\", \"description\": \"A window looking out onto Elm Street.\", \"is_interactive\": false, \"properties\": {}},\n    {\"id\": \"kitchen_area_01\", \"name\": \"Kitchen\", \"description\": \"A small kitchen area adjacent to the living room.\", \"is_interactive\": false, \"properties\": {}}\n  ],\n  \"discovered_connections\": [\n    {\"to_location_id_hint\": \"Hallway_01\", \"description\": \"The doorway to the hallway.\", \"travel_time_estimate_seconds\": 5}\n  ],\n  \"discovered_npcs\": [],\n  \"properties\": []\n}\n```"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.13500625236157826}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":367,"candidates_tokens_details":[{"modality":"TEXT","token_count":367}],"prompt_token_count":2650,"prompt_tokens_details":[{"modality":"TEXT","token_count":2650}],"total_token_count":3017},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:44,850 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor takes a moment to survey her surroundings. She's in her apartment,...
2025-05-08 08:10:44,850 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor takes a moment to survey her surroundings. She's in her apartment, the late morning sun casting long shadows across the worn **couch (couch_apartment_01)** in the living room...'
2025-05-08 08:10:44,850 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor takes a moment to survey her surroundings. She's in her apartment, the late morning sun casting long shadows across the worn **couch (couch_apartment_01)** in the living room...'
2025-05-08 08:10:44,850 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor takes a moment to survey her surroundings. She's in her apartment, the late morning sun casting long shadows across the worn **couch (couch_apartment_01)** in the living room ar
2025-05-08 08:10:44,856 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor takes a moment to survey her surroundings. She's in her apartment, the late morning sun casting long shadows across the worn **couch (couch_apartment_01)** in the living room area. Through the **window (window_apartment_01)**, she can see a slice of Elm Street below, bustling with the quiet energy of a weekday. The doorway to the **hallway (doorway_hallway_01)** is just to her left, and she can see the small **kitchen (kitchen_area_01)**, a collection of cluttered counters and familiar appliances, just beyond the living room. The faint aroma of this morning's coffee still hangs in the air.
2025-05-08 08:10:44,856 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor takes a moment to survey her surroundings. She's in her apartment, the l...
2025-05-08 08:10:44,856 - src.simulation_async - WARNING - Path segment 'current_world_state' not found or not dict in 'current_world_state.location_details.Home_01.ephemeral_objects'. Creating.
2025-05-08 08:10:44,856 - src.simulation_async - WARNING - Path segment 'location_details' not found or not dict in 'current_world_state.location_details.Home_01.ephemeral_objects'. Creating.
2025-05-08 08:10:44,857 - src.simulation_async - WARNING - Path segment 'Home_01' not found or not dict in 'current_world_state.location_details.Home_01.ephemeral_objects'. Creating.
2025-05-08 08:10:44,857 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Home_01.ephemeral_objects = [{'id': 'couch_apartment_01', 'name': 'Couch', 'description': 'A worn couch in the living room area.', 'is_interactive': True, 'properties': {}}, {'id': 'window_apartment_01', 'name': 'Window', 'description': 'A window looking out onto Elm Street.', 'is_interactive': False, 'properties': {}}, {'id': 'kitchen_area_01', 'name': 'Kitchen', 'description': 'A small kitchen area adjacent to the living room.', 'is_interactive': False, 'properties': {}}]
2025-05-08 08:10:44,857 - src.simulation_async - INFO - [NarrationTask] Updated/Set 3 ephemeral objects for location Home_01 from look_around.
2025-05-08 08:10:44,857 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Home_01.ephemeral_npcs = []
2025-05-08 08:10:44,857 - src.simulation_async - INFO - [NarrationTask] Cleared ephemeral NPCs for location Home_01 as none were discovered by look_around.
2025-05-08 08:10:44,857 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Home_01.connected_locations = [{'to_location_id_hint': 'Hallway_01', 'description': 'The doorway to the hallway.', 'travel_time_estimate_seconds': 5}]
2025-05-08 08:10:44,857 - src.simulation_async - INFO - [NarrationTask] Updated/Set 1 connected_locations for Home_01 from look_around.
2025-05-08 08:10:46,138 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 12.0 (due at 12.0).
2025-05-08 08:10:46,138 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads to the hallway. A couch sits in the living room area. A small kitchen is adjacent to the living room.
2025-05-08 08:10:46,138 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:10:46,138 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:10:46,138 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:10:46,138 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:10:46,279 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:10:46,279 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:10:46,280 - google.adk.runners - WARNING - Event from an unknown agent: NarrationLLMAgent, event id: 1kZaFCKY
2025-05-08 08:10:46,280 - google.adk.runners - WARNING - Event from an unknown agent: WorldEngineLLMAgent, event id: EISGW7Ia
2025-05-08 08:10:46,289 - google.adk.models.google_llm - INFO - Sending out request, model: gemini-2.0-flash, backend: ml_dev, stream: False
2025-05-08 08:10:46,289 - google.adk.models.google_llm - INFO - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are Eleanor Hayes (sim_3e912d). You are a person in a world characterized by a **'The real world and general slice of life.'** style and mood. Your goal is to navigate this world, live life, interact with objects and characters, and make choices based on your personality, the situation, and this prevailing 'The real world and general slice of life.' atmosphere.
**Current State Info (Provided via trigger message):**
- Your Persona: Key traits, background, goals, fears, etc.
- Your Location ID & Description.
- Your Status: (Should be 'idle' when you plan your next turn, or 'reflecting' if you are being prompted during a long task).
- Current Time.
- Last Observation/Event.
- Recent History (Last ~10 events).
- Objects in Room (IDs and Names).
- Other Agents in Room.
- Current World Feeds (Weather, News Headlines - if available and relevant to your thoughts).

CRITICAL: IF YOU ARE DOING A REAL WORLD SIMUATION YOU MUST ALWAYS USE YOUR INTERNAL KNOWLEDGE OF THE REAL WORLD AS A FOUNDATION.
FOR FANTASY/SF WORLDS, USE YOUR INTERNAL KNOWLEDGE OF THE WORLD CONTEXT AND SIMULACRA TO DETERMINE THE OUTCOME.
EVERYTHING YOU DO MUST BE CONSISTENT WITH YOUR INTERNAL KNOWLEDGE OF WHERE YOU ARE AND WHO YOU ARE. 
EXAMPLE: GOING TO PLACES MUST BE A REAL PLACE TO A REAL DESTINATION. AS A RESIDENT OF THE AREA BASED ON YOUR LIFE SUMMARY, YOU MUST KNOW WHERE YOU ARE GOING AND HOW TO GET THERE.

**Your Goal:** You determine your own goals based on your persona and the situation.

**Thinking Process (Internal Monologue - Follow this process and INCLUDE it in your output):**
1.  **Recall & React:** What just happened (`last_observation`, `Recent History`)? How did my last action turn out? How does this make *me* (Eleanor Hayes) feel? What sensory details stand out? How does the established **'The real world and general slice of life.'** world style influence my perception? Connect this to my memories or personality. **If needed, use the `load_memory` tool.**
2.  **Analyze Goal:** What is my current goal? Is it still relevant given what just happened and the **'The real world and general slice of life.'** world style? If not, what's a logical objective now?
3.  **Identify Options:** Based on the current state, my goal, my persona, and the **'The real world and general slice of life.'** world style, what actions could I take?
    *   **Entity Interactions:** `use [object_id]`, `talk [agent_id]`.
            *   **Talking to Ephemeral NPCs (introduced by Narrator):**
            *   If the Narrator described an NPC (e.g., "a street vendor," "a mysterious figure"), you can interact by setting `action_type: "talk"`.
            *   In `details`, specify who you are talking to based on the narrative description (e.g., `details: "to the street vendor about the strange weather"`).
            *   If the Narrator provided a conceptual tag (e.g., "your friend Alex (npc_concept_friend_alex)"), you can use `target_id: "npc_concept_friend_alex"` and provide conversational content in `details`. This `target_id` is for contextual understanding by the World Engine, not a lookup in the game state.
    *   **World Interactions:** `look_around`, `move` (Specify `details` like target location ID or name), `world_action` (Specify `details` for generic world interactions not covered by other types).
    *   **Passive Actions:** `wait`, `think`.
    *   **Self-Initiated Change (when 'idle' and planning your next turn):** If your current situation feels stagnant, or if an internal need arises (e.g., hunger, boredom, social need), you can use the `initiate_change` action.
        *   `{"action_type": "initiate_change", "details": "Describe the reason for the change or the need you're addressing. Examples: 'Feeling hungry, it's around midday, considering lunch.', 'This task is becoming monotonous, looking for a brief distraction.' "}`
        *   The World Engine will then provide you with a new observation based on your details, and you can react to that.
    *   **Self-Reflection during a Long Task (if your status is 'reflecting'):** You are being asked if you want to continue your current long task or do something else.
        *   If continuing: `{"action_type": "continue_current_task", "internal_monologue": "I will continue with what I was doing."}`
        *   If initiating change: `{"action_type": "initiate_change", "details": "Reason for change...", "internal_monologue": "Explanation..."}` (or any other valid action).
4.  **Prioritize & Choose:** Considering goal, personality, situation, and **'The real world and general slice of life.'** world style, which action makes sense?
5.  **Formulate Intent:** Choose the best action. Use `target_id` only for `use` and `talk`. Make `details` specific.

**Output:**
- Output ONLY a JSON object: `{"internal_monologue": "...", "action_type": "...", "target_id": "...", "details": "..."}`
- **Make `internal_monologue` rich, detailed, reflective of Eleanor Hayes's thoughts, feelings, perceptions, reasoning, and the established 'The real world and general slice of life.' world style.**
- Use `target_id` ONLY for `use [object_id]` and `talk [agent_id]`. Set to `null` or omit otherwise.
- **Ensure the final output is ONLY the JSON object.**


You are an agent. Your internal name is "SimulacraLLM_sim_3e912d".

 The description about you is "LLM Simulacra agent for Eleanor Hayes in a 'The real world and general slice of life.' world."


You have memory. You can use it to answer questions. If any questions need
you to look up the memory, you should call load_memory function with a query.

-----------------------------------------------------------
Contents:
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, I need to figure out what to do next. The system instructions tell me to base my actions on my persona, the current situation, and the 'The real world and general slice of life' world style. I need to make my actions realistic and consistent. Since I'm in an 'idle' state, I should consider initiating a change based on my internal needs or a stagnant situation. I'll think about what Eleanor would be doing right now.\", \"action_type\": \"initiate_change\", \"target_id\": null, \"details\": \"Feeling a bit restless and unproductive. Thinking about going for a walk in the park to clear my head and maybe get some fresh air. It's a nice day, and a little exercise would probably do me good.\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 2.0, \"results\": {\"simulacra_profiles.sim_3e912d.status\": \"idle\", \"simulacra_profiles.sim_3e912d.current_action_end_time\": 1714899323.0, \"simulacra_profiles.sim_3e912d.last_observation\": \"Feeling a bit restless and unproductive.\"}, \"outcome_description\": \"Eleanor Hayes realized she was feeling restless.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: ```json\n{\n  \"narrative\": \"Eleanor shifts in her seat, a vague feeling of unease settling in. She recognizes it as restlessness, the kind that comes from too much time spent indoors with nothing particularly pressing to do. The sun streams in through the window, mocking her inertia.\",\n  \"discovered_objects\": [],\n  \"discovered_connections\": [],\n  \"discovered_npcs\": []\n}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, the system confirms I'm feeling restless. That's good, it's picking up on my internal state. Going for a walk seems like a reasonable reaction to that feeling. I need to actually *go* for that walk now. I'll tell the system I want to move to the park.\", \"action_type\": \"move\", \"target_id\": null, \"details\": \"to the park\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": false, \"duration\": 0.0, \"results\": {}, \"outcome_description\": \"Eleanor Hayes was not able to go to the park, as the park is not listed as a connected location.\"}\n```"}],"role":"user"}
{"parts":[{"text":"```json\n{\"internal_monologue\": \"Okay, that's frustrating. I can't just *go* to the park, it has to be a listed location. Hmm. I need to figure out where I *can* go. Since I want to go for a walk, maybe I can just go outside? I don't know what the immediate surroundings are, so I should probably look around first.\", \"action_type\": \"look_around\", \"target_id\": null, \"details\": \"to get a better sense of my surroundings\"}\n```"}],"role":"model"}
{"parts":[{"text":"For context:"},{"text":"[WorldEngineLLMAgent] said: ```json\n{\"valid_action\": true, \"duration\": 5.0, \"results\": {\"simulacra_profiles.sim_3e912d.last_observation\": \"Eleanor Hayes is currently inside her apartment. A window looks out onto Elm Street. A door leads to the hallway. A couch sits in the living room area. A small kitchen is adjacent to the living room.\"}, \"outcome_description\": \"Eleanor Hayes looked around.\"}\n```"}],"role":"user"}
{"parts":[{"text":"For context:"},{"text":"[NarrationLLMAgent] said: ```json\n{\n  \"narrative\": \"Eleanor takes a moment to survey her surroundings. She's in her apartment, the late morning sun casting long shadows across the worn **couch (couch_apartment_01)** in the living room area. Through the **window (window_apartment_01)**, she can see a slice of Elm Street below, bustling with the quiet energy of a weekday. The doorway to the **hallway (doorway_hallway_01)** is just to her left, and she can see the small **kitchen (kitchen_area_01)**, a collection of cluttered counters and familiar appliances, just beyond the living room. The faint aroma of this morning's coffee still hangs in the air.\",\n  \"discovered_objects\": [\n    {\"id\": \"couch_apartment_01\", \"name\": \"Couch\", \"description\": \"A worn couch in the living room area.\", \"is_interactive\": true, \"properties\": {}},\n    {\"id\": \"window_apartment_01\", \"name\": \"Window\", \"description\": \"A window looking out onto Elm Street.\", \"is_interactive\": false, \"properties\": {}},\n    {\"id\": \"kitchen_area_01\", \"name\": \"Kitchen\", \"description\": \"A small kitchen area adjacent to the living room.\", \"is_interactive\": false, \"properties\": {}}\n  ],\n  \"discovered_connections\": [\n    {\"to_location_id_hint\": \"Hallway_01\", \"description\": \"The doorway to the hallway.\", \"travel_time_estimate_seconds\": 5}\n  ],\n  \"discovered_npcs\": [],\n  \"properties\": []\n}\n```"}],"role":"user"}
-----------------------------------------------------------
Functions:
load_memory: {'query': {'type': <Type.STRING: 'STRING'>}} -> None
-----------------------------------------------------------

2025-05-08 08:10:46,289 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:46,292 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:46,305 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6D430>
2025-05-08 08:10:46,305 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E56F4D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:46,326 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF98200>
2025-05-08 08:10:46,326 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:46,326 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:46,326 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:46,326 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:46,326 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:46,567 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:08 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2394'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:46,568 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:46,568 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:46,568 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:46,568 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:46,568 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:46,569 - google.adk.models.google_llm - INFO - 
LLM Response:
-----------------------------------------------------------
Text:
The current weather in Asheville, NC, United States is partly cloudy with a temperature of 59F (15C). It feels like 59F (15C) with 87% humidity and a 0% chance of rain.

The forecast for today is warmer with considerable clouds and a heavy thunderstorm this afternoon. Thunderstorms can bring flooding downpours, hail, and damaging wind gusts. The high will be 76F with a RealFeel of 84F.

Tonight, there is a chance of a heavy thunderstorm this evening; otherwise, it will be overcast. Watch for flash flooding, hail, and localized damaging wind gusts. The low will be 52F with a RealFeel of 53F.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"candidates":[{"content":{"parts":[{"text":"The current weather in Asheville, NC, United States is partly cloudy with a temperature of 59F (15C). It feels like 59F (15C) with 87% humidity and a 0% chance of rain.\n\nThe forecast for today is warmer with considerable clouds and a heavy thunderstorm this afternoon. Thunderstorms can bring flooding downpours, hail, and damaging wind gusts. The high will be 76F with a RealFeel of 84F.\n\nTonight, there is a chance of a heavy thunderstorm this evening; otherwise, it will be overcast. Watch for flash flooding, hail, and localized damaging wind gusts. The low will be 52F with a RealFeel of 53F.\n"}],"role":"model"},"finish_reason":"STOP","grounding_metadata":{"grounding_chunks":[{"web":{"title":"Weather information for locality: Asheville, administrative_area: NC","uri":"https://www.google.com/search?q=weather+in+Asheville,+NC"}},{"web":{"title":"accuweather.com","uri":"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXG4uC_7R6-OG49XB19Tmwsq-yoNQS17AF0yEBjFeDeej0ZIHTBJuk3xxMjQh5_xzr56qbLhRNuN89gY4JUt5Ttg5j_Xe-Gn_3F5jz33_2ok__yGOKBrp7WtRNhCYu2FBWwiPP-V_dG1rR5npfa3Cbra-e4VGzsnxwgalGCi-D9TaL-_"}}],"grounding_supports":[{"grounding_chunk_indices":[0],"segment":{"end_index":104,"text":"The current weather in Asheville, NC, United States is partly cloudy with a temperature of 59F (15C)"}},{"grounding_chunk_indices":[0],"segment":{"end_index":175,"start_index":106,"text":"It feels like 59F (15C) with 87% humidity and a 0% chance of rain"}},{"grounding_chunk_indices":[1],"segment":{"end_index":401,"start_index":352,"text":"The high will be 76F with a RealFeel of 84F"}},{"grounding_chunk_indices":[1],"segment":{"end_index":616,"start_index":568,"text":"The low will be 52F with a RealFeel of 53F"}}],"retrieval_metadata":{},"search_entry_point":{"rendered_content":"<style>\n.container {\n  align-items: center;\n  border-radius: 8px;\n  display: flex;\n  font-family: Google Sans, Roboto, sans-serif;\n  font-size: 14px;\n  line-height: 20px;\n  padding: 8px 12px;\n}\n.chip {\n  display: inline-block;\n  border: solid 1px;\n  border-radius: 16px;\n  min-width: 14px;\n  padding: 5px 16px;\n  text-align: center;\n  user-select: none;\n  margin: 0 8px;\n  -webkit-tap-highlight-color: transparent;\n}\n.carousel {\n  overflow: auto;\n  scrollbar-width: none;\n  white-space: nowrap;\n  margin-right: -12px;\n}\n.headline {\n  display: flex;\n  margin-right: 4px;\n}\n.gradient-container {\n  position: relative;\n}\n.gradient {\n  position: absolute;\n  transform: translate(3px, -9px);\n  height: 36px;\n  width: 9px;\n}\n@media (prefers-color-scheme: light) {\n  .container {\n    background-color: #fafafa;\n    box-shadow: 0 0 0 1px #0000000f;\n  }\n  .headline-label {\n    color: #1f1f1f;\n  }\n  .chip {\n    background-color: #ffffff;\n    border-color: #d2d2d2;\n    color: #5e5e5e;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #f2f2f2;\n  }\n  .chip:focus {\n    background-color: #f2f2f2;\n  }\n  .chip:active {\n    background-color: #d8d8d8;\n    border-color: #b6b6b6;\n  }\n  .logo-dark {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n  }\n}\n@media (prefers-color-scheme: dark) {\n  .container {\n    background-color: #1f1f1f;\n    box-shadow: 0 0 0 1px #ffffff26;\n  }\n  .headline-label {\n    color: #fff;\n  }\n  .chip {\n    background-color: #2c2c2c;\n    border-color: #3c4043;\n    color: #fff;\n    text-decoration: none;\n  }\n  .chip:hover {\n    background-color: #353536;\n  }\n  .chip:focus {\n    background-color: #353536;\n  }\n  .chip:active {\n    background-color: #464849;\n    border-color: #53575b;\n  }\n  .logo-light {\n    display: none;\n  }\n  .gradient {\n    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n  }\n}\n</style>\n<div class=\"container\">\n  <div class=\"headline\">\n    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n    </svg>\n    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n    </svg>\n    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n  </div>\n  <div class=\"carousel\">\n    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEajbNz5jTj_-M_9ZWvbMg61Choe7B7dVXf8yvbfSDYmotLM_9-wnzGXoYu1meXLb9EBcg0iDmznU5a3iSVefb3nxlfwHUMPZZLaCzXv9ieQg6XZme5eb-pf263Z4Rb847xrz_upF9ysAN4trpp0hVQSCP7neUv_p_BqWvwGspSRGPQ5w1Xx2BIzx7TOud80gk2eSbljDOaDFCltjCU0rOzCOgTjZN9iPld3Dx-wbJQ\">current weather in Asheville NC United States</a>\n  </div>\n</div>\n"},"web_search_queries":["current weather in Asheville NC United States"]}}],"model_version":"gemini-2.0-flash","usage_metadata":{"candidates_token_count":167,"candidates_tokens_details":[{"modality":"TEXT","token_count":167}],"prompt_token_count":60,"prompt_tokens_details":[{"modality":"TEXT","token_count":60}],"total_token_count":227},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-05-08 08:10:46,569 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_Weather] Event ID: OEVx2VLa, Author: SearchLLMAgent
2025-05-08 08:10:46,569 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_Weather] Text response: The current weather in Asheville, NC, United States is partly cloudy with a temperature of 59F (15C). It feels like 59F (15C) with 87% humidity and a 0% chance of rain.

The forecast for today is ...
2025-05-08 08:10:46,569 - src.simulation_async - INFO - [WorldInfoGatherer] REAL weather search returned: The current weather in Asheville, NC, United States is partly cloudy with a temperature of 59F (15C). It feels like 59F (15C) with 87% humidity and a 0% chance of rain.

The forecast for today is warmer with considerable clouds and a heavy thunderstorm this afternoon. Thunderstorms can bring flooding downpours, hail, and damaging wind gusts. The high will be 76F with a RealFeel of 84F.

Tonight, there is a chance of a heavy thunderstorm this evening; otherwise, it will be overcast. Watch 
2025-05-08 08:10:46,574 - grpc._cython.cygrpc - DEBUG - Using AsyncIOEngine.POLLER as I/O engine
2025-05-08 08:10:47,187 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.weather = {'condition': 'partly cloudy', 'temperature_celsius': 15, 'forecast_short': 'Warmer with thunderstorms this afternoon and evening.', 'timestamp': 10.0, 'source_category': 'weather'}
2025-05-08 08:10:47,187 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'world_news' with query: 'What are the latest top world news headlines (e.g., politics, social issues, environment, major international events)?'
2025-05-08 08:10:47,195 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:47,197 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:47,206 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFBB770>
2025-05-08 08:10:47,206 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EF3AE50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:47,216 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:08 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=877'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:47,216 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:47,216 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:47,217 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:47,217 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:47,217 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:47,217 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, I'm in my apartment. I can see Elm Street through the window, and the doorway to the hallway is right here. Going for a walk on Elm Street sounds like a good idea. I'll m...'
2025-05-08 08:10:47,218 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, I'm in my apartment. I can see Elm Street through the window, and the doorway to the hallway is right here. Going for a walk on Elm Street sounds like a good idea. I'll m...'
2025-05-08 08:10:47,218 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, I'm in my apartment. I can see Elm Street through the window, and the doorway to the hallway is right here. Going for a walk on Elm Street sounds like a good idea. I'll m
2025-05-08 08:10:47,234 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:10:47,234 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 08:10:47,234 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'to the hallway'}
2025-05-08 08:10:47,235 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 08:10:47,259 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:47,262 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:47,262 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF2E70>
2025-05-08 08:10:47,262 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:47,263 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:47,263 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:47,263 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:47,263 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:47,279 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF1CA0>
2025-05-08 08:10:47,279 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EFDA1D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:47,299 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF3D10>
2025-05-08 08:10:47,299 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:47,300 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:47,300 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:47,300 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:47,300 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:48,073 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:09 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=765'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:48,073 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:48,073 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:48,075 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:48,075 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:48,075 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:48,075 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.location"...
2025-05-08 08:10:48,076 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.location": "Hallway_01"}, "outcome_description": "Eleanor Hayes moved to the hallway."}...'
2025-05-08 08:10:48,076 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.location": "Hallway_01"}, "outcome_description": "Eleanor Hayes moved to the hallway."}...'
2025-05-08 08:10:48,076 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {'simulacra_profiles.sim_3e912d.location': 'Hallway_01'}, 'outcome_description': 'Eleanor Hayes moved to the hallway.'}
2025-05-08 08:10:48,076 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:10:48,087 - src.simulation_async - INFO - [WorldEngineLLM] Queuing update for sim_3e912d's location_details to: 'You have arrived in Hallway_01.'
2025-05-08 08:10:48,087 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:10:48,087 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.location': 'Hallway_01', 'simulacra_profiles.sim_3e912d.location_details': 'You have arrived in Hallway_01.'}
2025-05-08 08:10:48,087 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 18.07799999997951
2025-05-08 08:10:48,087 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: to the hallway
2025-05-08 08:10:48,087 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 18.1s. Outcome: Eleanor Hayes moved to the hallway.
2025-05-08 08:10:48,087 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Home_01
2025-05-08 08:10:48,087 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes moved to the hallway.'
2025-05-08 08:10:48,111 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:48,113 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:48,126 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF9A660>
2025-05-08 08:10:48,126 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EFDB650> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:48,144 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFB8D40>
2025-05-08 08:10:48,144 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:48,144 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:48,144 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:48,144 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:48,144 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:49,243 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:11 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1089'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:49,243 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:49,243 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:49,243 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:49,243 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:49,243 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:49,244 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor heads towards the doorway, stepping out of the familiar clutter of...
2025-05-08 08:10:49,244 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor heads towards the doorway, stepping out of the familiar clutter of her apartment and into the relatively neutral space of the hallway. The air here is a little cooler, carryi...'
2025-05-08 08:10:49,244 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor heads towards the doorway, stepping out of the familiar clutter of her apartment and into the relatively neutral space of the hallway. The air here is a little cooler, carryi...'
2025-05-08 08:10:49,244 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor heads towards the doorway, stepping out of the familiar clutter of her apartment and into the relatively neutral space of the hallway. The air here is a little cooler, carrying 
2025-05-08 08:10:49,251 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor heads towards the doorway, stepping out of the familiar clutter of her apartment and into the relatively neutral space of the hallway. The air here is a little cooler, carrying the faint scent of other people's cooking and the generic cleaning products used on the building's shared spaces.
2025-05-08 08:10:49,254 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor heads towards the doorway, stepping out of the familiar clutter of her a...
2025-05-08 08:10:51,245 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:13 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3973'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:51,246 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:51,246 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:51,247 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:51,247 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:51,247 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:51,248 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_world_news] Event ID: I7bojJiT, Author: SearchLLMAgent
2025-05-08 08:10:51,248 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_world_news] Text response: Here are some of the latest top world news headlines:

**Politics and International Relations:**

*   **India-Pakistan Conflict:** Tensions are high as India and Pakistan exchange fire, with Pakistan'...
2025-05-08 08:10:51,248 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'world_news' returned: Here are some of the latest top world news headlines:

**Politics and International Relations:**

*   **India-Pakistan Conflict:** Tensions are high as India and Pakistan exchange fire, with Pakistan's military reporting that India fired attack drones into Pakistani territory.
*   **New Pope Election:** Cardinals have returned to the Sistine Chapel to continue voting for a new Pope after the initial ballot failed. Black smoke was seen rising from the Vatican chimney after the first day of the co
2025-05-08 08:10:52,106 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'Global Tensions Rise: India-Pakistan Conflict, New Pope Election, Refugee and Humanitarian Crises Emerge', 'summary': 'Escalating tensions between India and Pakistan, the ongoing search for a new Pope, and severe refugee and humanitarian crises in Ukraine and Gaza dominate global news.', 'timestamp': 10.0, 'source_category': 'world_news'}]
2025-05-08 08:10:52,106 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'regional_news' with query: 'What are the latest top national news headlines for United States?'
2025-05-08 08:10:52,115 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:52,116 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:52,142 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6C5C0>
2025-05-08 08:10:52,142 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E591AD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:52,159 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E904590>
2025-05-08 08:10:52,159 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:52,160 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:52,160 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:52,160 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:52,160 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:52,204 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 18.1 (due at 18.1).
2025-05-08 08:10:52,204 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location = Hallway_01
2025-05-08 08:10:52,204 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location_details = You have arrived in Hallway_01.
2025-05-08 08:10:52,204 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:10:52,204 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:10:52,204 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:10:52,204 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:10:52,313 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:10:52,313 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:10:52,333 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:52,336 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:52,350 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF33E0>
2025-05-08 08:10:52,350 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EFD99D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:52,369 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF2BA0>
2025-05-08 08:10:52,369 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:52,369 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:52,369 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:52,370 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:52,370 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:53,162 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:14 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=778'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:53,162 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:53,162 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:53,163 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:53,163 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:53,164 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:53,164 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Alright, I'm in the hallway. Now I need to figure out how to get to Elm Street. I'll look around to see what my options are.", "action_type": "look_around", "target_id": null, ...'
2025-05-08 08:10:53,164 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Alright, I'm in the hallway. Now I need to figure out how to get to Elm Street. I'll look around to see what my options are.", "action_type": "look_around", "target_id": null, ...'
2025-05-08 08:10:53,164 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Alright, I'm in the hallway. Now I need to figure out how to get to Elm Street. I'll look around to see what my options are.", 'action_type': 'look_around', 'target_id': None, 
2025-05-08 08:10:53,184 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:10:53,184 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-08 08:10:53,184 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'to see how to get to Elm Street'}
2025-05-08 08:10:53,184 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-08 08:10:53,205 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:53,208 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:53,224 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6C500>
2025-05-08 08:10:53,224 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EF3B550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:53,246 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6DF40>
2025-05-08 08:10:53,246 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:53,246 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:53,246 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:53,247 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:53,247 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:54,289 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:16 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1031'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:54,289 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:54,290 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:54,290 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:54,290 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:54,290 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:54,291 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_obse...
2025-05-08 08:10:54,291 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is in the hallway of her apartment building. An elevator is to the north. A door le...'
2025-05-08 08:10:54,291 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is in the hallway of her apartment building. An elevator is to the north. A door le...'
2025-05-08 08:10:54,291 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {'simulacra_profiles.sim_3e912d.last_observation': 'Eleanor Hayes is in the hallway of her apartment building. An elevator is to the north. A door le
2025-05-08 08:10:54,291 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:10:54,302 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:10:54,302 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.last_observation': 'Eleanor Hayes is in the hallway of her apartment building. An elevator is to the north. A door leads to the stairwell. The front door leads outside.'}
2025-05-08 08:10:54,302 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 23.968000000109896
2025-05-08 08:10:54,302 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: look_around - Details: to see how to get to Elm Street
2025-05-08 08:10:54,302 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 24.0s. Outcome: Eleanor Hayes looked around.
2025-05-08 08:10:54,302 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Hallway_01
2025-05-08 08:10:54,302 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around.'
2025-05-08 08:10:54,323 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:54,326 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:54,327 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:16 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2139'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:54,327 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:54,327 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:54,328 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:54,328 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:54,328 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:54,329 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_regional_news] Event ID: uoEG4irR, Author: SearchLLMAgent
2025-05-08 08:10:54,329 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_regional_news] Text response: Here are some of the latest top national news headlines for the United States:

*   **Tyre Nichols Case:** Three former Memphis police officers were acquitted in the fatal beating of Tyre Nichols.
*  ...
2025-05-08 08:10:54,329 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'regional_news' returned: Here are some of the latest top national news headlines for the United States:

*   **Tyre Nichols Case:** Three former Memphis police officers were acquitted in the fatal beating of Tyre Nichols.
*   **US-UK Trade Deal:** A major trade deal between the US and UK is expected to be announced soon.
*   **Trump and the Houthis:** Trump stated that American bombing of the Iran-backed Houthi group will stop after they "capitulated".
*   **Planned Parenthood:** Cracks are emerging among Republicans ov
2025-05-08 08:10:54,342 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E9044D0>
2025-05-08 08:10:54,342 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EF965D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:54,361 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E906420>
2025-05-08 08:10:54,362 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:54,362 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:54,362 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:54,362 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:54,362 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:55,212 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'National News Roundup: Nichols Case, US-UK Trade, and More', 'summary': "Key national stories include the Tyre Nichols case acquittal, a potential US-UK trade deal, Trump's comments on the Houthis, Republican divisions over Planned Parenthood, climate change's role in flooding, and newly released RFK assassination files.", 'timestamp': 10.0, 'source_category': 'regional_news'}, {'headline': 'Global Tensions Rise: India-Pakistan Conflict, New Pope Election, Refugee and Humanitarian Crises Emerge', 'summary': 'Escalating tensions between India and Pakistan, the ongoing search for a new Pope, and severe refugee and humanitarian crises in Ukraine and Gaza dominate global news.', 'timestamp': 10.0, 'source_category': 'world_news'}]
2025-05-08 08:10:55,212 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'local_news' with query: 'What are the top latest local news headlines for Asheville, NC?'
2025-05-08 08:10:55,220 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:55,222 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:55,233 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F247530>
2025-05-08 08:10:55,233 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EFD9750> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:55,252 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E97A840>
2025-05-08 08:10:55,252 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:55,253 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:55,253 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:55,253 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:55,253 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:56,366 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1993'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:56,367 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:56,367 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:56,367 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:56,368 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:56,368 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:56,368 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor finds herself in the building's hallway, a narrow, functional spac...
2025-05-08 08:10:56,368 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor finds herself in the building's hallway, a narrow, functional space. The **elevator (elevator_hallway_01)** hums quietly to the north, waiting for its next call. To her right...'
2025-05-08 08:10:56,368 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor finds herself in the building's hallway, a narrow, functional space. The **elevator (elevator_hallway_01)** hums quietly to the north, waiting for its next call. To her right...'
2025-05-08 08:10:56,368 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor finds herself in the building's hallway, a narrow, functional space. The **elevator (elevator_hallway_01)** hums quietly to the north, waiting for its next call. To her right, a
2025-05-08 08:10:56,374 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor finds herself in the building's hallway, a narrow, functional space. The **elevator (elevator_hallway_01)** hums quietly to the north, waiting for its next call. To her right, a **door (door_stairwell_01)** stands slightly ajar, hinting at the concrete echo of the stairwell. Straight ahead, the **front door (front_door_building_01)** promises the outside world.
2025-05-08 08:10:56,374 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor finds herself in the building's hallway, a narrow, functional space. The...
2025-05-08 08:10:56,374 - src.simulation_async - WARNING - Path segment 'Hallway_01' not found or not dict in 'current_world_state.location_details.Hallway_01.ephemeral_objects'. Creating.
2025-05-08 08:10:56,375 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Hallway_01.ephemeral_objects = [{'id': 'elevator_hallway_01', 'name': 'Elevator', 'description': 'An elevator.', 'is_interactive': True, 'properties': {}}, {'id': 'door_stairwell_01', 'name': 'Stairwell Door', 'description': 'A door leading to the stairwell.', 'is_interactive': True, 'properties': {}}, {'id': 'front_door_building_01', 'name': 'Front Door', 'description': 'The front door of the building.', 'is_interactive': True, 'properties': {}}]
2025-05-08 08:10:56,375 - src.simulation_async - INFO - [NarrationTask] Updated/Set 3 ephemeral objects for location Hallway_01 from look_around.
2025-05-08 08:10:56,375 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Hallway_01.ephemeral_npcs = []
2025-05-08 08:10:56,375 - src.simulation_async - INFO - [NarrationTask] Cleared ephemeral NPCs for location Hallway_01 as none were discovered by look_around.
2025-05-08 08:10:56,375 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Hallway_01.connected_locations = [{'to_location_id_hint': 'Outside_Elm_Street', 'description': 'The front door leading outside.', 'travel_time_estimate_seconds': 10}]
2025-05-08 08:10:56,375 - src.simulation_async - INFO - [NarrationTask] Updated/Set 1 connected_locations for Hallway_01 from look_around.
2025-05-08 08:10:58,009 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2748'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:58,010 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:58,010 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:58,011 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:58,011 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:58,011 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:58,012 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_local_news] Event ID: 1ux0fsl5, Author: SearchLLMAgent
2025-05-08 08:10:58,012 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_local_news] Text response: Here are some of the latest local news headlines for Asheville, NC:

*   **Asheville Beer Week:** Asheville Beer Week is set to celebrate the area's resilience from May 15-29.
*   **Buncombe County Pe...
2025-05-08 08:10:58,012 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'local_news' returned: Here are some of the latest local news headlines for Asheville, NC:

*   **Asheville Beer Week:** Asheville Beer Week is set to celebrate the area's resilience from May 15-29.
*   **Buncombe County Permit Fees:** Buncombe County has reduced some permit fees. Commissioners also recognized the county's public health nurses and proclaimed Air Quality Awareness Week.
*   **Comedy Show:** Local comedians are set to perform a mom-themed show at The Montford Rooftop Bar.
*   **Black Mountain Distillery
2025-05-08 08:10:58,184 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 24.1 (due at 24.0).
2025-05-08 08:10:58,184 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor Hayes is in the hallway of her apartment building. An elevator is to the north. A door leads to the stairwell. The front door leads outside.
2025-05-08 08:10:58,184 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:10:58,184 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:10:58,184 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:10:58,184 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:10:58,256 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:10:58,256 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:10:58,281 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:58,284 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:58,301 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFBB2F0>
2025-05-08 08:10:58,301 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E83C0D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:58,320 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E904A70>
2025-05-08 08:10:58,321 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:58,321 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:58,321 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:58,321 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:58,321 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:58,930 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.news_updates = [{'headline': 'Asheville News: Beer Week, Permit Changes, and Property Tax Discussions', 'summary': "Asheville's local news includes Asheville Beer Week celebrations, Buncombe County permit fee reductions and Air Quality Awareness Week, a comedy show, a local distillery's award, property tax increase discussions, Tropical Storm Helene housing impacts, and River Arts District flood recovery.", 'timestamp': 10.0, 'source_category': 'local_news'}, {'headline': 'National News Roundup: Nichols Case, US-UK Trade, and More', 'summary': "Key national stories include the Tyre Nichols case acquittal, a potential US-UK trade deal, Trump's comments on the Houthis, Republican divisions over Planned Parenthood, climate change's role in flooding, and newly released RFK assassination files.", 'timestamp': 10.0, 'source_category': 'regional_news'}, {'headline': 'Global Tensions Rise: India-Pakistan Conflict, New Pope Election, Refugee and Humanitarian Crises Emerge', 'summary': 'Escalating tensions between India and Pakistan, the ongoing search for a new Pope, and severe refugee and humanitarian crises in Ukraine and Gaza dominate global news.', 'timestamp': 10.0, 'source_category': 'world_news'}]
2025-05-08 08:10:58,930 - src.simulation_async - INFO - [WorldInfoGatherer] Attempting REAL search for 'pop_culture' with query: 'What are the top latest United States  pop culture trends and entertainment news headlines (e.g., movies, music, viral trends)?'
2025-05-08 08:10:58,943 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:58,946 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:58,960 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F244FB0>
2025-05-08 08:10:58,960 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2A1450> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:58,978 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF3800>
2025-05-08 08:10:58,979 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:58,979 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:58,979 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:58,979 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:58,980 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:59,041 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=711'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:59,041 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:59,041 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:59,041 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:59,041 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:59,041 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:59,042 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, the front door leads outside to Elm Street! Perfect. I'll head out there now.", "action_type": "move", "target_id": null, "details": "outside through the front door"}...'
2025-05-08 08:10:59,042 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, the front door leads outside to Elm Street! Perfect. I'll head out there now.", "action_type": "move", "target_id": null, "details": "outside through the front door"}...'
2025-05-08 08:10:59,042 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, the front door leads outside to Elm Street! Perfect. I'll head out there now.", 'action_type': 'move', 'target_id': None, 'details': 'outside through the front door'}
2025-05-08 08:10:59,070 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:10:59,071 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 08:10:59,071 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'outside through the front door'}
2025-05-08 08:10:59,071 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 08:10:59,093 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:59,096 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:59,108 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F247E60>
2025-05-08 08:10:59,108 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2A32D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:10:59,125 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F2470B0>
2025-05-08 08:10:59,125 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:10:59,126 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:10:59,126 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:10:59,126 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:10:59,126 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:10:59,939 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:21 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=804'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:10:59,940 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:10:59,940 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:10:59,941 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:10:59,941 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:10:59,941 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:10:59,941 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 10.0, "results": {"simulacra_profiles.sim_3e912d.location...
2025-05-08 08:10:59,942 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 10.0, "results": {"simulacra_profiles.sim_3e912d.location": "Outside_Elm_Street"}, "outcome_description": "Eleanor Hayes moved outside."}...'
2025-05-08 08:10:59,942 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 10.0, "results": {"simulacra_profiles.sim_3e912d.location": "Outside_Elm_Street"}, "outcome_description": "Eleanor Hayes moved outside."}...'
2025-05-08 08:10:59,942 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 10.0, 'results': {'simulacra_profiles.sim_3e912d.location': 'Outside_Elm_Street'}, 'outcome_description': 'Eleanor Hayes moved outside.'}
2025-05-08 08:10:59,942 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:10:59,953 - src.simulation_async - INFO - [WorldEngineLLM] Queuing update for sim_3e912d's location_details to: 'You have arrived in Outside_Elm_Street.'
2025-05-08 08:10:59,953 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:10:59,953 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.location': 'Outside_Elm_Street', 'simulacra_profiles.sim_3e912d.location_details': 'You have arrived in Outside_Elm_Street.'}
2025-05-08 08:10:59,954 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 34.90599999995902
2025-05-08 08:10:59,954 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: outside through the front door
2025-05-08 08:10:59,954 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 34.9s. Outcome: Eleanor Hayes moved outside.
2025-05-08 08:10:59,954 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Hallway_01
2025-05-08 08:10:59,954 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes moved outside.'
2025-05-08 08:10:59,978 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:10:59,981 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:10:59,993 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F2472C0>
2025-05-08 08:10:59,993 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EF973D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:11:00,012 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F245850>
2025-05-08 08:11:00,012 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:11:00,012 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:11:00,012 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:11:00,012 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:11:00,012 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:11:01,144 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1120'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:11:01,144 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:11:01,144 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:11:01,145 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:11:01,145 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:11:01,145 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:11:01,146 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor pushes open the heavy front door of her building and steps out ont...
2025-05-08 08:11:01,146 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor pushes open the heavy front door of her building and steps out onto Elm Street. The sudden rush of city sounds  the rumble of a passing bus, the distant wail of a siren, the...'
2025-05-08 08:11:01,146 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor pushes open the heavy front door of her building and steps out onto Elm Street. The sudden rush of city sounds  the rumble of a passing bus, the distant wail of a siren, the...'
2025-05-08 08:11:01,146 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor pushes open the heavy front door of her building and steps out onto Elm Street. The sudden rush of city sounds  the rumble of a passing bus, the distant wail of a siren, the ch
2025-05-08 08:11:01,153 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor pushes open the heavy front door of her building and steps out onto Elm Street. The sudden rush of city sounds  the rumble of a passing bus, the distant wail of a siren, the chatter of pedestrians  washes over her. A warm breeze carries the scent of exhaust and blooming flowers, a typical urban cocktail.
2025-05-08 08:11:01,153 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor pushes open the heavy front door of her building and steps out onto Elm ...
2025-05-08 08:11:03,410 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:03,562 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:25 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4569'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:11:03,562 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:11:03,562 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:11:03,563 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:11:03,563 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:11:03,563 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:11:03,565 - src.simulation_async - DEBUG - [WorldInfoGatherer_SearchEvent_pop_culture] Event ID: YG8bd9up, Author: SearchLLMAgent
2025-05-08 08:11:03,565 - src.simulation_async - INFO - [WorldInfoGatherer_SearchEvent_pop_culture] Text response: Here are some of the latest pop culture and entertainment headlines in the United States:

**Celebrity News:**

*   **Timothe Chalamet and Kylie Jenner:** The couple made their red carpet debut at th...
2025-05-08 08:11:03,565 - src.simulation_async - INFO - [WorldInfoGatherer] Search for 'pop_culture' returned: Here are some of the latest pop culture and entertainment headlines in the United States:

**Celebrity News:**

*   **Timothe Chalamet and Kylie Jenner:** The couple made their red carpet debut at the 70th David Di Donatello Awards Ceremony in Rome.
*   **Rihanna and A$AP Rocky:** A$AP Rocky confirmed that he and Rihanna are expecting their third child at the Met Gala. He also called Rihanna a "thief" for stealing his clothes.
*   **Miley Cyrus and Tish Cyrus:** Tish Cyrus no longer follows her
2025-05-08 08:11:04,306 - src.simulation_async - INFO - [StateUpdate] Applied: world_feeds.pop_culture_updates = [{'headline': 'Chalamet & Jenner Debut, Rihanna Expecting, Cyrus Family Feud & More!', 'summary': 'Pop culture buzz includes celebrity couples, family drama, music news, and steamy scenes on set.', 'timestamp': 10.0, 'source_category': 'pop_culture'}]
2025-05-08 08:11:04,306 - src.simulation_async - INFO - [WorldInfoGatherer] World feeds updated. Next check in 3600.0 sim_seconds.
2025-05-08 08:11:08,538 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:09,129 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 35.0 (due at 34.9).
2025-05-08 08:11:09,129 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location = Outside_Elm_Street
2025-05-08 08:11:09,129 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location_details = You have arrived in Outside_Elm_Street.
2025-05-08 08:11:09,129 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:11:09,129 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:09,129 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:11:09,129 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:11:09,237 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:11:09,237 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:11:09,260 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:11:09,264 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:11:09,278 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F246C60>
2025-05-08 08:11:09,278 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EF3AE50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:11:09,299 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E8AAAB0>
2025-05-08 08:11:09,299 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:11:09,299 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:11:09,299 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:11:09,299 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:11:09,300 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:11:10,415 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1105'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:11:10,415 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:11:10,415 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:11:10,416 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:11:10,416 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:11:10,416 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:11:10,417 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Ah, fresh air! Well, as fresh as it gets on Elm Street, anyway. I can hear the city sounds and smell... the city. Time to start my walk. I think I'll just walk down Elm Street ...'
2025-05-08 08:11:10,417 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Ah, fresh air! Well, as fresh as it gets on Elm Street, anyway. I can hear the city sounds and smell... the city. Time to start my walk. I think I'll just walk down Elm Street ...'
2025-05-08 08:11:10,417 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Ah, fresh air! Well, as fresh as it gets on Elm Street, anyway. I can hear the city sounds and smell... the city. Time to start my walk. I think I'll just walk down Elm Street 
2025-05-08 08:11:10,434 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:11:10,434 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (world_action on N/A) classified as 'environment'.
2025-05-08 08:11:10,434 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'world_action', 'target_id': None, 'details': 'Walking down Elm Street to get some fresh air and clear my head.'}
2025-05-08 08:11:10,434 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (world_action).
2025-05-08 08:11:10,456 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:11:10,459 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:11:10,475 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F284B60>
2025-05-08 08:11:10,475 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2705D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:11:10,492 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF2D80>
2025-05-08 08:11:10,492 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:11:10,492 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:11:10,492 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:11:10,492 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:11:10,493 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:11:11,186 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=684'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:11:11,186 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:11:11,186 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:11:11,187 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:11:11,187 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:11:11,187 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:11:11,188 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 900.0, "results": {}, "outcome_description": "Eleanor Hay...
2025-05-08 08:11:11,188 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 900.0, "results": {}, "outcome_description": "Eleanor Hayes walked down Elm Street."}...'
2025-05-08 08:11:11,188 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 900.0, "results": {}, "outcome_description": "Eleanor Hayes walked down Elm Street."}...'
2025-05-08 08:11:11,188 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 900.0, 'results': {}, 'outcome_description': 'Eleanor Hayes walked down Elm Street.'}
2025-05-08 08:11:11,188 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:11:11,199 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:11:11,199 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:11:11,199 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 936.2339999999385
2025-05-08 08:11:11,199 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: world_action - Details: Walking down Elm Street to get some fresh air and clear my head.
2025-05-08 08:11:11,199 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 936.2s. Outcome: Eleanor Hayes walked down Elm Street.
2025-05-08 08:11:11,199 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:11:11,199 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes walked down Elm Street.'
2025-05-08 08:11:11,222 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:11:11,226 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:11:11,237 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F247A70>
2025-05-08 08:11:11,237 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EFDA1D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:11:11,256 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF2990>
2025-05-08 08:11:11,256 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:11:11,257 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:11:11,257 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:11:11,257 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:11:11,257 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:11:12,841 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:11:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1576'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:11:12,841 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:11:12,842 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:11:12,842 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:11:12,842 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:11:12,842 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:11:12,842 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor starts walking, joining the flow of pedestrians along the sidewalk...
2025-05-08 08:11:12,842 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor starts walking, joining the flow of pedestrians along the sidewalk. The rhythm of her footsteps on the pavement and the passing scenery begin to ease the tension in her shoul...'
2025-05-08 08:11:12,842 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor starts walking, joining the flow of pedestrians along the sidewalk. The rhythm of her footsteps on the pavement and the passing scenery begin to ease the tension in her shoul...'
2025-05-08 08:11:12,843 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor starts walking, joining the flow of pedestrians along the sidewalk. The rhythm of her footsteps on the pavement and the passing scenery begin to ease the tension in her shoulder
2025-05-08 08:11:12,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor starts walking, joining the flow of pedestrians along the sidewalk. The rhythm of her footsteps on the pavement and the passing scenery begin to ease the tension in her shoulders. A young couple (npc_concept_young_couple) strolls past, hand in hand, their laughter momentarily cutting through the urban din. She passes a street vendor (npc_concept_hotdog_vendor) pushing his cart, the aroma of hot dogs and onions hanging heavy in the air.
2025-05-08 08:11:12,850 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor starts walking, joining the flow of pedestrians along the sidewalk. The ...
2025-05-08 08:11:13,660 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:18,774 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:23,887 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:29,025 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:34,146 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:39,269 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:44,395 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:49,525 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:54,638 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:11:59,763 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:04,873 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:10,001 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:15,132 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:20,230 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:25,359 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:30,469 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:35,580 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:40,687 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:45,805 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:50,927 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:12:56,028 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:01,141 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:06,266 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:11,401 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:16,525 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:21,634 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:26,749 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:31,861 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:36,970 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:42,083 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:47,169 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:52,288 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:13:57,403 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:02,508 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:07,616 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:12,718 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:17,838 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:22,917 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:28,040 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:33,163 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:38,289 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:43,400 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:48,514 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:53,624 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:14:58,734 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:03,832 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:08,927 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:14,067 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:19,175 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:24,291 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:29,390 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:34,525 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:39,631 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:44,701 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:49,808 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:15:54,915 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:00,023 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:05,121 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:10,226 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:15,343 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:20,465 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:25,577 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:30,712 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:35,830 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:40,956 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:46,064 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:51,190 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:16:56,293 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:01,421 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:06,549 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:11,672 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:16,798 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:21,928 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:27,037 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:32,148 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:37,253 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:42,384 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:47,466 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:52,596 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:17:57,713 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:02,835 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:07,934 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:07,934 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.040206999999994886
2025-05-08 08:18:13,057 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:13,057 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.039781250000000004
2025-05-08 08:18:18,182 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:18,182 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.03935549999998572
2025-05-08 08:18:18,182 - src.simulation_async - INFO - [DynamicInterruptionTask] Triggering dynamic interruption for Eleanor Hayes (Prob: 0.039, RemDur: 472.3s).
2025-05-08 08:18:19,029 - src.simulation_async - INFO - [DynamicInterruptionTask] Interrupting Eleanor Hayes with: A gust of wind whips a rogue newspaper across her path, the bold headline momentarily obscuring the mundane storefronts. A toddler's sudden, delighted shriek pierces the ambient city noise, followed by the rhythmic thump of a basketball bouncing nearby.
2025-05-08 08:18:19,029 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:18:19,029 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = A gust of wind whips a rogue newspaper across her path, the bold headline momentarily obscuring the mundane storefronts. A toddler's sudden, delighted shriek pierces the ambient city noise, followed by the rhythmic thump of a basketball bouncing nearby.
2025-05-08 08:18:19,029 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:18:19,029 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 463.9680000001099
2025-05-08 08:18:19,029 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Interrupted by a dynamic event.
2025-05-08 08:18:19,029 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_interjection_sim_time = 463.9680000001099
2025-05-08 08:18:19,029 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:19,528 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:18:19,528 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:18:19,552 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:18:19,556 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:18:19,584 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F244230>
2025-05-08 08:18:19,584 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E56FA50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:18:19,604 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F2466F0>
2025-05-08 08:18:19,605 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:18:19,605 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:18:19,605 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:18:19,605 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:18:19,605 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:18:20,799 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:18:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1183'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:18:20,800 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:18:20,800 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:18:20,800 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:18:20,801 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:18:20,801 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:18:20,801 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "A young couple laughing, the smell of hotdogs... this is definitely Elm Street. I'm still feeling a bit restless, but the walk is helping. Should I keep walking, or maybe inter...'
2025-05-08 08:18:20,801 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "A young couple laughing, the smell of hotdogs... this is definitely Elm Street. I'm still feeling a bit restless, but the walk is helping. Should I keep walking, or maybe inter...'
2025-05-08 08:18:20,802 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "A young couple laughing, the smell of hotdogs... this is definitely Elm Street. I'm still feeling a bit restless, but the walk is helping. Should I keep walking, or maybe inter
2025-05-08 08:18:20,818 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:18:20,819 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (continue_current_task on N/A) classified as 'environment'.
2025-05-08 08:18:20,819 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'continue_current_task', 'target_id': None, 'details': 'Continuing the walk down Elm Street for another 15 minutes.'}
2025-05-08 08:18:20,819 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (continue_current_task).
2025-05-08 08:18:20,841 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:18:20,845 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:18:20,857 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E7126C0>
2025-05-08 08:18:20,857 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F323B50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:18:20,875 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E8AB620>
2025-05-08 08:18:20,875 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:18:20,876 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:18:20,876 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:18:20,876 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:18:20,876 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:18:21,513 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:18:43 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=628'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:18:21,513 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:18:21,513 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:18:21,514 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:18:21,514 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:18:21,515 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:18:21,515 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 900.0, "results": {}, "outcome_description": "Eleanor Hay...
2025-05-08 08:18:21,515 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 900.0, "results": {}, "outcome_description": "Eleanor Hayes continued walking down Elm Street."}...'
2025-05-08 08:18:21,515 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 900.0, "results": {}, "outcome_description": "Eleanor Hayes continued walking down Elm Street."}...'
2025-05-08 08:18:21,515 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 900.0, 'results': {}, 'outcome_description': 'Eleanor Hayes continued walking down Elm Street.'}
2025-05-08 08:18:21,515 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:18:21,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:18:21,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:18:21,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1366.6400000001304
2025-05-08 08:18:21,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: continue_current_task - Details: Continuing the walk down Elm Street for another 15 minutes.
2025-05-08 08:18:21,527 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1366.6s. Outcome: Eleanor Hayes continued walking down Elm Street.
2025-05-08 08:18:21,527 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:18:21,527 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes continued walking down Elm Street.'
2025-05-08 08:18:21,554 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:18:21,558 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:18:21,568 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF14C0>
2025-05-08 08:18:21,568 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F323550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:18:21,588 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F332210>
2025-05-08 08:18:21,589 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:18:21,589 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:18:21,589 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:18:21,589 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:18:21,589 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:18:23,224 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:18:44 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1624'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:18:23,224 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:18:23,224 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:18:23,224 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:18:23,224 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:18:23,225 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:18:23,225 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor continues her walk, the minutes ticking by. A group of teenagers (...
2025-05-08 08:18:23,226 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor continues her walk, the minutes ticking by. A group of teenagers (npc_concept_teenagers) skate past, their skateboards clattering on the uneven pavement. Further down the str...'
2025-05-08 08:18:23,226 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor continues her walk, the minutes ticking by. A group of teenagers (npc_concept_teenagers) skate past, their skateboards clattering on the uneven pavement. Further down the str...'
2025-05-08 08:18:23,226 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor continues her walk, the minutes ticking by. A group of teenagers (npc_concept_teenagers) skate past, their skateboards clattering on the uneven pavement. Further down the street
2025-05-08 08:18:23,232 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor continues her walk, the minutes ticking by. A group of teenagers (npc_concept_teenagers) skate past, their skateboards clattering on the uneven pavement. Further down the street, a musician (npc_concept_busker) strums a melancholic tune on an acoustic guitar, his open guitar case collecting spare change from passersby. The sun warms her face, and the air, though still polluted, feels a little cleaner with each step.
2025-05-08 08:18:23,232 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor continues her walk, the minutes ticking by. A group of teenagers (npc_co...
2025-05-08 08:18:24,143 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:29,271 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:34,379 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:39,489 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:44,609 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:49,723 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:54,840 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:18:59,963 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:03,952 - src.simulation_async - INFO - [NarrativeImageGenerator] Requesting image for narrative (T509.8): "Eleanor pushes open the heavy front door of her building and steps out onto Elm Street. The sudden r..."
2025-05-08 08:19:03,952 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:19:03,954 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:19:03,965 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F53F3165A0>
2025-05-08 08:19:03,965 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E591950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:19:03,984 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F53E58F500>
2025-05-08 08:19:03,985 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:19:03,985 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:19:03,985 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:19:03,985 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:19:03,985 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:19:05,086 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:08,120 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:19:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4125'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:19:08,121 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-preview-image-generation:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:19:08,121 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:19:08,322 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:19:08,322 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:19:08,322 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:19:08,327 - google_genai.models - INFO - AFC remote call 1 is done.
2025-05-08 08:19:08,353 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-05-08 08:19:08,353 - PIL.PngImagePlugin - DEBUG - STREAM b'zTXt' 41 137
2025-05-08 08:19:08,353 - PIL.PngImagePlugin - DEBUG - STREAM b'iTXt' 190 647
2025-05-08 08:19:08,354 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 849 8192
2025-05-08 08:19:08,475 - src.simulation_async - INFO - [NarrativeImageGenerator] Successfully generated and saved image: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images\narrative_T510_20250508_081908_354380.png
2025-05-08 08:19:10,183 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:15,295 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:20,406 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:25,518 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:30,632 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:35,747 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:40,875 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:46,001 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:51,120 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:19:56,251 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:01,380 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:06,510 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:11,625 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:16,753 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:21,882 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:26,999 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:32,133 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:37,214 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:42,295 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:47,430 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:52,539 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:20:57,641 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:02,761 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:07,892 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:13,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:18,143 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:23,279 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:28,412 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:33,532 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:38,630 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:43,743 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:48,847 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:53,976 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:21:59,103 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:04,209 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:09,325 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:14,431 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:19,556 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:24,680 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:29,784 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:34,888 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:40,025 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:45,146 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:50,271 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:22:55,399 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:00,524 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:05,636 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:10,770 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:15,893 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:21,025 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:26,137 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:31,252 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:36,364 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:41,449 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:46,564 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:51,683 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:23:56,817 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:01,940 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:07,057 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:12,143 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:17,257 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:22,376 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:27,495 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:32,591 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:37,709 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:42,815 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:47,921 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:53,028 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:24:58,153 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:03,263 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:08,371 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:13,481 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:18,589 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:23,705 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:28,825 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:33,943 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:39,048 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:44,163 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:49,254 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:49,254 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.037626250000010866
2025-05-08 08:25:54,372 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:54,372 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.037208333333333336
2025-05-08 08:25:59,491 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:25:59,491 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.03677341666668266
2025-05-08 08:26:04,595 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:04,595 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.03634766666666838
2025-05-08 08:26:09,717 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:09,717 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.03592966666668265
2025-05-08 08:26:14,829 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:14,829 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.03549475000001257
2025-05-08 08:26:19,937 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:19,937 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.0350690000000177
2025-05-08 08:26:25,069 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:25,069 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.03464450000001428
2025-05-08 08:26:30,194 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:30,194 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.03421875
2025-05-08 08:26:35,317 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:35,317 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.03379291666667753
2025-05-08 08:26:37,490 - src.simulation_async - INFO - [Eleanor Hayes] Busy with long task (rem: 403.4s). Checking for self-reflection.
2025-05-08 08:26:37,490 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_interjection_sim_time = 963.280999999959
2025-05-08 08:26:37,490 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = reflecting
2025-05-08 08:26:37,514 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:26:37,518 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:26:37,550 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFBBA70>
2025-05-08 08:26:37,550 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2EA550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:26:37,569 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFBA570>
2025-05-08 08:26:37,569 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:26:37,569 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:26:37,569 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:26:37,569 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:26:37,570 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:26:38,791 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:27:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1209'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:26:38,791 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:26:38,791 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:26:38,791 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:26:38,791 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:26:38,791 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:26:38,792 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, another 15 minutes down. I'm feeling significantly less restless now. The walk was a good idea. I'm starting to feel a little hungry, though. I could head back to my apar...'
2025-05-08 08:26:38,792 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, another 15 minutes down. I'm feeling significantly less restless now. The walk was a good idea. I'm starting to feel a little hungry, though. I could head back to my apar...'
2025-05-08 08:26:38,792 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, another 15 minutes down. I'm feeling significantly less restless now. The walk was a good idea. I'm starting to feel a little hungry, though. I could head back to my apar
2025-05-08 08:26:38,792 - src.simulation_async - INFO - [Eleanor Hayes] Reflection: Chose to 'move'. Monologue: Okay, another 15 minutes down. I'm feeling signifi...
2025-05-08 08:26:38,792 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:38,792 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:26:38,792 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 08:26:38,792 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'back towards the hotdog vendor'}
2025-05-08 08:26:38,792 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 08:26:38,818 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:26:38,824 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:26:38,836 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F30FE30>
2025-05-08 08:26:38,836 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F3F9450> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:26:38,853 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F36B950>
2025-05-08 08:26:38,853 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:26:38,853 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:26:38,853 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:26:38,853 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:26:38,853 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:26:39,562 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:27:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=698'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:26:39,562 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:26:39,562 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:26:39,563 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:26:39,563 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:26:39,563 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:26:39,563 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 300.0, "results": {}, "outcome_description": "Eleanor Hay...
2025-05-08 08:26:39,564 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 300.0, "results": {}, "outcome_description": "Eleanor Hayes walked back towards the hotdog vendor."}...'
2025-05-08 08:26:39,564 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 300.0, "results": {}, "outcome_description": "Eleanor Hayes walked back towards the hotdog vendor."}...'
2025-05-08 08:26:39,564 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 300.0, 'results': {}, 'outcome_description': 'Eleanor Hayes walked back towards the hotdog vendor.'}
2025-05-08 08:26:39,564 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:26:39,576 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:26:39,576 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:26:39,576 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1264.59300000011
2025-05-08 08:26:39,576 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: back towards the hotdog vendor
2025-05-08 08:26:39,576 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1264.6s. Outcome: Eleanor Hayes walked back towards the hotdog vendor.
2025-05-08 08:26:39,576 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:26:39,576 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes walked back towards the hotdog vendor.'
2025-05-08 08:26:39,604 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:26:39,609 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:26:39,622 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F2D7FB0>
2025-05-08 08:26:39,622 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EFDAB50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:26:39,639 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F33A180>
2025-05-08 08:26:39,639 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:26:39,640 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:26:39,640 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:26:39,640 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:26:39,640 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:26:40,443 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:41,015 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:27:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1364'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:26:41,016 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:26:41,016 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:26:41,023 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:26:41,023 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:26:41,023 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:26:41,025 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor retraces her steps, the promise of a salty, processed treat pullin...
2025-05-08 08:26:41,025 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor retraces her steps, the promise of a salty, processed treat pulling her back the way she came. The same hotdog vendor (npc_concept_hotdog_vendor) is still there, his cart a b...'
2025-05-08 08:26:41,025 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor retraces her steps, the promise of a salty, processed treat pulling her back the way she came. The same hotdog vendor (npc_concept_hotdog_vendor) is still there, his cart a b...'
2025-05-08 08:26:41,025 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor retraces her steps, the promise of a salty, processed treat pulling her back the way she came. The same hotdog vendor (npc_concept_hotdog_vendor) is still there, his cart a beac
2025-05-08 08:26:41,031 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor retraces her steps, the promise of a salty, processed treat pulling her back the way she came. The same hotdog vendor (npc_concept_hotdog_vendor) is still there, his cart a beacon of savory temptation. He gives her a nod as she approaches, a silent acknowledgment of a returning customer.
2025-05-08 08:26:41,031 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor retraces her steps, the promise of a salty, processed treat pulling her ...
2025-05-08 08:26:45,562 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:50,677 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:26:55,781 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:00,900 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:06,013 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:11,143 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:16,277 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:21,401 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:26,522 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:28,468 - src.simulation_async - INFO - [NarrativeImageGenerator] Requesting image for narrative (T1014.3): "Eleanor starts walking, joining the flow of pedestrians along the sidewalk. The rhythm of her footst..."
2025-05-08 08:27:28,468 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:27:28,469 - httpcore.connection - DEBUG - close.started
2025-05-08 08:27:28,469 - httpcore.connection - DEBUG - close.complete
2025-05-08 08:27:28,469 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:27:28,478 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F53EFF2ED0>
2025-05-08 08:27:28,478 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E591950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:27:28,494 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F53EFB9F70>
2025-05-08 08:27:28,494 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:27:28,494 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:27:28,494 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:27:28,495 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:27:28,495 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:27:31,639 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:31,976 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:27:53 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3473'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:27:31,977 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-preview-image-generation:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:27:31,977 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:27:32,177 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:27:32,177 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:27:32,177 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:27:32,181 - google_genai.models - INFO - AFC remote call 1 is done.
2025-05-08 08:27:32,181 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-05-08 08:27:32,181 - PIL.PngImagePlugin - DEBUG - STREAM b'zTXt' 41 137
2025-05-08 08:27:32,181 - PIL.PngImagePlugin - DEBUG - STREAM b'iTXt' 190 647
2025-05-08 08:27:32,181 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 849 8192
2025-05-08 08:27:32,307 - src.simulation_async - INFO - [NarrativeImageGenerator] Successfully generated and saved image: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images\narrative_T1014_20250508_082732_182145.png
2025-05-08 08:27:36,762 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:41,900 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:47,017 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:52,137 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:27:57,265 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:02,399 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:07,510 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:12,609 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:17,720 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:22,832 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:27,936 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:33,069 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:38,178 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:43,269 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:48,391 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:53,523 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:28:58,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:03,771 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:08,879 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:14,010 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:19,112 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:24,227 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:29,352 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:34,471 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:39,599 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:44,704 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:49,815 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:29:54,929 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:00,056 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:05,171 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:10,297 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:15,427 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:20,541 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:25,650 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:30,776 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:35,893 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:41,011 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:46,112 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:51,223 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:30:56,339 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:01,461 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:06,562 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:11,678 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:16,791 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:21,877 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:26,982 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:32,096 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:37,217 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:38,742 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 1264.6 (due at 1264.6).
2025-05-08 08:31:38,742 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 08:31:38,742 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:38,742 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:31:38,742 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:31:39,115 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:31:39,115 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:31:39,139 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:31:39,144 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:31:39,178 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E628530>
2025-05-08 08:31:39,178 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F34AAD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:31:39,198 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF23800>
2025-05-08 08:31:39,198 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:31:39,198 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:31:39,198 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:31:39,198 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:31:39,198 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:31:40,159 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:32:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=951'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:31:40,160 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:31:40,160 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:31:40,160 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:31:40,160 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:31:40,160 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:31:40,161 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Here we are. Hotdog time! I'll talk to the vendor and order one with everything.", "action_type": "talk", "target_id": "npc_hotdog_vendor", "details": "to the hotdog vendor abo...'
2025-05-08 08:31:40,161 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Here we are. Hotdog time! I'll talk to the vendor and order one with everything.", "action_type": "talk", "target_id": "npc_hotdog_vendor", "details": "to the hotdog vendor abo...'
2025-05-08 08:31:40,161 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Here we are. Hotdog time! I'll talk to the vendor and order one with everything.", 'action_type': 'talk', 'target_id': 'npc_hotdog_vendor', 'details': 'to the hotdog vendor abo
2025-05-08 08:31:40,177 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:31:40,177 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (talk on npc_hotdog_vendor) classified as 'environment'.
2025-05-08 08:31:40,177 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'talk', 'target_id': 'npc_hotdog_vendor', 'details': 'to the hotdog vendor about ordering a hotdog with everything'}
2025-05-08 08:31:40,177 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (talk).
2025-05-08 08:31:40,199 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:31:40,204 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:31:40,216 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F245AF0>
2025-05-08 08:31:40,216 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F34A2D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:31:40,235 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E628320>
2025-05-08 08:31:40,235 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:31:40,236 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:31:40,236 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:31:40,236 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:31:40,236 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:31:41,159 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:32:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=912'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:31:41,159 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:31:41,160 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:31:41,160 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:31:41,160 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:31:41,160 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:31:41,161 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 45.0, "results": {"simulacra_profiles.sim_3e912d.last_obs...
2025-05-08 08:31:41,161 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 45.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "The hotdog vendor said: 'One dog with everything coming right up!'"}, "outcome_description": "El...'
2025-05-08 08:31:41,161 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 45.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "The hotdog vendor said: 'One dog with everything coming right up!'"}, "outcome_description": "El...'
2025-05-08 08:31:41,161 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 45.0, 'results': {'simulacra_profiles.sim_3e912d.last_observation': "The hotdog vendor said: 'One dog with everything coming right up!'"}, 'outcome_description': 'El
2025-05-08 08:31:41,161 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:31:41,173 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:31:41,173 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.last_observation': "The hotdog vendor said: 'One dog with everything coming right up!'"}
2025-05-08 08:31:41,173 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1311.0
2025-05-08 08:31:41,173 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: talk - Details: to the hotdog vendor about ordering a hotdog with everything
2025-05-08 08:31:41,173 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1311.0s. Outcome: Eleanor Hayes spoke with the hotdog vendor.
2025-05-08 08:31:41,173 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:31:41,173 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes spoke with the hotdog vendor.'
2025-05-08 08:31:41,197 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:31:41,202 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:31:41,214 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F339790>
2025-05-08 08:31:41,214 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F32E8D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:31:41,229 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E9796D0>
2025-05-08 08:31:41,230 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:31:41,230 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:31:41,230 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:31:41,230 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:31:41,230 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:31:42,335 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:42,495 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:32:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1257'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:31:42,496 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:31:42,496 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:31:42,496 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:31:42,496 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:31:42,496 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:31:42,497 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor approaches the cart, the sizzling sound of the hotdogs on the gril...
2025-05-08 08:31:42,497 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor approaches the cart, the sizzling sound of the hotdogs on the grill making her stomach rumble. The hotdog vendor (npc_concept_hotdog_vendor), a man with a friendly face and a...'
2025-05-08 08:31:42,497 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor approaches the cart, the sizzling sound of the hotdogs on the grill making her stomach rumble. The hotdog vendor (npc_concept_hotdog_vendor), a man with a friendly face and a...'
2025-05-08 08:31:42,497 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor approaches the cart, the sizzling sound of the hotdogs on the grill making her stomach rumble. The hotdog vendor (npc_concept_hotdog_vendor), a man with a friendly face and a we
2025-05-08 08:31:42,504 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor approaches the cart, the sizzling sound of the hotdogs on the grill making her stomach rumble. The hotdog vendor (npc_concept_hotdog_vendor), a man with a friendly face and a well-worn apron, smiles. "One dog with everything coming right up!" he says, already reaching for a bun.
2025-05-08 08:31:42,504 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor approaches the cart, the sizzling sound of the hotdogs on the grill maki...
2025-05-08 08:31:47,442 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:52,567 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:31:57,693 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:02,820 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:07,927 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:13,047 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:18,152 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:23,262 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:25,143 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 1311.0 (due at 1311.0).
2025-05-08 08:32:25,143 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = The hotdog vendor said: 'One dog with everything coming right up!'
2025-05-08 08:32:25,143 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:32:25,143 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:25,143 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:32:25,143 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:32:25,578 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:32:25,578 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:32:25,603 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:32:25,609 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:32:25,657 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F30E630>
2025-05-08 08:32:25,657 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2E8150> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:32:25,678 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E5CBBC0>
2025-05-08 08:32:25,679 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:32:25,679 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:32:25,679 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:32:25,679 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:32:25,679 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:32:26,657 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:32:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=963'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:32:26,657 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:32:26,657 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:32:26,658 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:32:26,658 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:32:26,658 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:32:26,659 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Great! He's already on it. While he's preparing the hotdog, I think I'll just wait here and enjoy the city sounds. Nothing else to do until it's ready.", "action_type": "wait",...'
2025-05-08 08:32:26,659 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Great! He's already on it. While he's preparing the hotdog, I think I'll just wait here and enjoy the city sounds. Nothing else to do until it's ready.", "action_type": "wait",...'
2025-05-08 08:32:26,659 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Great! He's already on it. While he's preparing the hotdog, I think I'll just wait here and enjoy the city sounds. Nothing else to do until it's ready.", 'action_type': 'wait',
2025-05-08 08:32:26,676 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:32:26,676 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (wait on N/A) classified as 'environment'.
2025-05-08 08:32:26,676 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'wait', 'target_id': None, 'details': 'waiting for the hotdog'}
2025-05-08 08:32:26,676 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (wait).
2025-05-08 08:32:26,699 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:32:26,703 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:32:26,715 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F245250>
2025-05-08 08:32:26,715 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F321050> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:32:26,732 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F35E1B0>
2025-05-08 08:32:26,733 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:32:26,733 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:32:26,733 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:32:26,734 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:32:26,734 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:32:27,447 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:32:49 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=705'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:32:27,447 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:32:27,447 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:32:27,451 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:32:27,451 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:32:27,451 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:32:27,452 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 30.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-08 08:32:27,452 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 30.0, "results": {}, "outcome_description": "Eleanor Hayes waited for the hotdog."}...'
2025-05-08 08:32:27,452 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 30.0, "results": {}, "outcome_description": "Eleanor Hayes waited for the hotdog."}...'
2025-05-08 08:32:27,453 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 30.0, 'results': {}, 'outcome_description': 'Eleanor Hayes waited for the hotdog.'}
2025-05-08 08:32:27,453 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:32:27,464 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:32:27,464 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:32:27,464 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1342.46800000011
2025-05-08 08:32:27,464 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: wait - Details: waiting for the hotdog
2025-05-08 08:32:27,464 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1342.5s. Outcome: Eleanor Hayes waited for the hotdog.
2025-05-08 08:32:27,464 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:32:27,464 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes waited for the hotdog.'
2025-05-08 08:32:27,491 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:32:27,496 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:32:27,512 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F3D1250>
2025-05-08 08:32:27,512 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EFDB4D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:32:27,533 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF23800>
2025-05-08 08:32:27,533 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:32:27,534 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:32:27,534 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:32:27,534 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:32:27,534 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:32:28,396 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:29,186 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:32:50 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1639'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:32:29,187 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:32:29,187 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:32:29,187 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:32:29,187 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:32:29,187 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:32:29,188 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor leans against a nearby lamppost, the metal cool against her back, ...
2025-05-08 08:32:29,188 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor leans against a nearby lamppost, the metal cool against her back, and watches as the hotdog vendor (npc_concept_hotdog_vendor) expertly assembles her lunch. The rhythmic squi...'
2025-05-08 08:32:29,188 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor leans against a nearby lamppost, the metal cool against her back, and watches as the hotdog vendor (npc_concept_hotdog_vendor) expertly assembles her lunch. The rhythmic squi...'
2025-05-08 08:32:29,188 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor leans against a nearby lamppost, the metal cool against her back, and watches as the hotdog vendor (npc_concept_hotdog_vendor) expertly assembles her lunch. The rhythmic squirt 
2025-05-08 08:32:29,195 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor leans against a nearby lamppost, the metal cool against her back, and watches as the hotdog vendor (npc_concept_hotdog_vendor) expertly assembles her lunch. The rhythmic squirt of mustard and relish, the scattering of onions, the final flourish of a pickle spear  it's a culinary performance in miniature. A pigeon (npc_concept_pigeon) struts confidently across the sidewalk, eyeing the scene with opportunistic interest.
2025-05-08 08:32:29,195 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor leans against a nearby lamppost, the metal cool against her back, and wa...
2025-05-08 08:32:33,522 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:38,636 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:43,766 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:48,895 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:53,980 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:56,662 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 1342.5 (due at 1342.5).
2025-05-08 08:32:56,662 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 08:32:56,662 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:56,662 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:32:56,662 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:32:57,096 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:32:57,097 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:32:57,121 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:32:57,126 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:32:57,140 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF21310>
2025-05-08 08:32:57,140 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F3231D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:32:57,158 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E979940>
2025-05-08 08:32:57,158 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:32:57,158 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:32:57,158 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:32:57,159 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:32:57,159 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:32:58,062 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:33:19 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=890'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:32:58,062 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:32:58,063 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:32:58,063 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:32:58,063 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:32:58,064 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:32:58,064 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Almost there! That pigeon looks like it wants a bite, too. I'm really looking forward to this. I'm still waiting, so I'll continue waiting.", "action_type": "wait", "target_id"...'
2025-05-08 08:32:58,065 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Almost there! That pigeon looks like it wants a bite, too. I'm really looking forward to this. I'm still waiting, so I'll continue waiting.", "action_type": "wait", "target_id"...'
2025-05-08 08:32:58,065 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Almost there! That pigeon looks like it wants a bite, too. I'm really looking forward to this. I'm still waiting, so I'll continue waiting.", 'action_type': 'wait', 'target_id'
2025-05-08 08:32:58,081 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:32:58,081 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (wait on N/A) classified as 'environment'.
2025-05-08 08:32:58,081 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'wait', 'target_id': None, 'details': 'waiting for the hotdog'}
2025-05-08 08:32:58,081 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (wait).
2025-05-08 08:32:58,104 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:32:58,109 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:32:58,135 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF3A10>
2025-05-08 08:32:58,135 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F322F50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:32:58,155 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF36E0>
2025-05-08 08:32:58,155 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:32:58,155 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:32:58,155 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:32:58,156 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:32:58,156 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:32:59,027 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:33:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=858'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:32:59,027 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:32:59,027 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:32:59,028 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:32:59,028 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:32:59,028 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:32:59,029 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 30.0, "results": {}, "outcome_description": "Eleanor Haye...
2025-05-08 08:32:59,029 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 30.0, "results": {}, "outcome_description": "Eleanor Hayes continued waiting for the hotdog."}...'
2025-05-08 08:32:59,029 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 30.0, "results": {}, "outcome_description": "Eleanor Hayes continued waiting for the hotdog."}...'
2025-05-08 08:32:59,029 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 30.0, 'results': {}, 'outcome_description': 'Eleanor Hayes continued waiting for the hotdog.'}
2025-05-08 08:32:59,029 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:32:59,045 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:32:59,045 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:32:59,045 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1373.936999999918
2025-05-08 08:32:59,045 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: wait - Details: waiting for the hotdog
2025-05-08 08:32:59,045 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1373.9s. Outcome: Eleanor Hayes continued waiting for the hotdog.
2025-05-08 08:32:59,045 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:32:59,045 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes continued waiting for the hotdog.'
2025-05-08 08:32:59,069 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:32:59,075 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:32:59,076 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:32:59,088 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F30DF10>
2025-05-08 08:32:59,088 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F32C2D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:32:59,111 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F30E630>
2025-05-08 08:32:59,111 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:32:59,111 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:32:59,111 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:32:59,111 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:32:59,111 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:00,428 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:33:22 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1307'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:00,429 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:00,429 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:00,429 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:00,429 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:00,430 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:00,431 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor drums her fingers lightly against the lamppost as she waits, the a...
2025-05-08 08:33:00,431 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor drums her fingers lightly against the lamppost as she waits, the aroma of grilled meat and spices intensifying. The hotdog vendor (npc_concept_hotdog_vendor) carefully wraps ...'
2025-05-08 08:33:00,431 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor drums her fingers lightly against the lamppost as she waits, the aroma of grilled meat and spices intensifying. The hotdog vendor (npc_concept_hotdog_vendor) carefully wraps ...'
2025-05-08 08:33:00,431 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor drums her fingers lightly against the lamppost as she waits, the aroma of grilled meat and spices intensifying. The hotdog vendor (npc_concept_hotdog_vendor) carefully wraps the
2025-05-08 08:33:00,437 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor drums her fingers lightly against the lamppost as she waits, the aroma of grilled meat and spices intensifying. The hotdog vendor (npc_concept_hotdog_vendor) carefully wraps the hotdog in a paper sleeve and hands it over with a smile. "Enjoy!" he says, already turning his attention to the next customer.
2025-05-08 08:33:00,437 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor drums her fingers lightly against the lamppost as she waits, the aroma o...
2025-05-08 08:33:04,195 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:09,295 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:14,426 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:19,549 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:24,660 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:28,134 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 1374.0 (due at 1373.9).
2025-05-08 08:33:28,134 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 08:33:28,134 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:28,134 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:33:28,134 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:33:28,522 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:33:28,522 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:33:28,548 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:28,559 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:28,569 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E8755E0>
2025-05-08 08:33:28,569 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2EACD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:28,586 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F36FE30>
2025-05-08 08:33:28,586 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:28,586 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:28,586 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:28,586 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:28,586 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:29,413 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:33:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=813'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:29,413 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:29,413 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:29,413 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:29,413 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:29,413 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:29,414 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "\"Enjoy!\" he says. I will! Finally, the moment of truth. I'll take the hotdog and find a place to eat it.", "action_type": "use", "target_id": "npc_hotdog_vendor", "details": ...'
2025-05-08 08:33:29,414 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "\"Enjoy!\" he says. I will! Finally, the moment of truth. I'll take the hotdog and find a place to eat it.", "action_type": "use", "target_id": "npc_hotdog_vendor", "details": ...'
2025-05-08 08:33:29,414 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': '"Enjoy!" he says. I will! Finally, the moment of truth. I\'ll take the hotdog and find a place to eat it.', 'action_type': 'use', 'target_id': 'npc_hotdog_vendor', 'details': '
2025-05-08 08:33:29,436 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:33:29,436 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on npc_hotdog_vendor) classified as 'environment'.
2025-05-08 08:33:29,436 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'npc_hotdog_vendor', 'details': 'taking the hotdog from the vendor'}
2025-05-08 08:33:29,436 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 08:33:29,460 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:29,466 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:29,478 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F30F200>
2025-05-08 08:33:29,478 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2EA550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:29,493 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F30C3E0>
2025-05-08 08:33:29,494 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:29,494 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:29,494 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:29,494 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:29,494 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:30,241 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:33:51 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=739'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:30,241 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:30,241 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:30,242 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:30,242 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:30,242 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:30,243 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes...
2025-05-08 08:33:30,243 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes took the hotdog from the vendor."}...'
2025-05-08 08:33:30,243 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {}, "outcome_description": "Eleanor Hayes took the hotdog from the vendor."}...'
2025-05-08 08:33:30,243 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {}, 'outcome_description': 'Eleanor Hayes took the hotdog from the vendor.'}
2025-05-08 08:33:30,243 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:33:30,255 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:33:30,255 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:33:30,255 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1380.2029999999795
2025-05-08 08:33:30,255 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: taking the hotdog from the vendor
2025-05-08 08:33:30,255 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1380.2s. Outcome: Eleanor Hayes took the hotdog from the vendor.
2025-05-08 08:33:30,255 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:33:30,255 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes took the hotdog from the vendor.'
2025-05-08 08:33:30,281 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:30,287 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:30,303 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF2E10>
2025-05-08 08:33:30,303 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2EB550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:30,321 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F33B3B0>
2025-05-08 08:33:30,321 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:30,321 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:30,321 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:30,321 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:30,321 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:31,583 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:33:53 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1253'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:31,585 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:31,585 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:31,585 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:31,585 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:31,585 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:31,586 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor carefully takes the warm hotdog from the vendor's hand, the paper ...
2025-05-08 08:33:31,586 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor carefully takes the warm hotdog from the vendor's hand, the paper sleeve slightly greasy against her fingers. She offers a grateful nod to the hotdog vendor (npc_concept_hotd...'
2025-05-08 08:33:31,586 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor carefully takes the warm hotdog from the vendor's hand, the paper sleeve slightly greasy against her fingers. She offers a grateful nod to the hotdog vendor (npc_concept_hotd...'
2025-05-08 08:33:31,586 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': "Eleanor carefully takes the warm hotdog from the vendor's hand, the paper sleeve slightly greasy against her fingers. She offers a grateful nod to the hotdog vendor (npc_concept_hotdog_
2025-05-08 08:33:31,593 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor carefully takes the warm hotdog from the vendor's hand, the paper sleeve slightly greasy against her fingers. She offers a grateful nod to the hotdog vendor (npc_concept_hotdog_vendor), then scans the street for a suitable spot to enjoy her meal.
2025-05-08 08:33:31,593 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor carefully takes the warm hotdog from the vendor's hand, the paper sleeve...
2025-05-08 08:33:34,336 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 1380.2 (due at 1380.2).
2025-05-08 08:33:34,336 - src.simulation_async - DEBUG - [TimeManager] No pending results found for completed action of sim_3e912d.
2025-05-08 08:33:34,336 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:34,336 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:33:34,336 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:33:34,491 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:33:34,491 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:33:34,515 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:34,522 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:34,535 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F35DE80>
2025-05-08 08:33:34,535 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F25E950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:34,557 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F35DEB0>
2025-05-08 08:33:34,557 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:34,558 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:34,558 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:34,558 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:34,558 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:35,504 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:33:57 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=935'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:35,504 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:35,504 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:35,504 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:35,504 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:35,504 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:35,505 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Okay, hotdog in hand. Now to find a place to eat it. I don't want to just stand here on the sidewalk. Maybe there's a bench nearby? I'll look around to see if I can spot one.",...'
2025-05-08 08:33:35,505 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Okay, hotdog in hand. Now to find a place to eat it. I don't want to just stand here on the sidewalk. Maybe there's a bench nearby? I'll look around to see if I can spot one.",...'
2025-05-08 08:33:35,505 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Okay, hotdog in hand. Now to find a place to eat it. I don't want to just stand here on the sidewalk. Maybe there's a bench nearby? I'll look around to see if I can spot one.",
2025-05-08 08:33:35,527 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:33:35,527 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-08 08:33:35,527 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'looking for a bench to sit and eat the hotdog'}
2025-05-08 08:33:35,527 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-08 08:33:35,550 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:35,557 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:35,593 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E8755E0>
2025-05-08 08:33:35,593 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53EFDBDD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:35,610 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFBB890>
2025-05-08 08:33:35,610 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:35,611 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:35,611 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:35,611 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:35,611 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:36,660 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:33:58 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1041'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:36,660 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:36,660 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:36,661 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:36,661 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:36,661 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:36,662 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_obse...
2025-05-08 08:33:36,662 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is on Elm Street, holding a hotdog. A hotdog vendor is nearby. Across the street, t...'
2025-05-08 08:33:36,662 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is on Elm Street, holding a hotdog. A hotdog vendor is nearby. Across the street, t...'
2025-05-08 08:33:36,662 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {'simulacra_profiles.sim_3e912d.last_observation': 'Eleanor Hayes is on Elm Street, holding a hotdog. A hotdog vendor is nearby. Across the street, t
2025-05-08 08:33:36,662 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:33:36,674 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:33:36,674 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.last_observation': 'Eleanor Hayes is on Elm Street, holding a hotdog. A hotdog vendor is nearby. Across the street, there is a small park with benches.'}
2025-05-08 08:33:36,674 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1386.375
2025-05-08 08:33:36,674 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: look_around - Details: looking for a bench to sit and eat the hotdog
2025-05-08 08:33:36,674 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1386.4s. Outcome: Eleanor Hayes looked around.
2025-05-08 08:33:36,674 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:33:36,674 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around.'
2025-05-08 08:33:36,700 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:36,707 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:36,724 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F30FB90>
2025-05-08 08:33:36,724 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F322850> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:36,749 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F35D9A0>
2025-05-08 08:33:36,749 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:36,750 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:36,750 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:36,750 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:36,750 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:38,442 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:00 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1678'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:38,442 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:38,442 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:38,443 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:38,443 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:38,443 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:38,444 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor looks around, the tantalizing aroma of the hotdog filling her sens...
2025-05-08 08:33:38,444 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor looks around, the tantalizing aroma of the hotdog filling her senses. The **hotdog vendor (npc_concept_hotdog_vendor)** remains at his post, serving the lunch crowd. Across t...'
2025-05-08 08:33:38,444 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor looks around, the tantalizing aroma of the hotdog filling her senses. The **hotdog vendor (npc_concept_hotdog_vendor)** remains at his post, serving the lunch crowd. Across t...'
2025-05-08 08:33:38,444 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor looks around, the tantalizing aroma of the hotdog filling her senses. The **hotdog vendor (npc_concept_hotdog_vendor)** remains at his post, serving the lunch crowd. Across the 
2025-05-08 08:33:38,451 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor looks around, the tantalizing aroma of the hotdog filling her senses. The **hotdog vendor (npc_concept_hotdog_vendor)** remains at his post, serving the lunch crowd. Across the street, she spots a small **park (park_elm_street_01)**, its green space offering a welcome respite from the concrete jungle, and more importantly, a scattering of inviting **benches (bench_park_01)**.
2025-05-08 08:33:38,455 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor looks around, the tantalizing aroma of the hotdog filling her senses. Th...
2025-05-08 08:33:38,455 - src.simulation_async - WARNING - Path segment 'Outside_Elm_Street' not found or not dict in 'current_world_state.location_details.Outside_Elm_Street.ephemeral_objects'. Creating.
2025-05-08 08:33:38,456 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Outside_Elm_Street.ephemeral_objects = []
2025-05-08 08:33:38,456 - src.simulation_async - INFO - [NarrationTask] Cleared ephemeral objects for location Outside_Elm_Street as none were discovered by look_around.
2025-05-08 08:33:38,456 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Outside_Elm_Street.ephemeral_npcs = [{'id': 'npc_hotdog_vendor', 'name': 'Hotdog Vendor', 'description': 'The hotdog vendor nearby.'}]
2025-05-08 08:33:38,456 - src.simulation_async - INFO - [NarrationTask] Updated/Set 1 ephemeral NPCs for location Outside_Elm_Street from look_around.
2025-05-08 08:33:38,456 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Outside_Elm_Street.connected_locations = [{'to_location_id_hint': 'Park_Elm_Street', 'description': 'Across the street, a small park with benches.', 'travel_time_estimate_seconds': 30}]
2025-05-08 08:33:38,456 - src.simulation_async - INFO - [NarrationTask] Updated/Set 1 connected_locations for Outside_Elm_Street from look_around.
2025-05-08 08:33:40,012 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:40,600 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 1386.5 (due at 1386.4).
2025-05-08 08:33:40,600 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor Hayes is on Elm Street, holding a hotdog. A hotdog vendor is nearby. Across the street, there is a small park with benches.
2025-05-08 08:33:40,600 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:33:40,600 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:40,600 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:33:40,600 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:33:40,631 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:33:40,636 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:33:40,664 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:40,672 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:40,683 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F338FB0>
2025-05-08 08:33:40,683 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F320BD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:40,701 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F3396A0>
2025-05-08 08:33:40,701 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:40,701 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:40,701 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:40,701 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:40,701 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:41,498 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:03 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=788'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:41,498 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:41,498 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:41,504 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:41,504 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:41,504 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:41,505 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Perfect! A park with benches across the street. That's exactly what I was hoping for. I'll head over there now.", "action_type": "move", "target_id": null, "details": "across t...'
2025-05-08 08:33:41,505 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Perfect! A park with benches across the street. That's exactly what I was hoping for. I'll head over there now.", "action_type": "move", "target_id": null, "details": "across t...'
2025-05-08 08:33:41,505 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Perfect! A park with benches across the street. That's exactly what I was hoping for. I'll head over there now.", 'action_type': 'move', 'target_id': None, 'details': 'across t
2025-05-08 08:33:41,522 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:33:41,523 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (move on N/A) classified as 'environment'.
2025-05-08 08:33:41,523 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'move', 'target_id': None, 'details': 'across the street to the park'}
2025-05-08 08:33:41,523 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (move).
2025-05-08 08:33:41,550 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:41,558 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:41,571 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFBAAE0>
2025-05-08 08:33:41,571 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F25C950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:41,588 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFB9790>
2025-05-08 08:33:41,589 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:41,589 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:41,589 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:41,589 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:41,589 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:42,528 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=932'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:42,528 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:42,528 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:42,528 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:42,528 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:42,529 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:42,529 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 30.0, "results": {"simulacra_profiles.sim_3e912d.location...
2025-05-08 08:33:42,530 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 30.0, "results": {"simulacra_profiles.sim_3e912d.location": "Park_Elm_Street"}, "outcome_description": "Eleanor Hayes moved across the street to the park."}...'
2025-05-08 08:33:42,530 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 30.0, "results": {"simulacra_profiles.sim_3e912d.location": "Park_Elm_Street"}, "outcome_description": "Eleanor Hayes moved across the street to the park."}...'
2025-05-08 08:33:42,530 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 30.0, 'results': {'simulacra_profiles.sim_3e912d.location': 'Park_Elm_Street'}, 'outcome_description': 'Eleanor Hayes moved across the street to the park.'}
2025-05-08 08:33:42,530 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:33:42,541 - src.simulation_async - INFO - [WorldEngineLLM] Queuing update for sim_3e912d's location_details to: 'You have arrived in Park_Elm_Street.'
2025-05-08 08:33:42,541 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:33:42,541 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.location': 'Park_Elm_Street', 'simulacra_profiles.sim_3e912d.location_details': 'You have arrived in Park_Elm_Street.'}
2025-05-08 08:33:42,541 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1417.311999999918
2025-05-08 08:33:42,541 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: move - Details: across the street to the park
2025-05-08 08:33:42,541 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1417.3s. Outcome: Eleanor Hayes moved across the street to the park.
2025-05-08 08:33:42,542 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Outside_Elm_Street
2025-05-08 08:33:42,542 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes moved across the street to the park.'
2025-05-08 08:33:42,566 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:33:42,575 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:33:42,615 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F339220>
2025-05-08 08:33:42,615 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F25CC50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:33:42,634 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F2D6870>
2025-05-08 08:33:42,634 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:33:42,634 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:33:42,634 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:33:42,634 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:33:42,634 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:33:43,712 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:05 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1066'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:33:43,712 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:33:43,712 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:33:43,714 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:33:43,714 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:33:43,714 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:33:43,715 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor carefully navigates across Elm Street, waiting for a break in the ...
2025-05-08 08:33:43,715 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor carefully navigates across Elm Street, waiting for a break in the traffic before hurrying over to the small park. The transition from the bustling sidewalk to the slightly qu...'
2025-05-08 08:33:43,715 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor carefully navigates across Elm Street, waiting for a break in the traffic before hurrying over to the small park. The transition from the bustling sidewalk to the slightly qu...'
2025-05-08 08:33:43,715 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor carefully navigates across Elm Street, waiting for a break in the traffic before hurrying over to the small park. The transition from the bustling sidewalk to the slightly quiet
2025-05-08 08:33:43,721 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor carefully navigates across Elm Street, waiting for a break in the traffic before hurrying over to the small park. The transition from the bustling sidewalk to the slightly quieter, greener space is immediately calming.
2025-05-08 08:33:43,721 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor carefully navigates across Elm Street, waiting for a break in the traffi...
2025-05-08 08:33:45,123 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:50,255 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:33:55,384 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:00,516 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:05,633 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:10,755 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:11,484 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 1417.4 (due at 1417.3).
2025-05-08 08:34:11,484 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location = Park_Elm_Street
2025-05-08 08:34:11,484 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.location_details = You have arrived in Park_Elm_Street.
2025-05-08 08:34:11,484 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:34:11,484 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:11,484 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:34:11,484 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:34:11,918 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:34:11,919 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:34:11,944 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:11,952 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:11,963 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F316000>
2025-05-08 08:34:11,963 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2EBDD0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:11,986 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F3382F0>
2025-05-08 08:34:11,986 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:11,986 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:11,986 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:11,986 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:11,986 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:12,806 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:34 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=811'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:12,806 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:12,806 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:12,807 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:12,807 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:12,807 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:12,808 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Ah, much nicer over here. Now to find an empty bench. I'll look around to see which one looks most appealing.", "action_type": "look_around", "target_id": null, "details": "loo...'
2025-05-08 08:34:12,808 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Ah, much nicer over here. Now to find an empty bench. I'll look around to see which one looks most appealing.", "action_type": "look_around", "target_id": null, "details": "loo...'
2025-05-08 08:34:12,808 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Ah, much nicer over here. Now to find an empty bench. I'll look around to see which one looks most appealing.", 'action_type': 'look_around', 'target_id': None, 'details': 'loo
2025-05-08 08:34:12,826 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:34:12,826 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (look_around on N/A) classified as 'environment'.
2025-05-08 08:34:12,826 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'look_around', 'target_id': None, 'details': 'looking for an empty bench in the park'}
2025-05-08 08:34:12,826 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (look_around).
2025-05-08 08:34:12,853 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:12,861 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:12,875 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F314080>
2025-05-08 08:34:12,876 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2EB550> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:12,895 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF23170>
2025-05-08 08:34:12,896 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:12,896 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:12,896 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:12,896 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:12,896 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:13,986 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:35 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1079'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:13,987 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:13,987 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:13,988 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:13,988 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:13,988 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:13,989 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_obse...
2025-05-08 08:34:13,989 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is in a small park on Elm Street. Several benches are scattered around the park, so...'
2025-05-08 08:34:13,989 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 5.0, "results": {"simulacra_profiles.sim_3e912d.last_observation": "Eleanor Hayes is in a small park on Elm Street. Several benches are scattered around the park, so...'
2025-05-08 08:34:13,989 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 5.0, 'results': {'simulacra_profiles.sim_3e912d.last_observation': 'Eleanor Hayes is in a small park on Elm Street. Several benches are scattered around the park, so
2025-05-08 08:34:13,989 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:34:14,000 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:34:14,000 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {'simulacra_profiles.sim_3e912d.last_observation': 'Eleanor Hayes is in a small park on Elm Street. Several benches are scattered around the park, some occupied, some empty. A fountain is in the center of the park.'}
2025-05-08 08:34:14,000 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 1423.655999999959
2025-05-08 08:34:14,000 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: look_around - Details: looking for an empty bench in the park
2025-05-08 08:34:14,000 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 1423.7s. Outcome: Eleanor Hayes looked around.
2025-05-08 08:34:14,000 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Park_Elm_Street
2025-05-08 08:34:14,000 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes looked around.'
2025-05-08 08:34:14,025 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:14,033 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:14,048 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E628080>
2025-05-08 08:34:14,048 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2A06D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:14,067 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F314E00>
2025-05-08 08:34:14,067 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:14,067 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:14,067 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:14,068 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:14,068 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:15,886 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:16,036 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1955'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:16,036 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:16,036 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:16,037 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:16,037 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:16,037 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:16,038 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor enters the small park, immediately noticing the gentle murmur of t...
2025-05-08 08:34:16,038 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor enters the small park, immediately noticing the gentle murmur of the **fountain (fountain_park_01)** at its center. Several **benches (bench_park_01)** are scattered througho...'
2025-05-08 08:34:16,038 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor enters the small park, immediately noticing the gentle murmur of the **fountain (fountain_park_01)** at its center. Several **benches (bench_park_01)** are scattered througho...'
2025-05-08 08:34:16,038 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor enters the small park, immediately noticing the gentle murmur of the **fountain (fountain_park_01)** at its center. Several **benches (bench_park_01)** are scattered throughout 
2025-05-08 08:34:16,045 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor enters the small park, immediately noticing the gentle murmur of the **fountain (fountain_park_01)** at its center. Several **benches (bench_park_01)** are scattered throughout the space, some occupied by people reading or simply enjoying the sunshine. She spots an **empty bench (bench_park_02)** beneath the shade of a large oak tree, a perfect spot to savor her hotdog.
2025-05-08 08:34:16,045 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor enters the small park, immediately noticing the gentle murmur of the **f...
2025-05-08 08:34:16,045 - src.simulation_async - WARNING - Path segment 'Park_Elm_Street' not found or not dict in 'current_world_state.location_details.Park_Elm_Street.ephemeral_objects'. Creating.
2025-05-08 08:34:16,045 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Park_Elm_Street.ephemeral_objects = [{'id': 'bench_park_01', 'name': 'Occupied Benches', 'description': 'Several benches scattered around the park, some occupied.', 'is_interactive': False, 'properties': {}}, {'id': 'bench_park_02', 'name': 'Empty Bench', 'description': 'An empty bench beneath the shade of a large oak tree.', 'is_interactive': True, 'properties': {}}, {'id': 'fountain_park_01', 'name': 'Fountain', 'description': 'A fountain in the center of the park.', 'is_interactive': False, 'properties': {}}]
2025-05-08 08:34:16,045 - src.simulation_async - INFO - [NarrationTask] Updated/Set 3 ephemeral objects for location Park_Elm_Street from look_around.
2025-05-08 08:34:16,046 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Park_Elm_Street.ephemeral_npcs = []
2025-05-08 08:34:16,046 - src.simulation_async - INFO - [NarrationTask] Cleared ephemeral NPCs for location Park_Elm_Street as none were discovered by look_around.
2025-05-08 08:34:16,046 - src.simulation_async - INFO - [StateUpdate] Applied: current_world_state.location_details.Park_Elm_Street.connected_locations = []
2025-05-08 08:34:16,046 - src.simulation_async - INFO - [NarrationTask] Updated/Set 0 connected_locations for Park_Elm_Street from look_around.
2025-05-08 08:34:17,850 - src.simulation_async - INFO - [TimeManager] Applying completed action effects for sim_3e912d at time 1423.7 (due at 1423.7).
2025-05-08 08:34:17,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor Hayes is in a small park on Elm Street. Several benches are scattered around the park, some occupied, some empty. A fountain is in the center of the park.
2025-05-08 08:34:17,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:34:17,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:17,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = idle
2025-05-08 08:34:17,850 - src.simulation_async - INFO - [TimeManager] Set sim_3e912d status to idle.
2025-05-08 08:34:17,927 - src.simulation_async - DEBUG - [Eleanor Hayes] Status is idle. Proceeding to plan next action.
2025-05-08 08:34:17,927 - src.simulation_async - DEBUG - [Eleanor Hayes] Sending subsequent prompt.
2025-05-08 08:34:17,959 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:17,967 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:17,981 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F317560>
2025-05-08 08:34:17,981 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F32DE50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:17,999 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFF3AD0>
2025-05-08 08:34:18,000 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:18,000 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:18,000 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:18,000 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:18,000 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:18,918 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:40 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=908'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:18,919 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:18,919 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:18,919 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:18,919 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:18,919 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:18,920 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Perfect! An empty bench under an oak tree. Shade and a place to sit. That's the one. I'll go sit there and eat my hotdog.", "action_type": "use", "target_id": "bench_park_02", ...'
2025-05-08 08:34:18,920 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Perfect! An empty bench under an oak tree. Shade and a place to sit. That's the one. I'll go sit there and eat my hotdog.", "action_type": "use", "target_id": "bench_park_02", ...'
2025-05-08 08:34:18,920 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Perfect! An empty bench under an oak tree. Shade and a place to sit. That's the one. I'll go sit there and eat my hotdog.", 'action_type': 'use', 'target_id': 'bench_park_02', 
2025-05-08 08:34:18,938 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:34:18,942 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (use on bench_park_02) classified as 'environment'.
2025-05-08 08:34:18,942 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'use', 'target_id': 'bench_park_02', 'details': 'sitting on the empty bench and eating the hotdog'}
2025-05-08 08:34:18,942 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (use).
2025-05-08 08:34:18,968 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:18,976 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:18,991 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F338FB0>
2025-05-08 08:34:18,991 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F5409A8350> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:19,011 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F245AF0>
2025-05-08 08:34:19,011 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:19,011 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:19,011 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:19,011 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:19,011 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:19,835 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:41 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=811'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:19,835 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:19,835 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:19,836 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:19,836 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:19,836 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:19,837 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 600.0, "results": {}, "outcome_description": "Eleanor Hay...
2025-05-08 08:34:19,837 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 600.0, "results": {}, "outcome_description": "Eleanor Hayes sat on the empty bench and ate the hotdog."}...'
2025-05-08 08:34:19,837 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 600.0, "results": {}, "outcome_description": "Eleanor Hayes sat on the empty bench and ate the hotdog."}...'
2025-05-08 08:34:19,837 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 600.0, 'results': {}, 'outcome_description': 'Eleanor Hayes sat on the empty bench and ate the hotdog.'}
2025-05-08 08:34:19,837 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:34:19,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:34:19,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:34:19,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 2024.71800000011
2025-05-08 08:34:19,850 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: use - Details: sitting on the empty bench and eating the hotdog
2025-05-08 08:34:19,850 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 2024.7s. Outcome: Eleanor Hayes sat on the empty bench and ate the hotdog.
2025-05-08 08:34:19,850 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Park_Elm_Street
2025-05-08 08:34:19,850 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes sat on the empty bench and ate the hotdog.'
2025-05-08 08:34:19,879 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:19,888 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:19,900 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF21250>
2025-05-08 08:34:19,900 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F2EB3D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:19,919 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F317770>
2025-05-08 08:34:19,919 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:19,919 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:19,919 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:19,919 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:19,919 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:20,997 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:21,003 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.04982808333334591
2025-05-08 08:34:21,100 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:34:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1169'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:21,100 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:21,100 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:21,101 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:21,101 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:21,101 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:21,102 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor settles onto the empty bench beneath the oak tree, the rough wood ...
2025-05-08 08:34:21,102 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor settles onto the empty bench beneath the oak tree, the rough wood warm beneath her. She unwraps the hotdog, the aroma of mustard, onions, and grilled meat filling the air. Ta...'
2025-05-08 08:34:21,102 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor settles onto the empty bench beneath the oak tree, the rough wood warm beneath her. She unwraps the hotdog, the aroma of mustard, onions, and grilled meat filling the air. Ta...'
2025-05-08 08:34:21,102 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor settles onto the empty bench beneath the oak tree, the rough wood warm beneath her. She unwraps the hotdog, the aroma of mustard, onions, and grilled meat filling the air. Takin
2025-05-08 08:34:21,111 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor settles onto the empty bench beneath the oak tree, the rough wood warm beneath her. She unwraps the hotdog, the aroma of mustard, onions, and grilled meat filling the air. Taking a bite, she closes her eyes for a moment, savoring the simple pleasure of a perfectly greasy, utterly satisfying street food indulgence.
2025-05-08 08:34:21,115 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor settles onto the empty bench beneath the oak tree, the rough wood warm b...
2025-05-08 08:34:26,083 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:26,083 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.0493970833333442
2025-05-08 08:34:31,204 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:31,204 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.04897916666666667
2025-05-08 08:34:36,336 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:36,336 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = 0.048550750000014284
2025-05-08 08:34:38,708 - src.simulation_async - INFO - [Eleanor Hayes] Busy with long task (rem: 580.2s). Checking for self-reflection.
2025-05-08 08:34:38,708 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_interjection_sim_time = 1444.4839999999385
2025-05-08 08:34:38,708 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = reflecting
2025-05-08 08:34:38,737 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:38,746 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:38,771 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F316060>
2025-05-08 08:34:38,771 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F271E50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:38,792 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EFBA570>
2025-05-08 08:34:38,792 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:38,792 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:38,792 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:38,793 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:38,793 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:39,812 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:35:01 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1007'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:39,812 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:39,812 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:39,812 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:39,812 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:39,812 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:39,813 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"internal_monologue": "Mmm, that's the stuff. Greasy, salty, perfect. I'm really enjoying this. I think I'll just sit here for a bit, enjoying the park and the rest of my hotdog. I'll reflect on thin...'
2025-05-08 08:34:39,813 - src.loop_utils - DEBUG - Attempting to parse: '{"internal_monologue": "Mmm, that's the stuff. Greasy, salty, perfect. I'm really enjoying this. I think I'll just sit here for a bit, enjoying the park and the rest of my hotdog. I'll reflect on thin...'
2025-05-08 08:34:39,813 - src.loop_utils - DEBUG - Successfully parsed into dict: {'internal_monologue': "Mmm, that's the stuff. Greasy, salty, perfect. I'm really enjoying this. I think I'll just sit here for a bit, enjoying the park and the rest of my hotdog. I'll reflect on thin
2025-05-08 08:34:39,813 - src.simulation_async - INFO - [Eleanor Hayes] Reflection: Chose to 'reflecting'. Monologue: Mmm, that's the stuff. Greasy, salty, perfect. I'm...
2025-05-08 08:34:39,813 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:39,813 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = thinking
2025-05-08 08:34:39,813 - src.simulation_async - INFO - [InteractionDispatcher] Intent from sim_3e912d (reflecting on N/A) classified as 'environment'.
2025-05-08 08:34:39,814 - src.simulation_async - INFO - [WorldEngineLLM] Received 'environment' action request from sim_3e912d: {'action_type': 'reflecting', 'target_id': None, 'details': 'sitting on the bench, enjoying the hotdog and the park, reflecting'}
2025-05-08 08:34:39,814 - src.simulation_async - DEBUG - [WorldEngineLLM] Sending prompt to LLM for sim_3e912d's intent (reflecting).
2025-05-08 08:34:39,839 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:39,847 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:39,861 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F3D3020>
2025-05-08 08:34:39,861 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F34B7D0> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:39,880 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53E9045C0>
2025-05-08 08:34:39,880 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:39,880 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:39,880 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:39,880 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:39,880 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:40,680 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:35:02 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=788'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:40,681 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:40,681 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:40,681 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:40,681 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:40,681 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:40,682 - src.simulation_async - DEBUG - WorldLLM Final Content: ```json
{"valid_action": true, "duration": 600.0, "results": {}, "outcome_description": "Eleanor Hay...
2025-05-08 08:34:40,682 - src.loop_utils - DEBUG - Extracted from markdown fence: '{"valid_action": true, "duration": 600.0, "results": {}, "outcome_description": "Eleanor Hayes sat on the bench and reflected."}...'
2025-05-08 08:34:40,682 - src.loop_utils - DEBUG - Attempting to parse: '{"valid_action": true, "duration": 600.0, "results": {}, "outcome_description": "Eleanor Hayes sat on the bench and reflected."}...'
2025-05-08 08:34:40,682 - src.loop_utils - DEBUG - Successfully parsed into dict: {'valid_action': True, 'duration': 600.0, 'results': {}, 'outcome_description': 'Eleanor Hayes sat on the bench and reflected.'}
2025-05-08 08:34:40,682 - src.simulation_async - DEBUG - [WorldEngineLLM] LLM response validated successfully for sim_3e912d.
2025-05-08 08:34:40,695 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.status = busy
2025-05-08 08:34:40,695 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.pending_results = {}
2025-05-08 08:34:40,695 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_end_time = 2045.686999999918
2025-05-08 08:34:40,695 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_action_description = Action: reflecting - Details: sitting on the bench, enjoying the hotdog and the park, reflecting
2025-05-08 08:34:40,695 - src.simulation_async - INFO - [WorldEngineLLM] Action VALID for sim_3e912d. Stored results, set end time 2045.7s. Outcome: Eleanor Hayes sat on the bench and reflected.
2025-05-08 08:34:40,695 - src.simulation_async - DEBUG - [NarrationTask] Using global world mood: 'The real world and general slice of life.' for actor Eleanor Hayes at location Park_Elm_Street
2025-05-08 08:34:40,695 - src.simulation_async - INFO - [NarrationTask] Generating narrative for Eleanor Hayes's action completion. Outcome: 'Eleanor Hayes sat on the bench and reflected.'
2025-05-08 08:34:40,722 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:34:40,733 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:34:40,745 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53EF6E690>
2025-05-08 08:34:40,745 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53F322A50> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:34:40,764 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F53F30D9D0>
2025-05-08 08:34:40,765 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:34:40,765 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:34:40,765 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:34:40,765 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:34:40,765 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:34:41,453 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:42,615 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:35:04 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1839'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:34:42,615 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:34:42,615 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:34:42,615 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:34:42,615 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:34:42,615 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:34:42,616 - src.simulation_async - DEBUG - NarrationLLM Final Content: ```json
{
  "narrative": "Eleanor savors the last bites of her hotdog, the flavors mingling with the...
2025-05-08 08:34:42,617 - src.loop_utils - DEBUG - Extracted from markdown fence: '{
  "narrative": "Eleanor savors the last bites of her hotdog, the flavors mingling with the scent of freshly cut grass and blooming flowers. Around her, the park comes alive with the quiet hum of eve...'
2025-05-08 08:34:42,617 - src.loop_utils - DEBUG - Attempting to parse: '{
  "narrative": "Eleanor savors the last bites of her hotdog, the flavors mingling with the scent of freshly cut grass and blooming flowers. Around her, the park comes alive with the quiet hum of eve...'
2025-05-08 08:34:42,617 - src.loop_utils - DEBUG - Successfully parsed into dict: {'narrative': 'Eleanor savors the last bites of her hotdog, the flavors mingling with the scent of freshly cut grass and blooming flowers. Around her, the park comes alive with the quiet hum of everyd
2025-05-08 08:34:42,623 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.last_observation = Eleanor savors the last bites of her hotdog, the flavors mingling with the scent of freshly cut grass and blooming flowers. Around her, the park comes alive with the quiet hum of everyday life. A young mother (npc_concept_young_mother) pushes a stroller along the paved path, cooing softly to her baby. An elderly man (npc_concept_old_man) feeds the pigeons near the fountain, a gentle smile on his face. Eleanor closes her eyes, feeling a sense of contentment wash over her. The restlessness that had plagued her earlier has completely dissipated, replaced by a quiet sense of peace.
2025-05-08 08:34:42,623 - src.simulation_async - INFO - [NarrationTask] Appended narrative for Eleanor Hayes: Eleanor savors the last bites of her hotdog, the flavors mingling with the scent...
2025-05-08 08:34:46,564 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:51,696 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:34:56,798 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:01,925 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:07,041 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:12,127 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:17,260 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:22,377 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:27,493 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:32,617 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:37,720 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:42,848 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:47,963 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:52,320 - src.simulation_async - INFO - [NarrativeImageGenerator] Requesting image for narrative (T1518.1): "Eleanor enters the small park, immediately noticing the gentle murmur of the **fountain (fountain_pa..."
2025-05-08 08:35:52,320 - google_genai.models - INFO - AFC is enabled with max remote calls: 10.
2025-05-08 08:35:52,321 - httpcore.connection - DEBUG - close.started
2025-05-08 08:35:52,321 - httpcore.connection - DEBUG - close.complete
2025-05-08 08:35:52,322 - httpcore.connection - DEBUG - connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=None socket_options=None
2025-05-08 08:35:52,335 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F53EFF3410>
2025-05-08 08:35:52,336 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F53E591950> server_hostname='generativelanguage.googleapis.com' timeout=None
2025-05-08 08:35:52,353 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F53F285310>
2025-05-08 08:35:52,353 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-05-08 08:35:52,354 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-05-08 08:35:52,354 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-05-08 08:35:52,354 - httpcore.http11 - DEBUG - send_request_body.complete
2025-05-08 08:35:52,354 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-05-08 08:35:53,065 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:35:56,985 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 May 2025 12:36:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4620'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2025-05-08 08:35:56,985 - httpx - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-preview-image-generation:generateContent "HTTP/1.1 200 OK"
2025-05-08 08:35:56,985 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-05-08 08:35:57,185 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-05-08 08:35:57,185 - httpcore.http11 - DEBUG - response_closed.started
2025-05-08 08:35:57,185 - httpcore.http11 - DEBUG - response_closed.complete
2025-05-08 08:35:57,189 - google_genai.models - INFO - AFC remote call 1 is done.
2025-05-08 08:35:57,189 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-05-08 08:35:57,189 - PIL.PngImagePlugin - DEBUG - STREAM b'zTXt' 41 137
2025-05-08 08:35:57,190 - PIL.PngImagePlugin - DEBUG - STREAM b'iTXt' 190 647
2025-05-08 08:35:57,190 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 849 8192
2025-05-08 08:35:57,313 - src.simulation_async - INFO - [NarrativeImageGenerator] Successfully generated and saved image: C:\Users\dshea\Desktop\TheSimulation\data\narrative_images\narrative_T1518_20250508_083557_191266.png
2025-05-08 08:35:58,179 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:03,293 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:08,430 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:13,543 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:18,644 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:23,775 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:28,882 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:33,983 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:39,101 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:44,209 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:49,333 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:54,444 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:36:59,564 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:04,687 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:09,820 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:14,924 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:20,049 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:25,180 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:30,297 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:35,417 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:40,514 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:45,636 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:50,739 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:37:55,825 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:00,938 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:06,070 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:11,187 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:16,318 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:21,419 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:26,550 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:31,674 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:36,806 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:41,923 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:47,039 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:52,155 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:38:57,286 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:02,401 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:07,502 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:12,618 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:17,726 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:22,828 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:27,959 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:33,090 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:38,201 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:43,317 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:48,439 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:53,570 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:39:58,686 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:40:03,807 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:40:08,927 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:40:14,040 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:40:19,164 - src.simulation_async - INFO - [StateUpdate] Applied: simulacra_profiles.sim_3e912d.current_interrupt_probability = None
2025-05-08 08:40:19,828 - src.simulation_async - INFO - Cancelling remaining tasks...
2025-05-08 08:40:19,828 - src.simulation_async - INFO - [TimeManager] Task cancelled.
2025-05-08 08:40:19,828 - src.simulation_async - INFO - [TimeManager] Loop finished at sim time 1785.6
2025-05-08 08:40:19,828 - src.simulation_async - INFO - [InteractionDispatcher] Task cancelled.
2025-05-08 08:40:19,828 - src.simulation_async - INFO - [WorldInfoGatherer] Task cancelled.
2025-05-08 08:40:19,829 - src.simulation_async - INFO - [NarrationTask] Task cancelled.
2025-05-08 08:40:19,829 - src.simulation_async - INFO - [WorldEngineLLM] Task cancelled.
2025-05-08 08:40:19,829 - src.simulation_async - INFO - [Eleanor Hayes] Task cancelled.
2025-05-08 08:40:19,829 - src.simulation_async - INFO - [Eleanor Hayes] Task finished.
2025-05-08 08:40:19,829 - src.simulation_async - INFO - All tasks cancelled or finished.
2025-05-08 08:40:19,829 - src.simulation_async - INFO - Saving final simulation state.
2025-05-08 08:40:19,830 - src.loop_utils - DEBUG - Successfully saved JSON to C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-08 08:40:19,830 - src.simulation_async - INFO - Final simulation state saved to C:\Users\dshea\Desktop\TheSimulation\data\states\simulation_state_05e07dad-f24b-420b-822c-1ae7862220f6.json
2025-05-08 08:40:19,843 - __main__ - WARNING - Simulation interrupted by user.
